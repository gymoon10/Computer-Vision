{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofO343HlGP5u"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile\n",
        "import glob\n",
        "import io"
      ],
      "metadata": {
        "id": "s3QQkDdQGmcW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사전 학습된 BERT 모델 다운로드"
      ],
      "metadata": {
        "id": "Q56VUNJKHHCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)"
      ],
      "metadata": {
        "id": "2Ab11U6nGpF2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary 다운로드\n",
        "vocab_dir = \"./vocab/\"\n",
        "if not os.path.exists(vocab_dir):\n",
        "    os.mkdir(vocab_dir)\n",
        "\n",
        "save_path=\"./vocab/bert-base-uncased-vocab.txt\"\n",
        "url = \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt\"\n",
        "urllib.request.urlretrieve(url, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCpfr5YeGpN4",
        "outputId": "05ccbae3-3117-43d4-a770-7bb518d3ab42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./vocab/bert-base-uncased-vocab.txt',\n",
              " <http.client.HTTPMessage at 0x7f0c022da910>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-trained BERT의 가중치 다운로드\n",
        "weights_dir = \"./weights/\"\n",
        "if not os.path.exists(weights_dir):\n",
        "    os.mkdir(weights_dir)\n",
        "\n",
        "save_path = \"./weights/bert-base-uncased.tar.gz\"\n",
        "url = \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz\"\n",
        "urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "# 압축 해제\n",
        "archive_file = \"./weights/bert-base-uncased.tar.gz\"  # Uncased : 소문자 형식\n",
        "tar = tarfile.open(archive_file, 'r:gz')\n",
        "tar.extractall('./weights/')  \n",
        "tar.close()  "
      ],
      "metadata": {
        "id": "zpsVP0_eGrAV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "\n",
        "IMDb : http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "id": "aS9mQ-__HNW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_dir_path=\"./data/\"\n",
        "\n",
        "if not os.path.exists(target_dir_path):\n",
        "    os.mkdir(target_dir_path)\n",
        "    \n",
        "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "save_path = \"./data/aclImdb_v1.tar.gz\"\n",
        "urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "tar = tarfile.open('./data/aclImdb_v1.tar.gz')\n",
        "tar.extractall('./data/') \n",
        "tar.close()  "
      ],
      "metadata": {
        "id": "2fh6L6vhGsmz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_dir_path=\"./data/aclImdb/\"\n",
        "\n",
        "if os.path.exists(target_dir_path):\n",
        "    # Train\n",
        "    f = open('./data/IMDb_train.tsv','w')\n",
        "\n",
        "    path = './data/aclImdb/train/pos/'\n",
        "    for fname in glob.glob(os.path.join(path,'*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "            text = text.replace('\\t', \" \")\n",
        "            text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    path = './data/aclImdb/train/neg/'\n",
        "    for fname in glob.glob(os.path.join(path,'*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "            text = text.replace('\\t', \" \")\n",
        "            text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    # Test\n",
        "    f = open('./data/IMDb_test.tsv','w')\n",
        "\n",
        "    path = './data/aclImdb/test/pos/'\n",
        "    for fname in glob.glob(os.path.join(path,'*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "            text = text.replace('\\t', \" \")\n",
        "            text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    path = './data/aclImdb/test/neg/'\n",
        "\n",
        "    for fname in glob.glob(os.path.join(path,'*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "            text = text.replace('\\t', \" \")        \n",
        "            text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "UumqVFErHV1c"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT 구현"
      ],
      "metadata": {
        "id": "ckWuNhktHwKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n"
      ],
      "metadata": {
        "id": "C_y4yY8QHpx0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. BERT_Base 네트워크의 Config 불러오기"
      ],
      "metadata": {
        "id": "_r7COS6IHynu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "config_file = \"./weights/bert_config.json\"\n",
        "\n",
        "# json 형식으로 읽기\n",
        "json_file = open(config_file, 'r')\n",
        "config = json.load(json_file)\n",
        "\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf8x8FGjHtaH",
        "outputId": "a878fba8-0a35-4a13-bbd6-8cd144765bbe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_probs_dropout_prob': 0.1,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'max_position_embeddings': 512,\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'type_vocab_size': 2,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config['hidden_size']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj5NwanTImjP",
        "outputId": "ba0e188b-bafc-45bc-e624-b8ac5496a04c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install attrdict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wchxIme7IZIR",
        "outputId": "4c2b2df7-4d9b-48c5-851b-071a8ec4b319"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from attrdict) (1.15.0)\n",
            "Installing collected packages: attrdict\n",
            "Successfully installed attrdict-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary 변수를 object 변수로\n",
        "from attrdict import AttrDict \n",
        "\n",
        "config = AttrDict(config)\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYroRTMLIKHk",
        "outputId": "06673efc-f4aa-49f2-ccb2-4f08817f1510"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttrDict({'attention_probs_dropout_prob': 0.1, 'hidden_act': 'gelu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'intermediate_size': 3072, 'max_position_embeddings': 512, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 30522})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config.hidden_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzdbiQBKIYLh",
        "outputId": "31c61511-5c34-4faa-e607-9aa7474037f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. LayerNormalization \n",
        "\n",
        "Tensorflow 버전\n",
        "\n",
        "Tensor의 마지막 채널 (768차원으로 표현되는 개별 단어의 vector representation)에 대한 layer 정규화\n",
        "\n",
        "divide-by-zero를 방지하는 eps 추가\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/151758377-334c467c-20ec-4472-b66b-b14b6b6d40a6.png)\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/151758398-bdc09ad0-1840-4da9-906f-c7225b97f2e4.png)"
      ],
      "metadata": {
        "id": "QUjgaRB9IxJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertLayerNorm(nn.Module):\n",
        "    \n",
        "    def __init__(self, hidden_size, eps=1e-12):\n",
        "        super(BertLayerNorm, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(hidden_size))  # weights\n",
        "        self.beta = nn.Parameter(torch.zeros(hidden_size))  # bias\n",
        "        self.variance_epsilon = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = x.mean(-1, keepdim=True)  # 개별 단어 벡터마다 평균 계산\n",
        "        s = (x - u).pow(2).mean(-1, keepdim=True)  # 분산 계산 (broad casting)\n",
        "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "\n",
        "        return self.gamma * x + self.beta"
      ],
      "metadata": {
        "id": "xNlbj_ctIdZJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Embeddings\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/151758604-d80865e4-7fab-42e5-a83d-838d75c959d3.png)\n",
        "\n",
        "참고 : https://github.com/gymoon10/Paper-Review/blob/main/NLP/BERT.md"
      ],
      "metadata": {
        "id": "8cHsXBpyLGW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertEmbeddings(nn.Module):  \n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertEmbeddings, self).__init__()\n",
        "\n",
        "        # Token Embedding (단어 ID - > 단어 벡터)\n",
        "        self.word_embeddings = nn.Embedding(\n",
        "            config.vocab_size, config.hidden_size, padding_idx=0)  # vocab_size=30522 / hidden_size=768\n",
        "        \n",
        "        # Positional Embedding\n",
        "        self.position_embeddings = nn.Embedding(\n",
        "            config.max_position_embeddings, config.hidden_size)  # max_position_embeddings=512 (한 문장은 512개의 단어로 구성)\n",
        "\n",
        "        # Segment(sentence) Embedding\n",
        "        self.token_type_embeddings = nn.Embedding(\n",
        "            config.type_vocab_size, config.hidden_size)  # type_vocab_size=2\n",
        "        \n",
        "        # LayerNormalization\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        \n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None):\n",
        "        '''\n",
        "        입력\n",
        "        input_ids:  [batch_size, seq_len] 문장의 단어 ID 나열, seq_len=512\n",
        "        token_type_ids: [batch_size, seq_len] 각 단어가 1번째 문장인지, 2번째 문장인지를 나타내는 id\n",
        "        \n",
        "        출력\n",
        "        embeddings : [batch_size, seq_len, hidden_size], hidden_size=768\n",
        "        '''\n",
        "        # Token Embedding\n",
        "        words_embeddings = self.word_embeddings(input_ids)  \n",
        "\n",
        "        # Segment Embedding\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)  # 문장의 모든 단어를 첫 번째 문장으로(0)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        # Positional Embedding\n",
        "        seq_length = input_ids.size(1)  # seq_length=512\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)  # torch.Size([seq_length])\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)  # [batch, seq_length]로 차원 확장 (각 구성 요소는 동일, 일종의 행 복사)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        \n",
        "        # Output Embedding\n",
        "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
        "\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "\n",
        "        return embeddings  # [batch_size, seq_len, hidden_size] "
      ],
      "metadata": {
        "id": "no3j8Ve8LFpe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Process of Embedding"
      ],
      "metadata": {
        "id": "5w5HdKhrsc4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "input_ids = []\n",
        "for _ in range(64):\n",
        "    res = []\n",
        "    for _ in range(512):\n",
        "        res.append(random.randrange(1, 10000))\n",
        "    input_ids.append(res)\n",
        "\n",
        "token_type_ids = []\n",
        "for _ in range(64):\n",
        "    res = []\n",
        "    for _ in range(512):\n",
        "        res.append(random.randrange(0, 2))\n",
        "    token_type_ids.append(res)\n",
        "\n",
        "input_ids = torch.LongTensor(input_ids)\n",
        "print('input_ids :', input_ids.shape)\n",
        "\n",
        "token_type_ids = torch.LongTensor(token_type_ids)\n",
        "print('token_type_ids :', token_type_ids.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_idFhdXtoSEl",
        "outputId": "7e9fc2c0-c393-4b4f-a438-ffc994874fc7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids : torch.Size([64, 512])\n",
            "token_type_ids : torch.Size([64, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Embedding\n",
        "word_embeddings = nn.Embedding(\n",
        "            config.vocab_size, config.hidden_size, padding_idx=0)\n",
        "\n",
        "word_embeddings = word_embeddings(input_ids)\n",
        "print('word embeddings :', word_embeddings.shape)\n",
        "\n",
        "# Segment Embedding\n",
        "token_type_embeddings = nn.Embedding(\n",
        "            config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "token_type_embeddings = token_type_embeddings(token_type_ids)\n",
        "print('token_type_embeddings :', token_type_embeddings.shape)\n",
        "\n",
        "# Positional Embedding\n",
        "seq_length = input_ids.size(1)  # 512\n",
        "position_ids = torch.arange(\n",
        "            seq_length, dtype=torch.long, device=input_ids.device)  # torch.Size([512])\n",
        "position_ids = position_ids.unsqueeze(0).expand_as(input_ids)  # (64, 512)\n",
        "\n",
        "position_embeddings = nn.Embedding(\n",
        "            config.max_position_embeddings, config.hidden_size)\n",
        "\n",
        "position_embeddings = position_embeddings(position_ids)\n",
        "print('position_embeddings :', position_embeddings.shape)\n",
        "\n",
        "embeddings = word_embeddings + position_embeddings + token_type_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvxev-iEqbdk",
        "outputId": "5ee69dc5-6454-4817-c1b2-7e6874581692"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word embeddings : torch.Size([64, 512, 768])\n",
            "token_type_embeddings : torch.Size([64, 512, 768])\n",
            "position_embeddings : torch.Size([64, 512, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "position_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QK4lskHLqbgS",
        "outputId": "ac2fed4b-1947-4329-f6a2-18f9c04048ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   1,   2,  ..., 509, 510, 511],\n",
              "        [  0,   1,   2,  ..., 509, 510, 511],\n",
              "        [  0,   1,   2,  ..., 509, 510, 511],\n",
              "        ...,\n",
              "        [  0,   1,   2,  ..., 509, 510, 511],\n",
              "        [  0,   1,   2,  ..., 509, 510, 511],\n",
              "        [  0,   1,   2,  ..., 509, 510, 511]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. BERT Layer\n",
        "\n",
        "Transformer에 해당\n",
        "\n",
        "- BertAttention : self-attention 계산\n",
        "- BertIntermediate : self-attention의 출력 처리\n",
        "- BertOutput : BertAttention + BertIntermediate\n",
        "\n",
        "<br/>\n",
        "\n",
        "**입력** : [batch_size, seq_len, hidden_size] - [64, 512, 768]\n",
        "\n",
        "**출력** : [batch_size, seq_len, hidden_size] - [64, 512, 768]\n",
        "\n",
        "<br/>\n",
        "\n",
        "**구성**\n",
        "\n",
        "1. BertAttention\n",
        "\n",
        "   - BertSelfAttention\n",
        "   - BertSelfOutput\n",
        "\n",
        "2. BertIntermediate\n",
        "\n",
        "3. BertOutput"
      ],
      "metadata": {
        "id": "R18_TXukP972"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.1 BertSelfOutput\n",
        "\n",
        "BertSelfAttention의 출력을 처리하는 F.C layer\n",
        "\n"
      ],
      "metadata": {
        "id": "6YTDW2IdSfEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertSelfOutput(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertSelfOutput, self).__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        '''\n",
        "        hidden_states: BertSelfAttention의 출력 텐서\n",
        "        input_tensor: Embeddings 모듈 또는 앞단의 BertLayer의 출력\n",
        "        '''\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "\n",
        "        return hidden_states"
      ],
      "metadata": {
        "id": "Y0V-zq95SlhV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 BertSelfAttention & BertAttention\n",
        "\n",
        "**입력** : [seq_len, hidden_size] = [512, 768]  (Embedding 모듈의 출력 or 앞 단의BertLayer 출력)"
      ],
      "metadata": {
        "id": "G_Cfjb_jRzpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertSelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertSelfAttention, self).__init__()\n",
        "\n",
        "        self.num_attention_heads = config.num_attention_heads  # 12\n",
        "\n",
        "        self.attention_head_size = int(\n",
        "            config.hidden_size / config.num_attention_heads)  # 768/12=64\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size  # =hidden_size=768\n",
        "\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)  # nn.Linear(768, 768)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "    def transpose_for_scores(self, x):  \n",
        "        '''\n",
        "        Multi-Head-Attention 용으로 텐서의 형태 변환\n",
        "        [batch_size, seq_len, hidden] -> [batch_size, 12, seq_len, hidden / 12]  /  [64, 512, 768] -> [64, 12, 512, 64]\n",
        "        ''' \n",
        "        # 일종의 리스트 합 연산\n",
        "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)  # torch.size([64, 512]) + torch.size([12, 64])\n",
        "        x = x.view(*new_x_shape)  # torch.Size([64, 512, 12, 64])\n",
        "\n",
        "        return x.permute(0, 2, 1, 3)  # torch.Size([64, 12, 512, 64]) - [batch, heads, seq_len, hidden / heads]\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask, attention_show_fig=False):\n",
        "        '''\n",
        "        hidden_states: Embeddings 모듈 or 앞 단의 BertLayer 출력 - [64, 512, 768]\n",
        "        attention_mask: Transformer의 마스크와 같은 기능의 마스킹\n",
        "        attention_show_flg: Self-Attention의 가중치를 반환할지의 플래그\n",
        "        '''\n",
        "        # Q K V (Multi-Head-Attention 전부를 한꺼번에 변환)\n",
        "        mixed_query_layer = self.query(hidden_states)\n",
        "        mixed_key_layer = self.key(hidden_states)\n",
        "        mixed_value_layer = self.value(hidden_states)\n",
        "\n",
        "        # Multi-Head-Attention용으로 텐서 변환\n",
        "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
        "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
        "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
        "        \n",
        "        # Attention score\n",
        "        attention_scores = torch.matmul(\n",
        "            query_layer, key_layer.transpose(-1, -2))  # [64, 12, 512, 64] x [64, 12, 64, 512] = [64, 12, 512, 512]\n",
        "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)  # 한 문장을 구성하는 512개 단어들 간의 정규화된 유사도\n",
        "\n",
        "        # Masking (masking된 부분은 -inf, 나머지는 0)\n",
        "        attention_scores = attention_scores + attention_mask\n",
        "        \n",
        "        # Attention dist (정규화)\n",
        "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "        # Attention map\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)  # [64, 12, 512, 512] x [64, 12, 512, 64] = [64, 12, 512, 64]\n",
        "        \n",
        "        # Multi-Head-Attention의 텐서 형식을 원래대로\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()  # [64, 512, 12, 64]\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)  # [64, 512, 768]\n",
        "        context_layer = context_layer.view(*new_context_layer_shape)  # [64, 512, 768]\n",
        "\n",
        "        if attention_show_fig == True:\n",
        "            return context_layer, attention_probs\n",
        "\n",
        "        elif attention_show_fig == False:\n",
        "            return context_layer"
      ],
      "metadata": {
        "id": "E6FDN5ssP5V-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertAttention(nn.Module):\n",
        "    '''BertLayer 모듈의 Self-Attention 부분'''\n",
        "    def __init__(self, config):\n",
        "        super(BertAttention, self).__init__()\n",
        "        self.selfattn = BertSelfAttention(config)\n",
        "        self.output = BertSelfOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask, attention_show_fig=False):\n",
        "        '''\n",
        "        input_tensor: Embeddings 모듈 or 앞 단의 BertLayer 출력\n",
        "        attention_mask: Transformer의 마스크와 같은 기능의 마스킹\n",
        "        attention_show_flg: Self-Attention의 가중치를 반환할지의 플래그\n",
        "        '''\n",
        "        if attention_show_fig == True:\n",
        "            self_output, attention_probs = self.selfattn(input_tensor, attention_mask, attention_show_fig)\n",
        "            attention_output = self.output(self_output, input_tensor)\n",
        "\n",
        "            return attention_output, attention_probs\n",
        "\n",
        "        elif attention_show_fig == False:\n",
        "            self_output = self.selfattn(input_tensor, attention_mask, attention_show_fig)\n",
        "            attention_output = self.output(self_output, input_tensor)\n",
        "            \n",
        "            return attention_output"
      ],
      "metadata": {
        "id": "3jqwE9jimNBN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.1 Process of BertSelfAttention"
      ],
      "metadata": {
        "id": "0wcgaKYCy1Kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input\n",
        "hidden_states = embeddings\n",
        "print('hidden_states :', hidden_states.shape)\n",
        "print()\n",
        "\n",
        "num_attention_heads = config.num_attention_heads  # 12\n",
        "attention_head_size = int(\n",
        "            config.hidden_size / config.num_attention_heads)  # 768/12=64\n",
        "all_head_size = num_attention_heads * attention_head_size  # =hidden_size=768\n",
        "\n",
        "# Query Key Value\n",
        "query = nn.Linear(config.hidden_size, all_head_size)  # nn.Linear(768, 768)\n",
        "key = nn.Linear(config.hidden_size, all_head_size)\n",
        "value = nn.Linear(config.hidden_size, all_head_size)\n",
        "\n",
        "mixed_query_layer = query(hidden_states)\n",
        "mixed_key_layer = key(hidden_states)\n",
        "mixed_value_layer = value(hidden_states)\n",
        "print('mixed query key value :', mixed_query_layer.shape)\n",
        "\n",
        "# MHA용으로 텐서 변환 (transpose_for_scores)\n",
        "def transpose_for_scores(x):\n",
        "    new_x_shape = x.size()[:-1] + (num_attention_heads, attention_head_size)\n",
        "    x = x.view(*new_x_shape)\n",
        "    return x.permute(0, 2, 1, 3)\n",
        "\n",
        "query_layer = transpose_for_scores(mixed_query_layer)\n",
        "key_layer = transpose_for_scores(mixed_key_layer)\n",
        "value_layer = transpose_for_scores(mixed_value_layer)\n",
        "print('query key value for multi-heads :', query_layer.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SvRUmrzssXS",
        "outputId": "a167e221-1418-49af-f87f-3452d552d3e7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_states : torch.Size([64, 512, 768])\n",
            "\n",
            "mixed query key value : torch.Size([64, 512, 768])\n",
            "query key value for multi-heads : torch.Size([64, 12, 512, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention scores\n",
        "attention_scores = torch.matmul(\n",
        "    query_layer, key_layer.transpose(-1, -2))  # [64, 12, 512, 64] x [64, 12, 64, 512]\n",
        "attention_scores = attention_scores / \\\n",
        "    math.sqrt(attention_head_size)\n",
        "print('attention_scores :', attention_scores.shape)\n",
        "\n",
        "# Attention dist (정규화)\n",
        "attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
        "print('attention_probs :', attention_probs.shape)\n",
        "\n",
        "# Attention map\n",
        "context_layer = torch.matmul(attention_probs, value_layer)  # [64, 12, 512, 512] x [64, 12, 512, 64]\n",
        "print('context_layer :', context_layer.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXDHA-9NszUT",
        "outputId": "380f1e52-fd15-47a1-a7da-f48e01d8996f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attention_scores : torch.Size([64, 12, 512, 512])\n",
            "attention_probs : torch.Size([64, 12, 512, 512])\n",
            "context_layer : torch.Size([64, 12, 512, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Head-Attention의 텐서 형식을 원래대로\n",
        "context_layer = context_layer.permute(0, 2, 1, 3).contiguous()  # [64, 512, 12, 64]\n",
        "new_context_layer_shape = context_layer.size()[:-2] + (all_head_size, )  # [64, 512, 768]\n",
        "context_layer = context_layer.view(*new_context_layer_shape)\n",
        "print('context_layer :', context_layer.shape)  # [64, 512, 768]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8dt8RhptLMs",
        "outputId": "250ab67e-3e29-4f0e-e182-b7086fe390e4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_layer : torch.Size([64, 512, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2.2 Process of BertAttention"
      ],
      "metadata": {
        "id": "4wDGACofzAE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selfattn = BertSelfAttention(config)\n",
        "selfattn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKFwW5Z-uLeD",
        "outputId": "de6cad7e-6922-4048-d33d-e4e7b15356f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertSelfAttention(\n",
              "  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = BertSelfOutput(config)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qprVkiRZuy3E",
        "outputId": "bf407474-be24-482d-f116-f7335ae6a5d7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertSelfOutput(\n",
              "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (LayerNorm): BertLayerNorm()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = context_layer\n",
        "\n",
        "attention_mask = torch.randn([64, 12, 512, 512])\n",
        "\n",
        "print('input_tensor :', input_tensor.shape)\n",
        "print('attention_mask :', attention_mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYdO0To2vMek",
        "outputId": "c29b27ea-d88d-466d-9d6c-27e52fba630a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_tensor : torch.Size([64, 512, 768])\n",
            "attention_mask : torch.Size([64, 12, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "self_output, attention_probs = selfattn(input_tensor, attention_mask, attention_show_fig=True)\n",
        "print('self_output :', self_output.shape)\n",
        "print('attention_probs :', attention_probs.shape)\n",
        "\n",
        "attention_output = output(self_output, input_tensor)\n",
        "print('attention_output :', attention_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXmp_K6h0acI",
        "outputId": "95c4e1b8-c54b-4c8e-a0cc-151c3682ab8a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self_output : torch.Size([64, 512, 768])\n",
            "attention_probs : torch.Size([64, 12, 512, 512])\n",
            "attention_output : torch.Size([64, 512, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 BertIntermediate\n",
        "\n",
        "BERT TransformerBlock 모듈의 Feed-Forward"
      ],
      "metadata": {
        "id": "J6jZuYk67BJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gelu(x):\n",
        "    '''Gaussian Error Linear Unit\n",
        "    '''\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))"
      ],
      "metadata": {
        "id": "eRMd-kJW1ZpE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertIntermediate(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertIntermediate, self).__init__()\n",
        "        \n",
        "        # F.C layer\n",
        "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)  # nn.Linear(768, 3072)\n",
        "        # GeLU\n",
        "        self.intermediate_act_fn = gelu\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        '''\n",
        "        hidden_states:  BertAttention 출력 - [64, 512, 768]\n",
        "        '''\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)  # GELU에 의한 활성화\n",
        "        \n",
        "        return hidden_states  # [64, 512, 3072]"
      ],
      "metadata": {
        "id": "CVvE-rbn7WYF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 BertOutput\n",
        "\n",
        "BERT TransformerBlock 모듈의 Feed-Forward"
      ],
      "metadata": {
        "id": "I6bRna7F7_Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertOutput(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertOutput, self).__init__()\n",
        "\n",
        "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)  # nn.Linear(3072, 768)\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)  # 0.1\n",
        "\n",
        "    def forward(self, hidden_states, input_tensor):\n",
        "        '''\n",
        "        hidden_states:  BertIntermediate 출력 - [64, 512, 3072]\n",
        "        input_tensor: BertAttention의 출력 - [64, 512, 768]\n",
        "        '''\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "\n",
        "        return hidden_states  # [64, 512, 768]"
      ],
      "metadata": {
        "id": "fpT2Jrw37-lB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 BertLayer"
      ],
      "metadata": {
        "id": "6M2wKtIa_MGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertLayer, self).__init__()\n",
        "\n",
        "        # Self-Attention\n",
        "        self.attention = BertAttention(config)\n",
        "\n",
        "        # Self-Attention의 출력을 처리하는 F.C layer\n",
        "        self.intermediate = BertIntermediate(config)\n",
        "\n",
        "        # Self-Attention의 출력과 BertLayer에 원래의 입력을 더하는 layer\n",
        "        self.output = BertOutput(config)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask, attention_show_fig=False):\n",
        "        '''\n",
        "        hidden_states: Embedder 모듈의 출력 텐서 [batch_size, seq_len, hidden_size]\n",
        "        attention_mask: masking\n",
        "        attention_show_flg: Self-Attention의 가중치를 반환할지의 플래그\n",
        "        '''\n",
        "        if attention_show_fig == True:\n",
        "            attention_output, attention_probs = self.attention(\n",
        "                hidden_states, attention_mask, attention_show_fig)\n",
        "            intermediate_output = self.intermediate(attention_output)\n",
        "            layer_output = self.output(intermediate_output, attention_output)\n",
        "            \n",
        "            return layer_output, attention_probs\n",
        "\n",
        "        elif attention_show_fig == False:\n",
        "            attention_output = self.attention(\n",
        "                hidden_states, attention_mask, attention_show_fig)\n",
        "            intermediate_output = self.intermediate(attention_output)\n",
        "            layer_output = self.output(intermediate_output, attention_output)\n",
        "\n",
        "            return layer_output  # [batch_size, seq_length, hidden_size]"
      ],
      "metadata": {
        "id": "4gWBIAyM7ngm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BertLayer(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNRCHL7W_cUw",
        "outputId": "083a745d-d6d7-49dc-caba-976ffb459789"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertLayer(\n",
              "  (attention): BertAttention(\n",
              "    (selfattn): BertSelfAttention(\n",
              "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (output): BertSelfOutput(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (intermediate): BertIntermediate(\n",
              "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "  )\n",
              "  (output): BertOutput(\n",
              "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. BertEncoder\n",
        "\n",
        "BertLayer 모듈의 반복"
      ],
      "metadata": {
        "id": "5dIJkB_V_wTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioGE8Ua0Av7B",
        "outputId": "66d89ced-7c7f-432a-e620-a1357ff672f2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (1): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (2): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (3): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (4): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (5): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (6): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (7): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (8): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (9): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (10): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (11): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (selfattn): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): BertLayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertEncoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertEncoder, self).__init__()\n",
        "\n",
        "        # 12개의 BertLayer 모듈 생성\n",
        "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True, attention_show_fig=False):\n",
        "        '''\n",
        "        hidden_states: Embeddings 모듈 출력\n",
        "        attention_mask: masking\n",
        "        output_all_encoded_layers: 모든 TransformerBlock 모듈의 출력을 반환할 지, 최종 층의 출력만 반환할 지\n",
        "        attention_show_flg: Self-Attention의 가중치를 반환할지의 플래그\n",
        "        '''\n",
        "        # 반환 값 리스트\n",
        "        all_encoder_layers = []\n",
        "\n",
        "        for layer_module in self.layer:\n",
        "            if attention_show_fig == True:\n",
        "                hidden_states, attention_probs = layer_module(\n",
        "                    hidden_states, attention_mask, attention_show_fig)\n",
        "                \n",
        "            elif attention_show_fig == False:\n",
        "                hidden_states = layer_module(\n",
        "                    hidden_states, attention_mask, attention_show_fig)\n",
        "                \n",
        "            if output_all_encoded_layers:  # 중간 layer 출력들도 저장\n",
        "                all_encoder_layers.append(hidden_states)\n",
        "\n",
        "        if not output_all_encoded_layers:  # 마지막 layer의 출력만 저장\n",
        "            all_encoder_layers.append(hidden_states)\n",
        "\n",
        "        if attention_show_fig == True:\n",
        "            return all_encoder_layers, attention_probs\n",
        "\n",
        "        elif attention_show_fig == False:\n",
        "            return all_encoder_layers"
      ],
      "metadata": {
        "id": "Q-rFX24v_lKU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. BertPooler"
      ],
      "metadata": {
        "id": "9UwwLeBpBhSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertPooler(nn.Module):\n",
        "    '''입력 문장의 첫번째 단어 [cls] 토큰의 feature 반환, 유지'''\n",
        "    def __init__(self, config):\n",
        "        super(BertPooler, self).__init__()\n",
        "\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)  # nn.Linear(768, 768)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        # [CLS] 토큰의 feature 획득\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "      \n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "\n",
        "        return pooled_output"
      ],
      "metadata": {
        "id": "usrsW_NSBMCT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1 동작 확인"
      ],
      "metadata": {
        "id": "1BXWMBHsCG2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.LongTensor([[31, 51, 12, 23, 99], [15, 5, 1, 0, 0]])\n",
        "print(\"입력 단어 ID열의 텐서 크기: \", input_ids.shape, '- [batch, seq_length]')  \n",
        "\n",
        "# 마스크\n",
        "attention_mask = torch.LongTensor([[1, 1, 1, 1, 1], [1, 1, 1, 0, 0]])\n",
        "print(\"입력 마스크의 텐서 크기: \", attention_mask.shape, '- [batch, seq_length]')\n",
        "\n",
        "extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)  # 해당 위치에 새로운 차원이 추가됨\n",
        "extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)\n",
        "extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "print(\"확장된 마스크의 텐서 크기: \", extended_attention_mask.shape, '- [batch, 1, 1, seq_length]')\n",
        "\n",
        "# 문장의 ID. 두 미니 배치 각각에 대해, 0은 첫번째 문장을, 1은 2번째 문장을 나타냄\n",
        "token_type_ids = torch.LongTensor([[0, 0, 1, 1, 1], [0, 1, 1, 1, 1]])\n",
        "print(\"입력 문장 ID의 텐서 크기: \", token_type_ids.shape, '- [batch, seq_length]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRlL9IGTCD4W",
        "outputId": "232f1887-74a0-4515-9674-0f0f73afe799"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 단어 ID열의 텐서 크기:  torch.Size([2, 5]) - [batch, seq_length]\n",
            "입력 마스크의 텐서 크기:  torch.Size([2, 5]) - [batch, seq_length]\n",
            "확장된 마스크의 텐서 크기:  torch.Size([2, 1, 1, 5]) - [batch, 1, 1, seq_length]\n",
            "입력 문장 ID의 텐서 크기:  torch.Size([2, 5]) - [batch, seq_length]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extended_attention_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcEiMrM_CWXV",
        "outputId": "274daaa7-efa9-48f0-88ff-c44c9646241a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[    -0.,     -0.,     -0.,     -0.,     -0.]]],\n",
              "\n",
              "\n",
              "        [[[    -0.,     -0.,     -0., -10000., -10000.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = BertEmbeddings(config)\n",
        "encoder = BertEncoder(config)\n",
        "pooler = BertPooler(config)"
      ],
      "metadata": {
        "id": "S4sEmoYDCJ_B"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out1 = embeddings(input_ids, token_type_ids)\n",
        "print(\"BertEmbeddings의 출력 텐서 크기: \", out1.shape, '- [batch, seq_length, hidden]')\n",
        "print()\n",
        "\n",
        "out2 = encoder(out1, extended_attention_mask)  # default : Encoder를 구성하는 12개 BertLayer의 모든 hidden states 반환\n",
        "print(\"BertEncoder 최종 layer의 출력 텐서 크기: \", len(out2), '- # of Attention Heads')\n",
        "print()\n",
        "\n",
        "out3 = pooler(out2[-1])  # Encoder를 구성하는 마지막 BertLayer의 출력\n",
        "print(\"BertPooler의 입력 텐서 크기: \", out2[-1].shape)\n",
        "print(\"[CLS] 토큰에 해당하는 텐서 크기: \", out2[-1][:, 0].shape)\n",
        "print(\"BertPooler의 출력 텐서 크기: \", out3.shape, '- [batch, hidden]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddv6FWwqCOYx",
        "outputId": "98352230-4a33-448c-89c8-4177b5481c66"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertEmbeddings의 출력 텐서 크기:  torch.Size([2, 5, 768]) - [batch, seq_length, hidden]\n",
            "\n",
            "BertEncoder 최종 layer의 출력 텐서 크기:  12 - # of Attention Heads\n",
            "\n",
            "BertPooler의 입력 텐서 크기:  torch.Size([2, 5, 768])\n",
            "[CLS] 토큰에 해당하는 텐서 크기:  torch.Size([2, 768])\n",
            "BertPooler의 출력 텐서 크기:  torch.Size([2, 768]) - [batch, hidden]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. BERT 모델\n",
        "\n",
        "구현한 모듈을 전부 연결"
      ],
      "metadata": {
        "id": "NFBGnFUhEH1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertModel(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertModel, self).__init__()\n",
        "        \n",
        "        # 위에서 구현한 모듈 작성\n",
        "        self.embeddings = BertEmbeddings(config)  # 입력 문장 처리\n",
        "        self.encoder = BertEncoder(config)  # BertLayer 12개로 구성\n",
        "        self.pooler = BertPooler(config)  # [CLS]토큰 처리\n",
        "    \n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, output_all_encoded_layers=True, attention_show_fig=False):\n",
        "        '''\n",
        "        input_ids:  [batch_size, seq_length] 문장의 단어 ID 나열 - [64, 512]\n",
        "        token_type_ids:  [batch_size, seq_length] 각 단어가 1번째 문장인지, 2번째 문장인지를 나타내는 id - [64, 512]\n",
        "        attention_mask: masking - [64, 512]\n",
        "        output_all_encoded_layers: BertEncoder를 구성하는 모든 BertLayer의 출력을 반환할 지, 최종 층의 출력만 반환할 지\n",
        "        attention_show_flg: Self-Attention의 가중치를 반환할지의 플래그\n",
        "        '''\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones_like(input_ids)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)\n",
        "\n",
        "        # mask 변형 : [batch, seq_length] -> [batch, 1, 1, seq_length] (Multi-Head-Attention용으로 사용 가능하도록)\n",
        "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "        extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "        # Forward\n",
        "        # 1. BertEmbeddings\n",
        "        embedding_output = self.embeddings(input_ids, token_type_ids)\n",
        "        \n",
        "        # 2. BertEncoder (12개의 BertLayer로 구성)\n",
        "        if attention_show_fig == True:  # 12개 layer의 모든 hidden_state 출력 반환\n",
        "            encoded_layers, attention_probs = self.encoder(embedding_output,\n",
        "                                                           extended_attention_mask,\n",
        "                                                           output_all_encoded_layers, attention_show_fig)\n",
        "        elif attention_show_fig == False:  # 마지막 12번 째 layer의 hidden_state 출력만을 반환\n",
        "            encoded_layers = self.encoder(embedding_output,\n",
        "                                          extended_attention_mask,\n",
        "                                          output_all_encoded_layers, attention_show_fig)\n",
        "            \n",
        "        # 3. BertPooler\n",
        "        pooled_output = self.pooler(encoded_layers[-1])  # Encoder의 마지막 BertLayer출력 이용\n",
        "\n",
        "        if not output_all_encoded_layers:\n",
        "            encoded_layers = encoded_layers[-1]\n",
        "\n",
        "        if attention_show_fig == True:\n",
        "            return encoded_layers, pooled_output, attention_probs\n",
        "\n",
        "        elif attention_show_fig == False:\n",
        "            return encoded_layers, pooled_output"
      ],
      "metadata": {
        "id": "lqLRswGoCcmX"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6.1 동작 확인"
      ],
      "metadata": {
        "id": "qJIZHwZLsil_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.LongTensor([[31, 51, 12, 23, 99], [15, 5, 1, 0, 0]])\n",
        "attention_mask = torch.LongTensor([[1, 1, 1, 1, 1], [1, 1, 1, 0, 0]])\n",
        "token_type_ids = torch.LongTensor([[0, 0, 1, 1, 1], [0, 1, 1, 1, 1]])\n",
        "\n",
        "# BERT model\n",
        "net = BertModel(config)\n",
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFv4tRV8ENVU",
        "outputId": "8a8e4000-4a02-4d97-a198-800cfcffeb8e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (selfattn): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# forward\n",
        "encoded_layers, pooled_output, attention_probs = net(\n",
        "    input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False, attention_show_fig=True)  # 최종 BertLayer의 출력만\n",
        "\n",
        "print(\"encoded_layers의 텐서 크기: \", encoded_layers.shape, '- [batch, seq_length, hidden]')\n",
        "print(\"pooled_output의 텐서 크기: \", pooled_output.shape, '- [batch, hidden]')\n",
        "print(\"attention_probs의 텐서 크기: \", attention_probs.shape, '- [batch, # of heads, seq_length, seq_length]')  # 각 head 별로 문장은 구성하는 5개 단어들간의 self-attention dist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUIDlVyaENbg",
        "outputId": "4687ac8e-a163-410c-d687-9e289d391870"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded_layers의 텐서 크기:  torch.Size([2, 5, 768]) - [batch, seq_length, hidden]\n",
            "pooled_output의 텐서 크기:  torch.Size([2, 768]) - [batch, hidden]\n",
            "attention_probs의 텐서 크기:  torch.Size([2, 12, 5, 5]) - [batch, # of heads, seq_length, seq_length]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Application\n"
      ],
      "metadata": {
        "id": "BnxbxWV5vGYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모델 load\n",
        "weights_path = \"./weights/pytorch_model.bin\"\n",
        "loaded_state_dict = torch.load(weights_path)\n",
        "\n",
        "for state in loaded_state_dict.keys():\n",
        "    print(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz_bAInVENer",
        "outputId": "33e292a5-e2ef-4979-b78a-5f0bbe3dd4c4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.gamma\n",
            "bert.embeddings.LayerNorm.beta\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.output.LayerNorm.beta\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "cls.predictions.bias\n",
            "cls.predictions.transform.dense.weight\n",
            "cls.predictions.transform.dense.bias\n",
            "cls.predictions.transform.LayerNorm.gamma\n",
            "cls.predictions.transform.LayerNorm.beta\n",
            "cls.predictions.decoder.weight\n",
            "cls.seq_relationship.weight\n",
            "cls.seq_relationship.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = BertModel(config)\n",
        "net.eval()  # inference\n",
        "\n",
        "param_names = [] \n",
        "for name, param in net.named_parameters():\n",
        "    print(name)  # 사전 학습된 모델의 state_dict와 이름이 다른 것을 확인\n",
        "    param_names.append(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_wEkScHDE_j",
        "outputId": "353a3426-d094-428b-9e9a-45fbb62c87b8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings.word_embeddings.weight\n",
            "embeddings.position_embeddings.weight\n",
            "embeddings.token_type_embeddings.weight\n",
            "embeddings.LayerNorm.gamma\n",
            "embeddings.LayerNorm.beta\n",
            "encoder.layer.0.attention.selfattn.query.weight\n",
            "encoder.layer.0.attention.selfattn.query.bias\n",
            "encoder.layer.0.attention.selfattn.key.weight\n",
            "encoder.layer.0.attention.selfattn.key.bias\n",
            "encoder.layer.0.attention.selfattn.value.weight\n",
            "encoder.layer.0.attention.selfattn.value.bias\n",
            "encoder.layer.0.attention.output.dense.weight\n",
            "encoder.layer.0.attention.output.dense.bias\n",
            "encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "encoder.layer.0.attention.output.LayerNorm.beta\n",
            "encoder.layer.0.intermediate.dense.weight\n",
            "encoder.layer.0.intermediate.dense.bias\n",
            "encoder.layer.0.output.dense.weight\n",
            "encoder.layer.0.output.dense.bias\n",
            "encoder.layer.0.output.LayerNorm.gamma\n",
            "encoder.layer.0.output.LayerNorm.beta\n",
            "encoder.layer.1.attention.selfattn.query.weight\n",
            "encoder.layer.1.attention.selfattn.query.bias\n",
            "encoder.layer.1.attention.selfattn.key.weight\n",
            "encoder.layer.1.attention.selfattn.key.bias\n",
            "encoder.layer.1.attention.selfattn.value.weight\n",
            "encoder.layer.1.attention.selfattn.value.bias\n",
            "encoder.layer.1.attention.output.dense.weight\n",
            "encoder.layer.1.attention.output.dense.bias\n",
            "encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "encoder.layer.1.attention.output.LayerNorm.beta\n",
            "encoder.layer.1.intermediate.dense.weight\n",
            "encoder.layer.1.intermediate.dense.bias\n",
            "encoder.layer.1.output.dense.weight\n",
            "encoder.layer.1.output.dense.bias\n",
            "encoder.layer.1.output.LayerNorm.gamma\n",
            "encoder.layer.1.output.LayerNorm.beta\n",
            "encoder.layer.2.attention.selfattn.query.weight\n",
            "encoder.layer.2.attention.selfattn.query.bias\n",
            "encoder.layer.2.attention.selfattn.key.weight\n",
            "encoder.layer.2.attention.selfattn.key.bias\n",
            "encoder.layer.2.attention.selfattn.value.weight\n",
            "encoder.layer.2.attention.selfattn.value.bias\n",
            "encoder.layer.2.attention.output.dense.weight\n",
            "encoder.layer.2.attention.output.dense.bias\n",
            "encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "encoder.layer.2.attention.output.LayerNorm.beta\n",
            "encoder.layer.2.intermediate.dense.weight\n",
            "encoder.layer.2.intermediate.dense.bias\n",
            "encoder.layer.2.output.dense.weight\n",
            "encoder.layer.2.output.dense.bias\n",
            "encoder.layer.2.output.LayerNorm.gamma\n",
            "encoder.layer.2.output.LayerNorm.beta\n",
            "encoder.layer.3.attention.selfattn.query.weight\n",
            "encoder.layer.3.attention.selfattn.query.bias\n",
            "encoder.layer.3.attention.selfattn.key.weight\n",
            "encoder.layer.3.attention.selfattn.key.bias\n",
            "encoder.layer.3.attention.selfattn.value.weight\n",
            "encoder.layer.3.attention.selfattn.value.bias\n",
            "encoder.layer.3.attention.output.dense.weight\n",
            "encoder.layer.3.attention.output.dense.bias\n",
            "encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "encoder.layer.3.attention.output.LayerNorm.beta\n",
            "encoder.layer.3.intermediate.dense.weight\n",
            "encoder.layer.3.intermediate.dense.bias\n",
            "encoder.layer.3.output.dense.weight\n",
            "encoder.layer.3.output.dense.bias\n",
            "encoder.layer.3.output.LayerNorm.gamma\n",
            "encoder.layer.3.output.LayerNorm.beta\n",
            "encoder.layer.4.attention.selfattn.query.weight\n",
            "encoder.layer.4.attention.selfattn.query.bias\n",
            "encoder.layer.4.attention.selfattn.key.weight\n",
            "encoder.layer.4.attention.selfattn.key.bias\n",
            "encoder.layer.4.attention.selfattn.value.weight\n",
            "encoder.layer.4.attention.selfattn.value.bias\n",
            "encoder.layer.4.attention.output.dense.weight\n",
            "encoder.layer.4.attention.output.dense.bias\n",
            "encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "encoder.layer.4.attention.output.LayerNorm.beta\n",
            "encoder.layer.4.intermediate.dense.weight\n",
            "encoder.layer.4.intermediate.dense.bias\n",
            "encoder.layer.4.output.dense.weight\n",
            "encoder.layer.4.output.dense.bias\n",
            "encoder.layer.4.output.LayerNorm.gamma\n",
            "encoder.layer.4.output.LayerNorm.beta\n",
            "encoder.layer.5.attention.selfattn.query.weight\n",
            "encoder.layer.5.attention.selfattn.query.bias\n",
            "encoder.layer.5.attention.selfattn.key.weight\n",
            "encoder.layer.5.attention.selfattn.key.bias\n",
            "encoder.layer.5.attention.selfattn.value.weight\n",
            "encoder.layer.5.attention.selfattn.value.bias\n",
            "encoder.layer.5.attention.output.dense.weight\n",
            "encoder.layer.5.attention.output.dense.bias\n",
            "encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "encoder.layer.5.attention.output.LayerNorm.beta\n",
            "encoder.layer.5.intermediate.dense.weight\n",
            "encoder.layer.5.intermediate.dense.bias\n",
            "encoder.layer.5.output.dense.weight\n",
            "encoder.layer.5.output.dense.bias\n",
            "encoder.layer.5.output.LayerNorm.gamma\n",
            "encoder.layer.5.output.LayerNorm.beta\n",
            "encoder.layer.6.attention.selfattn.query.weight\n",
            "encoder.layer.6.attention.selfattn.query.bias\n",
            "encoder.layer.6.attention.selfattn.key.weight\n",
            "encoder.layer.6.attention.selfattn.key.bias\n",
            "encoder.layer.6.attention.selfattn.value.weight\n",
            "encoder.layer.6.attention.selfattn.value.bias\n",
            "encoder.layer.6.attention.output.dense.weight\n",
            "encoder.layer.6.attention.output.dense.bias\n",
            "encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "encoder.layer.6.attention.output.LayerNorm.beta\n",
            "encoder.layer.6.intermediate.dense.weight\n",
            "encoder.layer.6.intermediate.dense.bias\n",
            "encoder.layer.6.output.dense.weight\n",
            "encoder.layer.6.output.dense.bias\n",
            "encoder.layer.6.output.LayerNorm.gamma\n",
            "encoder.layer.6.output.LayerNorm.beta\n",
            "encoder.layer.7.attention.selfattn.query.weight\n",
            "encoder.layer.7.attention.selfattn.query.bias\n",
            "encoder.layer.7.attention.selfattn.key.weight\n",
            "encoder.layer.7.attention.selfattn.key.bias\n",
            "encoder.layer.7.attention.selfattn.value.weight\n",
            "encoder.layer.7.attention.selfattn.value.bias\n",
            "encoder.layer.7.attention.output.dense.weight\n",
            "encoder.layer.7.attention.output.dense.bias\n",
            "encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "encoder.layer.7.attention.output.LayerNorm.beta\n",
            "encoder.layer.7.intermediate.dense.weight\n",
            "encoder.layer.7.intermediate.dense.bias\n",
            "encoder.layer.7.output.dense.weight\n",
            "encoder.layer.7.output.dense.bias\n",
            "encoder.layer.7.output.LayerNorm.gamma\n",
            "encoder.layer.7.output.LayerNorm.beta\n",
            "encoder.layer.8.attention.selfattn.query.weight\n",
            "encoder.layer.8.attention.selfattn.query.bias\n",
            "encoder.layer.8.attention.selfattn.key.weight\n",
            "encoder.layer.8.attention.selfattn.key.bias\n",
            "encoder.layer.8.attention.selfattn.value.weight\n",
            "encoder.layer.8.attention.selfattn.value.bias\n",
            "encoder.layer.8.attention.output.dense.weight\n",
            "encoder.layer.8.attention.output.dense.bias\n",
            "encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "encoder.layer.8.attention.output.LayerNorm.beta\n",
            "encoder.layer.8.intermediate.dense.weight\n",
            "encoder.layer.8.intermediate.dense.bias\n",
            "encoder.layer.8.output.dense.weight\n",
            "encoder.layer.8.output.dense.bias\n",
            "encoder.layer.8.output.LayerNorm.gamma\n",
            "encoder.layer.8.output.LayerNorm.beta\n",
            "encoder.layer.9.attention.selfattn.query.weight\n",
            "encoder.layer.9.attention.selfattn.query.bias\n",
            "encoder.layer.9.attention.selfattn.key.weight\n",
            "encoder.layer.9.attention.selfattn.key.bias\n",
            "encoder.layer.9.attention.selfattn.value.weight\n",
            "encoder.layer.9.attention.selfattn.value.bias\n",
            "encoder.layer.9.attention.output.dense.weight\n",
            "encoder.layer.9.attention.output.dense.bias\n",
            "encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "encoder.layer.9.attention.output.LayerNorm.beta\n",
            "encoder.layer.9.intermediate.dense.weight\n",
            "encoder.layer.9.intermediate.dense.bias\n",
            "encoder.layer.9.output.dense.weight\n",
            "encoder.layer.9.output.dense.bias\n",
            "encoder.layer.9.output.LayerNorm.gamma\n",
            "encoder.layer.9.output.LayerNorm.beta\n",
            "encoder.layer.10.attention.selfattn.query.weight\n",
            "encoder.layer.10.attention.selfattn.query.bias\n",
            "encoder.layer.10.attention.selfattn.key.weight\n",
            "encoder.layer.10.attention.selfattn.key.bias\n",
            "encoder.layer.10.attention.selfattn.value.weight\n",
            "encoder.layer.10.attention.selfattn.value.bias\n",
            "encoder.layer.10.attention.output.dense.weight\n",
            "encoder.layer.10.attention.output.dense.bias\n",
            "encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "encoder.layer.10.attention.output.LayerNorm.beta\n",
            "encoder.layer.10.intermediate.dense.weight\n",
            "encoder.layer.10.intermediate.dense.bias\n",
            "encoder.layer.10.output.dense.weight\n",
            "encoder.layer.10.output.dense.bias\n",
            "encoder.layer.10.output.LayerNorm.gamma\n",
            "encoder.layer.10.output.LayerNorm.beta\n",
            "encoder.layer.11.attention.selfattn.query.weight\n",
            "encoder.layer.11.attention.selfattn.query.bias\n",
            "encoder.layer.11.attention.selfattn.key.weight\n",
            "encoder.layer.11.attention.selfattn.key.bias\n",
            "encoder.layer.11.attention.selfattn.value.weight\n",
            "encoder.layer.11.attention.selfattn.value.bias\n",
            "encoder.layer.11.attention.output.dense.weight\n",
            "encoder.layer.11.attention.output.dense.bias\n",
            "encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "encoder.layer.11.attention.output.LayerNorm.beta\n",
            "encoder.layer.11.intermediate.dense.weight\n",
            "encoder.layer.11.intermediate.dense.bias\n",
            "encoder.layer.11.output.dense.weight\n",
            "encoder.layer.11.output.dense.bias\n",
            "encoder.layer.11.output.LayerNorm.gamma\n",
            "encoder.layer.11.output.LayerNorm.beta\n",
            "pooler.dense.weight\n",
            "pooler.dense.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 state_dict 구성\n",
        "# loaded_state_dict와 param_names는 파라미터들의 이름은 다르지만, 동일한 순서로 대응됨\n",
        "new_state_dict = net.state_dict().copy()\n",
        "for index, (key_name, value) in enumerate(loaded_state_dict.items()):\n",
        "    name = param_names[index]  # 현재 네트워크의 파라미터명을 취득\n",
        "    new_state_dict[name] = value  # 파라미터 값 삽입\n",
        "    print(str(key_name)+\" → \"+str(name)) \n",
        "\n",
        "    if index+1 >= len(param_names):\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBgrMUWUtDFK",
        "outputId": "17fc8983-cac4-45ed-f198-1ac49639572a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight → embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight → embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight → embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.gamma → embeddings.LayerNorm.gamma\n",
            "bert.embeddings.LayerNorm.beta → embeddings.LayerNorm.beta\n",
            "bert.encoder.layer.0.attention.self.query.weight → encoder.layer.0.attention.selfattn.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias → encoder.layer.0.attention.selfattn.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight → encoder.layer.0.attention.selfattn.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias → encoder.layer.0.attention.selfattn.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight → encoder.layer.0.attention.selfattn.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias → encoder.layer.0.attention.selfattn.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight → encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias → encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.gamma → encoder.layer.0.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.beta → encoder.layer.0.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.0.intermediate.dense.weight → encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias → encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight → encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias → encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.gamma → encoder.layer.0.output.LayerNorm.gamma\n",
            "bert.encoder.layer.0.output.LayerNorm.beta → encoder.layer.0.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.attention.self.query.weight → encoder.layer.1.attention.selfattn.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias → encoder.layer.1.attention.selfattn.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight → encoder.layer.1.attention.selfattn.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias → encoder.layer.1.attention.selfattn.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight → encoder.layer.1.attention.selfattn.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias → encoder.layer.1.attention.selfattn.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight → encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias → encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.gamma → encoder.layer.1.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.beta → encoder.layer.1.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.1.intermediate.dense.weight → encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias → encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight → encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias → encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.gamma → encoder.layer.1.output.LayerNorm.gamma\n",
            "bert.encoder.layer.1.output.LayerNorm.beta → encoder.layer.1.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.attention.self.query.weight → encoder.layer.2.attention.selfattn.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias → encoder.layer.2.attention.selfattn.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight → encoder.layer.2.attention.selfattn.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias → encoder.layer.2.attention.selfattn.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight → encoder.layer.2.attention.selfattn.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias → encoder.layer.2.attention.selfattn.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight → encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias → encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.gamma → encoder.layer.2.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.beta → encoder.layer.2.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.2.intermediate.dense.weight → encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias → encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight → encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias → encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.gamma → encoder.layer.2.output.LayerNorm.gamma\n",
            "bert.encoder.layer.2.output.LayerNorm.beta → encoder.layer.2.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.attention.self.query.weight → encoder.layer.3.attention.selfattn.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias → encoder.layer.3.attention.selfattn.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight → encoder.layer.3.attention.selfattn.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias → encoder.layer.3.attention.selfattn.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight → encoder.layer.3.attention.selfattn.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias → encoder.layer.3.attention.selfattn.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight → encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias → encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.gamma → encoder.layer.3.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.beta → encoder.layer.3.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.3.intermediate.dense.weight → encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias → encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight → encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias → encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.gamma → encoder.layer.3.output.LayerNorm.gamma\n",
            "bert.encoder.layer.3.output.LayerNorm.beta → encoder.layer.3.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.attention.self.query.weight → encoder.layer.4.attention.selfattn.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias → encoder.layer.4.attention.selfattn.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight → encoder.layer.4.attention.selfattn.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias → encoder.layer.4.attention.selfattn.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight → encoder.layer.4.attention.selfattn.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias → encoder.layer.4.attention.selfattn.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight → encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias → encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.gamma → encoder.layer.4.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.beta → encoder.layer.4.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.4.intermediate.dense.weight → encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias → encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight → encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias → encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.gamma → encoder.layer.4.output.LayerNorm.gamma\n",
            "bert.encoder.layer.4.output.LayerNorm.beta → encoder.layer.4.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.attention.self.query.weight → encoder.layer.5.attention.selfattn.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias → encoder.layer.5.attention.selfattn.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight → encoder.layer.5.attention.selfattn.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias → encoder.layer.5.attention.selfattn.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight → encoder.layer.5.attention.selfattn.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias → encoder.layer.5.attention.selfattn.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight → encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias → encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.gamma → encoder.layer.5.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.beta → encoder.layer.5.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.5.intermediate.dense.weight → encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias → encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight → encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias → encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.gamma → encoder.layer.5.output.LayerNorm.gamma\n",
            "bert.encoder.layer.5.output.LayerNorm.beta → encoder.layer.5.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.attention.self.query.weight → encoder.layer.6.attention.selfattn.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias → encoder.layer.6.attention.selfattn.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight → encoder.layer.6.attention.selfattn.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias → encoder.layer.6.attention.selfattn.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight → encoder.layer.6.attention.selfattn.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias → encoder.layer.6.attention.selfattn.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight → encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias → encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.gamma → encoder.layer.6.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.beta → encoder.layer.6.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.6.intermediate.dense.weight → encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias → encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight → encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias → encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.gamma → encoder.layer.6.output.LayerNorm.gamma\n",
            "bert.encoder.layer.6.output.LayerNorm.beta → encoder.layer.6.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.attention.self.query.weight → encoder.layer.7.attention.selfattn.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias → encoder.layer.7.attention.selfattn.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight → encoder.layer.7.attention.selfattn.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias → encoder.layer.7.attention.selfattn.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight → encoder.layer.7.attention.selfattn.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias → encoder.layer.7.attention.selfattn.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight → encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias → encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.gamma → encoder.layer.7.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.beta → encoder.layer.7.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.7.intermediate.dense.weight → encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias → encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight → encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias → encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.gamma → encoder.layer.7.output.LayerNorm.gamma\n",
            "bert.encoder.layer.7.output.LayerNorm.beta → encoder.layer.7.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.attention.self.query.weight → encoder.layer.8.attention.selfattn.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias → encoder.layer.8.attention.selfattn.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight → encoder.layer.8.attention.selfattn.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias → encoder.layer.8.attention.selfattn.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight → encoder.layer.8.attention.selfattn.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias → encoder.layer.8.attention.selfattn.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight → encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias → encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.gamma → encoder.layer.8.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.beta → encoder.layer.8.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.8.intermediate.dense.weight → encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias → encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight → encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias → encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.gamma → encoder.layer.8.output.LayerNorm.gamma\n",
            "bert.encoder.layer.8.output.LayerNorm.beta → encoder.layer.8.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.attention.self.query.weight → encoder.layer.9.attention.selfattn.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias → encoder.layer.9.attention.selfattn.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight → encoder.layer.9.attention.selfattn.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias → encoder.layer.9.attention.selfattn.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight → encoder.layer.9.attention.selfattn.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias → encoder.layer.9.attention.selfattn.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight → encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias → encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.gamma → encoder.layer.9.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.beta → encoder.layer.9.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.9.intermediate.dense.weight → encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias → encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight → encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias → encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.gamma → encoder.layer.9.output.LayerNorm.gamma\n",
            "bert.encoder.layer.9.output.LayerNorm.beta → encoder.layer.9.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.attention.self.query.weight → encoder.layer.10.attention.selfattn.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias → encoder.layer.10.attention.selfattn.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight → encoder.layer.10.attention.selfattn.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias → encoder.layer.10.attention.selfattn.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight → encoder.layer.10.attention.selfattn.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias → encoder.layer.10.attention.selfattn.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight → encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias → encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.gamma → encoder.layer.10.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.beta → encoder.layer.10.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.10.intermediate.dense.weight → encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias → encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight → encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias → encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.gamma → encoder.layer.10.output.LayerNorm.gamma\n",
            "bert.encoder.layer.10.output.LayerNorm.beta → encoder.layer.10.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.attention.self.query.weight → encoder.layer.11.attention.selfattn.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias → encoder.layer.11.attention.selfattn.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight → encoder.layer.11.attention.selfattn.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias → encoder.layer.11.attention.selfattn.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight → encoder.layer.11.attention.selfattn.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias → encoder.layer.11.attention.selfattn.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight → encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias → encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.gamma → encoder.layer.11.attention.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.beta → encoder.layer.11.attention.output.LayerNorm.beta\n",
            "bert.encoder.layer.11.intermediate.dense.weight → encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias → encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight → encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias → encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.gamma → encoder.layer.11.output.LayerNorm.gamma\n",
            "bert.encoder.layer.11.output.LayerNorm.beta → encoder.layer.11.output.LayerNorm.beta\n",
            "bert.pooler.dense.weight → pooler.dense.weight\n",
            "bert.pooler.dense.bias → pooler.dense.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 state_dict를 BERT 모델에 제공\n",
        "net.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7DVnbxYwUVE",
        "outputId": "c5a742df-6b71-4c11-e63d-9afe1f79b41f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.1 BERT용 Tokenizer"
      ],
      "metadata": {
        "id": "ApShVsDI0hwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "def load_vocab(vocab_file):\n",
        "    \"\"\"text 형식의 vocab 파일의 내용을 사전에 저장\"\"\"\n",
        "    \n",
        "    vocab = collections.OrderedDict()  # (단어, id) 순서의 사전 변수 (ordered_dict)\n",
        "    ids_to_tokens = collections.OrderedDict()  # (id, 단어) 순서의 사전 변수\n",
        "    \n",
        "    index = 0\n",
        "    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n",
        "        while True:\n",
        "            token = reader.readline()\n",
        "            if not token:\n",
        "                break\n",
        "            token = token.strip()\n",
        "\n",
        "            # 저장\n",
        "            vocab[token] = index\n",
        "            ids_to_tokens[index] = token\n",
        "            index += 1\n",
        "\n",
        "    return vocab, ids_to_tokens"
      ],
      "metadata": {
        "id": "u-X4xnkwxNVk"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_file = \"./vocab/bert-base-uncased-vocab.txt\"\n",
        "vocab, ids_to_tokens = load_vocab(vocab_file)"
      ],
      "metadata": {
        "id": "-aKY2CoBxVCJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vocab"
      ],
      "metadata": {
        "id": "w1q1XkkMxVTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ids_to_tokens"
      ],
      "metadata": {
        "id": "fdAibQSPxgm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.2 단어 Bank의 문맥에 따른 의미 변화를 벡터 표현으로 계산"
      ],
      "metadata": {
        "id": "y7CcXfkr0p2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gymoon10/utils.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jsc9l-wyO4Z",
        "outputId": "6778013a-160b-4c5c-f13c-079a147ea2a3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'utils'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 47 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (47/47), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.tokenizer import BasicTokenizer, WordpieceTokenizer\n",
        "\n",
        "# BasicTokenizer, WordpieceTokenizer는, 참고 문헌[2] 그대로입니다\n",
        "# https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/pytorch_pretrained_bert/tokenization.py\n",
        "# sub-word로 단어 분할을 실시하는 클래스들입니다.\n",
        "class BertTokenizer(object):\n",
        "    '''BERT용의 문장 단어 분할 클래스를 구현'''\n",
        "\n",
        "    def __init__(self, vocab_file, do_lower_case=True):\n",
        "        '''\n",
        "        vocab_file: vocabulary에의 경로\n",
        "        do_lower_case: 전처리에서 단어를 소문자로 바꾸는지 여부\n",
        "        '''\n",
        "\n",
        "        # vocabulary의 로드\n",
        "        self.vocab, self.ids_to_tokens = load_vocab(vocab_file)\n",
        "\n",
        "        # 분할 처리 함수를 \"utils\" 폴더에서 imoprt, sub-word로 단어 분할을 실시\n",
        "        never_split = (\"[UNK]\", \"[SEP]\", \"[PAD]\", \"[CLS]\", \"[MASK]\")\n",
        "        # (주석)위 단어는 도중에 분할하지 않는다. 이를 통해 하나의 단어로 간주함\n",
        "\n",
        "        self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case,\n",
        "                                              never_split=never_split)\n",
        "        self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        '''문장의 단어를 분할하는 함수'''\n",
        "        split_tokens = []  # 분할 후 단어들\n",
        "        for token in self.basic_tokenizer.tokenize(text):\n",
        "            for sub_token in self.wordpiece_tokenizer.tokenize(token):\n",
        "                split_tokens.append(sub_token)\n",
        "        return split_tokens\n",
        "\n",
        "    def convert_tokens_to_ids(self, tokens):\n",
        "        \"\"\"분할된 단어 목록을 ID로 변환하는 함수\"\"\"\n",
        "        ids = []\n",
        "        for token in tokens:\n",
        "            ids.append(self.vocab[token])\n",
        "\n",
        "        return ids\n",
        "\n",
        "    def convert_ids_to_tokens(self, ids):\n",
        "        \"\"\"ID를 단어로 변환하는 함수\"\"\"\n",
        "        tokens = []\n",
        "        for i in ids:\n",
        "            tokens.append(self.ids_to_tokens[i])\n",
        "        return tokens"
      ],
      "metadata": {
        "id": "IQyWvM27xiSs"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq_length=8\n",
        "text_1 = \"[CLS] I accessed the bank account. [SEP]\"\n",
        "text_2 = \"[CLS] He transferred the deposit money into the bank account. [SEP]\"\n",
        "text_3 = \"[CLS] We play soccer at the bank of the river. [SEP]\"\n",
        "\n",
        "# Load Tokenizer\n",
        "tokenizer = BertTokenizer(\n",
        "    vocab_file=\"./vocab/bert-base-uncased-vocab.txt\", do_lower_case=True)\n",
        "\n",
        "# Tokenization\n",
        "tokenized_text_1 = tokenizer.tokenize(text_1)\n",
        "tokenized_text_2 = tokenizer.tokenize(text_2)\n",
        "tokenized_text_3 = tokenizer.tokenize(text_3)\n",
        "\n",
        "# 확인\n",
        "print(tokenized_text_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9kbLecBy7Fn",
        "outputId": "a6b538ca-5a0d-4fd3-807b-7d89beb7542a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'i', 'accessed', 'the', 'bank', 'account', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indexed_tokens_1 = tokenizer.convert_tokens_to_ids(tokenized_text_1)\n",
        "indexed_tokens_2 = tokenizer.convert_tokens_to_ids(tokenized_text_2)\n",
        "indexed_tokens_3 = tokenizer.convert_tokens_to_ids(tokenized_text_3)\n",
        "\n",
        "# 각 문장에서 bank의 위치\n",
        "bank_posi_1 = np.where(np.array(tokenized_text_1) == \"bank\")[0][0]  # 4\n",
        "bank_posi_2 = np.where(np.array(tokenized_text_2) == \"bank\")[0][0]  # 8\n",
        "bank_posi_3 = np.where(np.array(tokenized_text_3) == \"bank\")[0][0]  # 6\n",
        "\n",
        "# list -> tensor\n",
        "tokens_tensor_1 = torch.tensor([indexed_tokens_1])\n",
        "tokens_tensor_2 = torch.tensor([indexed_tokens_2])\n",
        "tokens_tensor_3 = torch.tensor([indexed_tokens_3])\n",
        "\n",
        "# bank의 단어 id\n",
        "bank_word_id = tokenizer.convert_tokens_to_ids([\"bank\"])[0]\n",
        "\n",
        "# 확인\n",
        "print(tokens_tensor_1)\n",
        "print(tokens_tensor_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4qJAOhuzEKN",
        "outputId": "159a9532-2d07-4a01-db0d-44be3c822547"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  1045, 11570,  1996,  2924,  4070,  1012,   102]])\n",
            "tensor([[  101,  2002,  4015,  1996, 12816,  2769,  2046,  1996,  2924,  4070,\n",
            "          1012,   102]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장을 BERT로 처리\n",
        "with torch.no_grad():  # inference\n",
        "    encoded_layers_1, _ = net(tokens_tensor_1, output_all_encoded_layers=True)\n",
        "    encoded_layers_2, _ = net(tokens_tensor_2, output_all_encoded_layers=True)\n",
        "    encoded_layers_3, _ = net(tokens_tensor_3, output_all_encoded_layers=True)"
      ],
      "metadata": {
        "id": "4_M_UqimzGRv"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(encoded_layers_1))\n",
        "print(encoded_layers_1[0].shape)  # [batch, seq_length, hidden]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEj20W9DzrYO",
        "outputId": "2001333c-d207-4a44-a65b-17a268aebdde"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "torch.Size([1, 8, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bank_vector_0 = net.embeddings.word_embeddings.weight[bank_word_id]\n",
        "\n",
        "# 문장1의 BertEncoder의 첫 번째 BertLayer의 출력\n",
        "bank_vector_1_1 = encoded_layers_1[0][0, bank_posi_1]\n",
        "\n",
        "# 문장1의 BertEncoder의 최종 12 번째 BertLayer의 출력\n",
        "bank_vector_1_12 = encoded_layers_1[11][0, bank_posi_1]\n",
        "\n",
        "# 문장2, 3도 마찬가지로 적용\n",
        "bank_vector_2_1 = encoded_layers_2[0][0, bank_posi_2]\n",
        "bank_vector_2_12 = encoded_layers_2[11][0, bank_posi_2]\n",
        "bank_vector_3_1 = encoded_layers_3[0][0, bank_posi_3]\n",
        "bank_vector_3_12 = encoded_layers_3[11][0, bank_posi_3]"
      ],
      "metadata": {
        "id": "_vGY2bRizKJ3"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bank_vector_1_12.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_xMMnRCz7kY",
        "outputId": "6f674259-8e7b-4470-c837-6df5bf1f2c9d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"bank의 초기 벡터와 문장1의 1단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_0, bank_vector_1_1, dim=0))\n",
        "print(\"bank의 초기 벡터와 문장1의 12단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_0, bank_vector_1_12, dim=0))\n",
        "\n",
        "print(\"문장1의 1층 bank와 문장2의 1단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_1_1, bank_vector_2_1, dim=0))\n",
        "print(\"문장1의 1층 bank와 문장3의 1단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_1_1, bank_vector_3_1, dim=0))\n",
        "\n",
        "print(\"문장1의 12층 bank와 문장2의 12단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_1_12, bank_vector_2_12, dim=0))\n",
        "print(\"문장1의 12층 bank와 문장3의 12단 bank의 유사도: \",\n",
        "      F.cosine_similarity(bank_vector_1_12, bank_vector_3_12, dim=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63dYV1IqzLtp",
        "outputId": "0bc6eaf4-67fa-450a-82b1-50736c6772ec"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bank의 초기 벡터와 문장1의 1단 bank의 유사도:  tensor(0.6814, grad_fn=<DivBackward0>)\n",
            "bank의 초기 벡터와 문장1의 12단 bank의 유사도:  tensor(0.2276, grad_fn=<DivBackward0>)\n",
            "문장1의 1층 bank와 문장2의 1단 bank의 유사도:  tensor(0.8968)\n",
            "문장1의 1층 bank와 문장3의 1단 bank의 유사도:  tensor(0.7584)\n",
            "문장1의 12층 bank와 문장2의 12단 bank의 유사도:  tensor(0.8796)\n",
            "문장1의 12층 bank와 문장3의 12단 bank의 유사도:  tensor(0.4814)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QhDomRsw2M2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jvk90EQVzNYv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}