{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_MLM&NSP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Setting\n",
        "\n",
        "BERT.ipynb와 동일"
      ],
      "metadata": {
        "id": "GXp4H2Hj9F0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile\n",
        "import glob\n",
        "import io"
      ],
      "metadata": {
        "id": "yZDCTRlk9Ef7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "# vocab\n",
        "vocab_dir = \"./vocab/\"\n",
        "if not os.path.exists(vocab_dir):\n",
        "    os.mkdir(vocab_dir)\n",
        "\n",
        "save_path=\"./vocab/bert-base-uncased-vocab.txt\"\n",
        "url = \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt\"\n",
        "urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "\n",
        "# weights\n",
        "weights_dir = \"./weights/\"\n",
        "if not os.path.exists(weights_dir):\n",
        "    os.mkdir(weights_dir)\n",
        "\n",
        "save_path = \"./weights/bert-base-uncased.tar.gz\"\n",
        "url = \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz\"\n",
        "urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "archive_file = \"./weights/bert-base-uncased.tar.gz\"  \n",
        "tar = tarfile.open(archive_file, 'r:gz')\n",
        "tar.extractall('./weights/')  \n",
        "tar.close()"
      ],
      "metadata": {
        "id": "nB4uDzYk8I-0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Config\n",
        "config_file = \"./weights/bert_config.json\"\n",
        "\n",
        "json_file = open(config_file, 'r')\n",
        "config = json.load(json_file)\n",
        "\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgUd5ABV8JEU",
        "outputId": "f652a3cc-15ed-4c31-f6dc-ce5e854133c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_probs_dropout_prob': 0.1,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'max_position_embeddings': 512,\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'type_vocab_size': 2,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BertLayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, eps=1e-12):\n",
        "        super(BertLayerNorm, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(hidden_size))  \n",
        "        self.beta = nn.Parameter(torch.zeros(hidden_size))  \n",
        "        self.variance_epsilon = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = x.mean(-1, keepdim=True)\n",
        "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "        \n",
        "        return self.gamma * x + self.beta"
      ],
      "metadata": {
        "id": "tnFA0KW58JJm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gelu(x):\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))"
      ],
      "metadata": {
        "id": "_AvRVSeA8JME"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QcQLne4C8JRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "cfcAGISi5Fpe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 사전 학습 과제 - Masked Language Model                  "
      ],
      "metadata": {
        "id": "V6B5ilpL5sI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedWordPredictions(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(MaskedWordPredictions, self).__init__()\n",
        "\n",
        "        # BERT 출력 변환 모듈\n",
        "        self.transform = BertPredictionHeadTransform(config)\n",
        "\n",
        "        # self.transform의 출력을 입력으로 받아, 각 위치의 단어가 어떤 것인지 맞추는 F.C layer\n",
        "        self.decoder = nn.Linear(in_features=config.hidden_size,  # 768\n",
        "                                 out_features=config.vocab_size, bias=False)  # 30522\n",
        "        self.bias = nn.Parameter(torch.zeros(config.vocab_size))  # 30522\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        '''\n",
        "        hidden_states: BERT 모델의 출력 [batch_size, seq_len, hidden_size]\n",
        "        '''\n",
        "        # 출력 변환\n",
        "        hidden_states = self.transform(hidden_states)\n",
        "        \n",
        "        # 각 위치의 단어가 vocab의 어느 단어에 해당하는지 클래스 분류 수행\n",
        "        hidden_states = self.decoder(hidden_states) + self.bias  \n",
        "\n",
        "        return hidden_states  # [batch, seq_len, vocab_size]\n",
        "\n",
        "class BertPredictionHeadTransform(nn.Module):\n",
        "    '''MaskedWordPredictions에서, BERT의 출력을 변환 (입출력 크기는 동일)'''\n",
        "    def __init__(self, config):\n",
        "        super(BertPredictionHeadTransform, self).__init__()\n",
        "        \n",
        "        # F.C layer\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)  # nn.Linear(768, 768)\n",
        "        \n",
        "        # GeLU\n",
        "        self.transform_act_fn = gelu\n",
        "\n",
        "        # LayerNormalization\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = self.transform_act_fn(hidden_states)\n",
        "        hidden_states = self.LayerNorm(hidden_states)\n",
        "        \n",
        "        return hidden_states                               "
      ],
      "metadata": {
        "id": "lxe7R5qQ5G6e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 사전 학습 과제 - Next Sentence Prediction\n",
        "\n",
        "BERT.ipynb의 5. BertPooler의 출력(입력 문장의 첫 번째 단어 [CLS]토큰의 벡터 representation - [batch, hidden])을 입력으로 받음"
      ],
      "metadata": {
        "id": "qWGY2H2i9VnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SeqRelationship(nn.Module):\n",
        "    def __init__(self, config, out_features):\n",
        "        super(SeqRelationship, self).__init__()\n",
        "        self.seq_relationship = nn.Linear(config.hidden_size, out_features)  # (768, 2) - 다음 문장인지 아닌 지\n",
        "\n",
        "    def forward(self, pooled_output):\n",
        "        return self.seq_relationship(pooled_output)"
      ],
      "metadata": {
        "id": "aUPJKJJ09U1n"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. BertPreTrainingHeads\n",
        "\n",
        "BERT의 사전 학습 과제 1, 2를 수행하는 어댑터 모듈"
      ],
      "metadata": {
        "id": "C4Mm7AE1_ObP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertPreTrainingHeads(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertPreTrainingHeads, self).__init__()\n",
        "        \n",
        "        # 사전 학습 과제 1 - MLM 수행 모듈\n",
        "        self.predictions = MaskedWordPredictions(config)  # vocab의 어느 단어에 해당하는지\n",
        "\n",
        "        # 사전 학습 과제 2 - NSP 수행 모듈\n",
        "        self.seq_relationship = SeqRelationship(config, out_features=2)  # 다음 문장인지, 아닌지\n",
        "\n",
        "    def forward(self, sequence_output, pooled_output):\n",
        "        '''\n",
        "        sequence_output : [batch_size, seq_len, hidden_size]\n",
        "        pooled_output : [batch_size, hidden_size] - [CLS] 토큰의 feature\n",
        "        '''\n",
        "        # 입력 문장의 masking된 각 단어가 vocab의 어떤 단어인지 판정\n",
        "        prediction_scores = self.predictions(sequence_output)  # [batch_size, seq_len, vocab_size=30522]\n",
        "        \n",
        "        # [CLS] 토큰에 대한 feature를 통해 1번째, 2번째 문장이 연결되어 있는 지 판정\n",
        "        seq_relationship_score = self.seq_relationship(pooled_output)  # [batch, 2]\n",
        "\n",
        "        return prediction_scores, seq_relationship_score"
      ],
      "metadata": {
        "id": "-nRBi0Cy-9kx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. BERT 모델에 연결\n",
        "\n",
        "BERT 모델에 사전 학습 과제용 어댑터 모듈 BertPreTrainingHeads 연결"
      ],
      "metadata": {
        "id": "4QwVUDCpDwZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertForMaskedLM(nn.Module):\n",
        "\n",
        "    def __init__(self, config, net_bert):\n",
        "        super(BertForMaskedLM, self).__init__()\n",
        "\n",
        "        # BERT 모델\n",
        "        self.bert = net_bert\n",
        "\n",
        "        # 사전 학습 과제용 어댑터 모듈\n",
        "        self.cls = BertPreTrainingHeads(config)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
        "        '''\n",
        "        input_ids:  [batch_size, seq_length] 문장의 단어 ID 나열\n",
        "        token_type_ids:  [batch_size, seq_length] 각 단어가 1번째 문장인지, 2번째 문장인지를 나타내는 id\n",
        "        attention_mask: masking\n",
        "        '''\n",
        "        # BERT 모델의 forward\n",
        "        encoded_layers, pooled_output = self.bert(  # 마지막 12번째 layer의 hidden_state, [CLS] 토큰의 hidden_state 반환\n",
        "            input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False, attention_show_flg=False)\n",
        "        \n",
        "        # 사전 학습 과제 수행\n",
        "        prediction_scores, seq_relationship_score = self.cls(\n",
        "            encoded_layers, pooled_output)\n",
        "        \n",
        "        return prediction_scores, seq_relationship_score"
      ],
      "metadata": {
        "id": "Lkpti1TwBXWC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lOFyN-pUELwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 학습된 BERT 모델 load"
      ],
      "metadata": {
        "id": "j6cd7ne2FqNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gymoon10/utils.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQfi5pHyEL4v",
        "outputId": "4416132a-04df-447e-fce0-5392a1d0f6f6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'utils'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 47 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (47/47), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install attrdict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE1ZgIOjEd1i",
        "outputId": "fd9af29e-2959-4ab8-98ed-b494649324da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting attrdict\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from attrdict) (1.15.0)\n",
            "Installing collected packages: attrdict\n",
            "Successfully installed attrdict-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.bert import get_config, BertModel, BertTokenizer"
      ],
      "metadata": {
        "id": "Oc5ad8AtFB2l"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = get_config(\"./weights/bert_config.json\")\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yEmWU6ZFEn9",
        "outputId": "16f88b69-3781-4eb9-d2f8-43e78bafc8c9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttrDict({'attention_probs_dropout_prob': 0.1, 'hidden_act': 'gelu', 'hidden_dropout_prob': 0.1, 'hidden_size': 768, 'initializer_range': 0.02, 'intermediate_size': 3072, 'max_position_embeddings': 512, 'num_attention_heads': 12, 'num_hidden_layers': 12, 'type_vocab_size': 2, 'vocab_size': 30522})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT 모델\n",
        "net_bert = BertModel(config)\n",
        "net_bert.eval()\n",
        "\n",
        "# BERT 모델에 사전 학습 과제용 어댑터 모듈 탑재\n",
        "net = BertForMaskedLM(config, net_bert)\n",
        "net.eval()\n",
        "\n",
        "# 학습된 가중치 로드\n",
        "weights_path = \"./weights/pytorch_model.bin\"\n",
        "loaded_state_dict = torch.load(weights_path)\n",
        "\n",
        "\n",
        "param_names = []  \n",
        "for name, param in net.named_parameters():\n",
        "    param_names.append(name)\n",
        "\n",
        "new_state_dict = net.state_dict().copy()\n",
        "for index, (key_name, value) in enumerate(loaded_state_dict.items()):\n",
        "    name = param_names[index]  \n",
        "    new_state_dict[name] = value \n",
        "   # print(str(key_name)+\"→\"+str(name))  \n",
        "\n",
        "    if index+1 >= len(param_names):\n",
        "        break\n",
        "\n",
        "# 새로운 state_dict를 BERT 모델에 제공\n",
        "net.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zs8SyFvD47B",
        "outputId": "e17e6a5b-e2b9-4cb1-b09f-92f53e3f99a2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. MLM 수행"
      ],
      "metadata": {
        "id": "kJ4O3rLmFzfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"[CLS] I accessed the bank account. [SEP] We play soccer at the bank of the river. [SEP]\"\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = BertTokenizer(\n",
        "    vocab_file=\"./vocab/bert-base-uncased-vocab.txt\", do_lower_case=True)\n",
        "\n",
        "# Tokenize\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URK2XIveE2VE",
        "outputId": "dc8ceee6-783b-4b25-92c7-8a6aafd120bf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'i', 'accessed', 'the', 'bank', 'account', '.', '[SEP]', 'we', 'play', 'soccer', 'at', 'the', 'bank', 'of', 'the', 'river', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# masking (13번째 단어)\n",
        "masked_index = 13\n",
        "tokenized_text[masked_index] = '[MASK]'\n",
        "\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMsolBy0GCta",
        "outputId": "ce7e63f8-064d-42b8-e78a-3e50ecf76b77"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'i', 'accessed', 'the', 'bank', 'account', '.', '[SEP]', 'we', 'play', 'soccer', 'at', 'the', '[MASK]', 'of', 'the', 'river', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "print(indexed_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1wXv4W_GHfj",
        "outputId": "84607613-f92b-4d25-84f4-4b53fe795af5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1045, 11570, 1996, 2924, 4070, 1012, 102, 2057, 2377, 4715, 2012, 1996, 103, 1997, 1996, 2314, 1012, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seq2id(indexed_tokens):\n",
        "    '''띄어쓰기된 단어 ID열을 문장 ID로. [SEP]으로 나누기'''\n",
        "    segments_ids = []\n",
        "    seq_id = 0\n",
        "\n",
        "    for word_id in indexed_tokens:\n",
        "        segments_ids.append(seq_id)  # seq_id=o or 1을 추가\n",
        "\n",
        "        # [SEP]를 발견하면 2번째 문장이 되므로 이후 id를 1로\n",
        "        if word_id == 102:  # ID 102가 [SEP]이다\n",
        "            seq_id = 1\n",
        "\n",
        "    return segments_ids\n",
        "\n",
        "segments_ids = seq2id(indexed_tokens)\n",
        "print(segments_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvLpfCYgGJ6N",
        "outputId": "701448d7-045f-490c-8c93-b59612838696"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서 변환\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "# Inference\n",
        "with torch.no_grad():\n",
        "    prediction_scores, seq_relationship_score = net(tokens_tensor, segments_tensors)\n",
        "\n",
        "# ID -> 단어\n",
        "predicted_index = torch.argmax(prediction_scores[0, masked_index]).item()\n",
        "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
        "print(predicted_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocjNmCbkGOW9",
        "outputId": "e7bca5c2-cbf3-4471-f64e-1a7fd778c081"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. NSP 수행\n",
        "\n",
        "클래스 0 : 두 문장이 연속 (의미를 가짐)\n",
        "\n",
        "클래스 1 : 두 문장은 서로 관계가 없음"
      ],
      "metadata": {
        "id": "zuFFsw1AGrVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text = \"[CLS] I accessed the bank account. [SEP] We play soccer at the bank of the river. [SEP]\"\n",
        "print(seq_relationship_score)\n",
        "print(torch.sigmoid(seq_relationship_score))  # 클래스 1 (NSP를 제대로 수행)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBFcpPO_GZrk",
        "outputId": "66597d80-4af6-4ad7-a20e-eb455bed0348"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5349,  3.1654]])\n",
            "tensor([[0.1773, 0.9595]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tnsvvx8QGvUC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}