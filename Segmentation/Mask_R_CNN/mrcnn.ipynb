{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mrcnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt6zSLge9YMX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.model_zoo import load_url\n",
        "from torchvision import models\n",
        "from torchvision.ops import misc"
      ],
      "metadata": {
        "id": "hEtZ9HdO9esb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Okery/PyTorch-Simple-MaskRCNN.git mrcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmfThWCE9fdd",
        "outputId": "43f59217-0b08-4eca-9e69-dd7bf2b34ec8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mrcnn'...\n",
            "remote: Enumerating objects: 840, done.\u001b[K\n",
            "remote: Counting objects: 100% (153/153), done.\u001b[K\n",
            "remote: Compressing objects: 100% (152/152), done.\u001b[K\n",
            "remote: Total 840 (delta 88), reused 2 (delta 0), pack-reused 687\u001b[K\n",
            "Receiving objects: 100% (840/840), 4.78 MiB | 22.44 MiB/s, done.\n",
            "Resolving deltas: 100% (485/485), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modules\n",
        "from mrcnn.pytorch_mask_rcnn.model.utils import AnchorGenerator\n",
        "from mrcnn.pytorch_mask_rcnn.model.rpn import RPNHead, RegionProposalNetwork\n",
        "from mrcnn.pytorch_mask_rcnn.model.pooler import RoIAlign\n",
        "from mrcnn.pytorch_mask_rcnn.model.roi_heads import RoIHeads\n",
        "from mrcnn.pytorch_mask_rcnn.model.transform import Transformer"
      ],
      "metadata": {
        "id": "B1sXXcEc9t2k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet Backbone\n",
        "class ResBackbone(nn.Module):\n",
        "    def __init__(self, backbone_name, pretrained):\n",
        "        super().__init__()\n",
        "        body = models.resnet.__dict__[backbone_name](\n",
        "            pretrained=pretrained, norm_layer=misc.FrozenBatchNorm2d)\n",
        "        \n",
        "        for name, parameter in body.named_parameters():\n",
        "            if 'layer2' not in name and 'layer3' not in name and 'layer4' not in name:\n",
        "                parameter.requires_grad_(False)\n",
        "                \n",
        "        self.body = nn.ModuleDict(d for i, d in enumerate(body.named_children()) if i < 8)\n",
        "        in_channels = 2048\n",
        "        self.out_channels = 256\n",
        "        \n",
        "        self.inner_block_module = nn.Conv2d(in_channels, self.out_channels, 1)\n",
        "        self.layer_block_module = nn.Conv2d(self.out_channels, self.out_channels, 3, 1, 1)\n",
        "        \n",
        "        for m in self.children():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_uniform_(m.weight, a=1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for module in self.body.values():\n",
        "            x = module(x)\n",
        "        x = self.inner_block_module(x)\n",
        "        x = self.layer_block_module(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZhRLcS0NLeFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskRCNN(nn.Module):\n",
        "    def __init__(self, backbone, num_classes,\n",
        "                 # RPN parameters\n",
        "                 rpn_fg_iou_thresh=0.7, rpn_bg_iou_thresh=0.3,\n",
        "                 rpn_num_samples=256, rpn_positive_fraction=0.5,\n",
        "                 rpn_reg_weights=(1., 1., 1., 1.),\n",
        "                 rpn_pre_nms_top_n_train=2000, rpn_pre_nms_top_n_test=1000,\n",
        "                 rpn_post_nms_top_n_train=2000, rpn_post_nms_top_n_test=1000,\n",
        "                 rpn_nms_thresh=0.7,\n",
        "                 # RoIHeads parameters\n",
        "                 box_fg_iou_thresh=0.5, box_bg_iou_thresh=0.5,\n",
        "                 box_num_samples=512, box_positive_fraction=0.25,\n",
        "                 box_reg_weights=(10., 10., 5., 5.),\n",
        "                 box_score_thresh=0.1, box_nms_thresh=0.6, box_num_detections=100):\n",
        "      \n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        out_channels = backbone.out_channels\n",
        "        \n",
        "        #------------- RPN --------------------------\n",
        "        # 1. Anchor Generator\n",
        "        anchor_sizes = (128, 256, 512)\n",
        "        anchor_ratios = (0.5, 1, 2)\n",
        "        num_anchors = len(anchor_sizes) * len(anchor_ratios)\n",
        "        rpn_anchor_generator = AnchorGenerator(anchor_sizes, anchor_ratios)\n",
        "        \n",
        "        # 2. RPN Head\n",
        "        rpn_head = RPNHead(out_channels, num_anchors)\n",
        "        \n",
        "        rpn_pre_nms_top_n = dict(training=rpn_pre_nms_top_n_train, testing=rpn_pre_nms_top_n_test)  # 남겨둘 proposal의 수 (NMS 전)\n",
        "        rpn_post_nms_top_n = dict(training=rpn_post_nms_top_n_train, testing=rpn_post_nms_top_n_test)  # 남겨둘 proposal의 수 (NMS 후)\n",
        "\n",
        "        # 3. Region Proposal Network - 최적의 region proposal(RoI) bbox 반환\n",
        "        self.rpn = RegionProposalNetwork(\n",
        "             rpn_anchor_generator, rpn_head,  # anchor generator, RPN head (분류 logits, bbox 출력)\n",
        "             rpn_fg_iou_thresh, rpn_bg_iou_thresh,  # IOU ths (fg: pos / bg: neg)\n",
        "             rpn_num_samples, rpn_positive_fraction,  # 샘플링한 anchor 수, pos/neg 비율\n",
        "             rpn_reg_weights,\n",
        "             rpn_pre_nms_top_n, rpn_post_nms_top_n, rpn_nms_thresh)\n",
        "        \n",
        "        #------------ RoIHeads --------------------------\n",
        "        box_roi_pool = RoIAlign(output_size=(7, 7), sampling_ratio=2)  # 7x7의 고정된 크기로 align (detection)\n",
        "        \n",
        "        # 1. Class branch\n",
        "        resolution = box_roi_pool.output_size[0]\n",
        "        in_channels = out_channels * resolution ** 2\n",
        "        mid_channels = 1024\n",
        "        box_predictor = FastRCNNPredictor(in_channels, mid_channels, num_classes)  # detection (objectness score, bbox)\n",
        "        \n",
        "        # 2. Mask branch\n",
        "        self.head = RoIHeads(\n",
        "             box_roi_pool, box_predictor,  # feature map에 대해 RPN proposal을 바탕으로 pooling & mask prediction\n",
        "             box_fg_iou_thresh, box_bg_iou_thresh,  # IOU ths (fg: pos / bg: neg)\n",
        "             box_num_samples, box_positive_fraction,  # 샘플링한 proposal 수, pos/neg 비율\n",
        "             box_reg_weights,\n",
        "             box_score_thresh, box_nms_thresh, box_num_detections)  # 분류 score가 box_score_thresh보다 큰 proposal에 대해서만 inference\n",
        "        \n",
        "        self.head.mask_roi_pool = RoIAlign(output_size=(14, 14), sampling_ratio=2)  # 14x14의 고정된 크기로 align (mask)\n",
        "        \n",
        "        # 3. Prediction\n",
        "        layers = (256, 256, 256, 256)\n",
        "        dim_reduced = 256\n",
        "        # backbone output channel, layers=(256)x4, 256, 91\n",
        "        self.head.mask_predictor = MaskRCNNPredictor(out_channels, layers, dim_reduced, num_classes) \n",
        "        \n",
        "        #------------ Transformer --------------------------\n",
        "        self.transformer = Transformer(\n",
        "            min_size=800, max_size=1333, \n",
        "            image_mean=[0.485, 0.456, 0.406], \n",
        "            image_std=[0.229, 0.224, 0.225])\n",
        "        \n",
        "    def forward(self, image, target=None):\n",
        "        ori_image_shape = image.shape[-2:]\n",
        "        \n",
        "        # image pre-processing\n",
        "        image, target = self.transformer(image, target)\n",
        "        image_shape = image.shape[-2:]\n",
        "        \n",
        "        # 1. Backbone -> feature map\n",
        "        feature = self.backbone(image)  \n",
        "        \n",
        "        # 2.RPN -> proposals\n",
        "        # 2.1 RPN head가 feature map을 입력으로 받아 objectness, bbox reg 수행\n",
        "        # 2.2 Objectness가 높은 상위 n개의 bbox들에 대해 NMS를 수행하여 최적의 proposal만 남김 \n",
        "        # 2.3 샘플링 비율을 맞춰서 GT와의 loss 계산\n",
        "        proposal, rpn_losses = self.rpn(feature, image_shape, target)\n",
        "\n",
        "        # 3. RoI head\n",
        "        # 3.1 RoI Align을 통해 proposal bbox에 해당하는 feature 계산\n",
        "        # 3.2 해당 feature를 바탕으로 예측 수행\n",
        "        result, roi_losses = self.head(feature, proposal, image_shape, target)  \n",
        "        \n",
        "        if self.training:\n",
        "            return dict(**rpn_losses, **roi_losses)\n",
        "        else:\n",
        "            result = self.transformer.postprocess(result, image_shape, ori_image_shape)\n",
        "            return result"
      ],
      "metadata": {
        "id": "VqEKjfcN9Y1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maskrcnn_resnet50(pretrained, num_classes, pretrained_backbone=True):\n",
        "    \"\"\"\n",
        "    Constructs a Mask R-CNN model with a ResNet-50 backbone.\n",
        "    \n",
        "    Arguments:\n",
        "        pretrained (bool): If True, returns a model pre-trained on COCO train2017.\n",
        "        num_classes (int): number of classes (including the background).\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        backbone_pretrained = False\n",
        "\n",
        "    # Model setting    \n",
        "    backbone = ResBackbone('resnet50', pretrained_backbone)\n",
        "    model = MaskRCNN(backbone, num_classes)\n",
        "    \n",
        "    if pretrained:\n",
        "        model_urls = {\n",
        "            'maskrcnn_resnet50_fpn_coco':\n",
        "                'https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth',\n",
        "        }\n",
        "        # 학습된 가중치 load\n",
        "        model_state_dict = load_url(model_urls['maskrcnn_resnet50_fpn_coco'])\n",
        "        \n",
        "        pretrained_msd = list(model_state_dict.values())\n",
        "        del_list = [i for i in range(265, 271)] + [i for i in range(273, 279)]  # 출력층에 가까운 layer는 삭제\n",
        "        for i, del_idx in enumerate(del_list):\n",
        "            pretrained_msd.pop(del_idx - i)\n",
        "\n",
        "        msd = model.state_dict()\n",
        "        skip_list = [271, 272, 273, 274, 279, 280, 281, 282, 293, 294]\n",
        "        if num_classes == 91:\n",
        "            skip_list = [271, 272, 273, 274]\n",
        "        for i, name in enumerate(msd):\n",
        "            if i in skip_list:\n",
        "                continue\n",
        "            msd[name].copy_(pretrained_msd[i])\n",
        "            \n",
        "        model.load_state_dict(msd)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "zQtrhdFDLiwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GfDJtx2cLizG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5nYXr2hyLi1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qKUHXuByLi31"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}