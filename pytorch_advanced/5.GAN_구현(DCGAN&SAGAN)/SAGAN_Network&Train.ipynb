{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SAGAN_Network&Train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uAkR1MNIRj9n"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-Attention\n",
        "\n",
        "DCGAN같이 ConvTranspose2d의 연속적인 사용은 국소적인 정보 확대의 연속에 불과. 이미지 전체의 포괄적인 정보를 반영하지 못하는 단점 존재.\n",
        "\n",
        "CNN은 기본적으로 local neighborhood의 정보만을 처리하기 때문에 long range dependencies (이미지 내에서 서로 멀리 떨어진 지역들)를 처리하는데 있어 비효율적.\n",
        "\n",
        "`Since the convolution operator has a local receptive field, long range dependencies can only be processed after passing through several convolutional layers. This could prevent learning about long-term dependencies.`\n",
        "\n",
        "SAGAN은 self-attention 모듈을 GAN에 도입하여 멀리 떨어진 지역들 간의 상관성, 의존성을 효율적으로 모델링함.\n",
        "\n",
        "커널 크기 최대의 합성곱 역할을 하지만, 해당 커널의 파라미터를 학습시키지 않고 자신과 유사한 특징량을 커널 값으로 하여 계산.\n",
        "\n",
        "<br/>\n",
        "\n",
        "**Attention 참고** :\n",
        "\n",
        "https://github.com/gymoon10/Paper-Review/blob/main/NLP/Attention%20is%20All%20you%20Need%20-%20%EC%84%A4%EB%AA%85%26%EB%85%BC%EB%AC%B8%EC%9D%BD%EA%B8%B0.ipynb\n",
        "\n",
        "https://github.com/gymoon10/Paper-Review/blob/main/NLP/BERT.md\n",
        "\n",
        "https://github.com/gymoon10/Paper-Review/blob/main/NLP/NMT_%EC%A0%95%EB%A6%AC.pdf"
      ],
      "metadata": {
        "id": "E0VW2lT6R3r0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://user-images.githubusercontent.com/44194558/148348716-8a2ce77c-1ae9-4607-a041-84ea2a84e365.png)\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/148348777-c217fc42-75aa-42a3-a9f6-545930bc13ee.png)\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/148348837-c5ded2b8-bfc7-4492-8667-7b061a7c7633.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "r1QdlyxTY3EL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Self_Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim):\n",
        "        super(Self_Attention, self).__init__()\n",
        "        \n",
        "        # Query, Key, Value embedding (채널 별 선형 합을 만드는 1x1 합성곱 이용)\n",
        "        # 입력에 대한 특징량 변환\n",
        "        self.query_conv = nn.Conv2d(\n",
        "            in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)  # Q : 원래 입력의 전치에 대응 / f (위 그림 참고)\n",
        "        self.key_conv = nn.Conv2d(\n",
        "            in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)  # K : 원래 입력 x에 대응 / g\n",
        "        self.value_conv = nn.Conv2d(\n",
        "            in_channels=in_dim, out_channels=in_dim, kernel_size=1)  # V : Attention map과 곱하는 대상 / h\n",
        "        \n",
        "        # Attention map 정규화용 (행 방향)\n",
        "        self.softmax = nn.Softmax(dim=-2)\n",
        "        \n",
        "        # Attention map에 대한 계수 / output = x + gamma * O (Attention map)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))  \n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input\n",
        "        X = x  # (B, C, H, W)\n",
        "\n",
        "        # Q, K embedding\n",
        "        proj_query = self.query_conv(X).view(X.shape[0], -1, X.shape[2] * X.shape[3])  # (B, C', H, W) -> (B, C', N), N=HxW\n",
        "        proj_query = proj_query.permute(0, 2, 1)  # 전치\n",
        "        proj_key = self.key_conv(X).view(X.shape[0], -1, X.shape[2] * X.shape[3])  # (B, C', H, W) -> (B, C', N)\n",
        "        \n",
        "        # Attention map 계산 + 정규화\n",
        "        S = torch.bmm(proj_query, proj_key)  # 배치 별 행렬곱\n",
        "        \n",
        "        # Attention score (weight)\n",
        "        attention_map_T = self.softmax(S)  # (N, N)\n",
        "        attention_map = attention_map_T.permute(0, 2, 1)  # B_ji (j th region을 생성하는데 i th region이 얼마나 중요한지)\n",
        "\n",
        "        # Self-Attention map 계산\n",
        "        proj_value = self.value_conv(x).view(X.shape[0], -1, X.shape[2] * X.shape[3])  # (B, C, N)\n",
        "        o = torch.bmm(proj_value, attention_map.permute(0, 2, 1))  # Batch 별로 (C, N) x (N, N)\n",
        "        o = o.view(X.shape[0], X.shape[1], X.shape[2], X.shape[3])  # Self-Attention map (입력 x를 포괄적인 정보를 바탕으로 조정하는 양)\n",
        "        out = x + self.gamma*o  # 포괄적인 정보를 고려하여 입력 x를 조정\n",
        "\n",
        "        return out, attention_map"
      ],
      "metadata": {
        "id": "_VEqO38SRs-e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator\n",
        "\n",
        " - 전치 합성곱 층에 스펙트럴 정규화를 추가 (마지막 layer 제외)\n",
        "\n",
        " - 3-4, 4-last layer 사이에 self attention 모듈 추가\n",
        "\n",
        "\n",
        " 스펙트럴 정규화는 데이터가 아닌 합성곱 층 등의 네트워크 가중치 파라미터를 표준화. D가 립시츠 연속성 조건을 만족하게 하여 GAN 학습을 용이하게 함.\n",
        "\n",
        " **립시츠 연속성** \n",
        "\n",
        " D에 대한 입력 이미지가 아주 조금 변하면 D의 출력 역시 거의 변하지 않아야 한다. (연속성을 확보하지 못하면 입력 이미지가 아주 조금 변해도 D의 출력이 크게 변화하하여 G, D가 제대로 학습하지 못함)\n",
        "\n",
        " 입력 -> 출력으로 확대 되는 처리가 있을 때 다양한 성분이 확대되는 값 중 최댓값 (고윳값 분해시 최대 고윳값에 대응)을 사용하여 층의 파라미터를 정규화"
      ],
      "metadata": {
        "id": "pNioSLfgaVfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, z_dim=20, image_size=64):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            # Spectral Normalization\n",
        "            nn.utils.spectral_norm(nn.ConvTranspose2d(z_dim, image_size * 8,\n",
        "                                                      kernel_size=4, stride=1)),\n",
        "            nn.BatchNorm2d(image_size * 8),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.ConvTranspose2d(image_size * 8, image_size * 4,\n",
        "                                                      kernel_size=4, stride=2, padding=1)),\n",
        "            nn.BatchNorm2d(image_size * 4),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.ConvTranspose2d(image_size * 4, image_size * 2,\n",
        "                                                      kernel_size=4, stride=2, padding=1)),\n",
        "            nn.BatchNorm2d(image_size * 2),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        # Self-Attention\n",
        "        self.self_attntion1 = Self_Attention(in_dim=image_size * 2)\n",
        "\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.ConvTranspose2d(image_size * 2, image_size,\n",
        "                                                      kernel_size=4, stride=2, padding=1)),\n",
        "            nn.BatchNorm2d(image_size),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.self_attntion2 = Self_Attention(in_dim=image_size)\n",
        "\n",
        "        self.last = nn.Sequential(\n",
        "            nn.ConvTranspose2d(image_size, 1, kernel_size=4,\n",
        "                               stride=2, padding=1),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.layer1(z)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out, attention_map1 = self.self_attntion1(out)\n",
        "        out = self.layer4(out)\n",
        "        out, attention_map2 = self.self_attntion2(out)\n",
        "        out = self.last(out)\n",
        "\n",
        "        return out, attention_map1, attention_map2"
      ],
      "metadata": {
        "id": "g-XQDN2nZbbR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "G = Generator(z_dim=20, image_size=64)\n",
        "\n",
        "input_z = torch.randn(1, 20)\n",
        "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
        "\n",
        "fake_images, attention_map1, attention_map2 = G(input_z)\n",
        "\n",
        "img_transformed = fake_images[0][0].detach().numpy()\n",
        "plt.imshow(img_transformed, 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "gmHvUtWkcJxJ",
        "outputId": "4b2d27be-86f7-4677-c3dd-8648f906ede0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator"
      ],
      "metadata": {
        "id": "k458mC6zccEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, z_dim=20, image_size=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(1, image_size, kernel_size=4,\n",
        "                                             stride=2, padding=1)),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(image_size, image_size*2, kernel_size=4,\n",
        "                                             stride=2, padding=1)),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(image_size*2, image_size*4, kernel_size=4,\n",
        "                                             stride=2, padding=1)),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        self.self_attntion1 = Self_Attention(in_dim=image_size*4)\n",
        "\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.utils.spectral_norm(nn.Conv2d(image_size*4, image_size*8, kernel_size=4,\n",
        "                                             stride=2, padding=1)),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        self.self_attntion2 = Self_Attention(in_dim=image_size*8)\n",
        "\n",
        "        self.last = nn.Conv2d(image_size*8, 1, kernel_size=4, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out, attention_map1 = self.self_attntion1(out)\n",
        "        out = self.layer4(out)\n",
        "        out, attention_map2 = self.self_attntion2(out)\n",
        "        out = self.last(out)\n",
        "\n",
        "        return out, attention_map1, attention_map2"
      ],
      "metadata": {
        "id": "h2npwByicNdZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator(z_dim=20, image_size=64)\n",
        "\n",
        "input_z = torch.randn(1, 20)\n",
        "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
        "\n",
        "fake_images, _, _ = G(input_z)\n",
        "\n",
        "d_out, attention_map1, attention_map2 = D(fake_images)\n",
        "\n",
        "print(nn.Sigmoid()(d_out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPF6y-qudJdM",
        "outputId": "d8d64e2e-68cb-46bb-e17b-58f3e98b6f85"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.4835]]]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "EIcpihWleuDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install scikit-learn==0.22.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4700JQ-EdM-n",
        "outputId": "439bee7d-ca2c-415e-ff74-f20d66eb9935"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==0.22.1\n",
            "  Downloading scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.1) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.1) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.1) (1.1.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "metadata": {
        "id": "X-r0bVD4ewzG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)"
      ],
      "metadata": {
        "id": "zK-LQcSKe2sZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784', version=1, data_home=\"./data/\")  \n",
        "\n",
        "X = mnist.data\n",
        "y = mnist.target"
      ],
      "metadata": {
        "id": "JL9b5DMLe20-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir_path = \"./data/img_78/\"\n",
        "if not os.path.exists(data_dir_path):\n",
        "    os.mkdir(data_dir_path)\n",
        "\n",
        "count7 = 0\n",
        "count8 = 0\n",
        "max_num = 200 \n",
        "\n",
        "for i in range(len(X)):\n",
        "    # 7\n",
        "    if (y[i] is \"7\") and (count7 < max_num):\n",
        "        file_path = \"./data/img_78/img_7_\" + str(count7) + \".jpg\"\n",
        "        im_f = (X[i].reshape(28, 28)) \n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64로 확대\n",
        "        pil_img_f.save(file_path)  # 저장\n",
        "        count7 += 1 \n",
        "    \n",
        "    # 8\n",
        "    if (y[i] is \"8\") and (count8 < max_num):\n",
        "        file_path = \"./data/img_78/img_8_\" + str(count8) + \".jpg\"\n",
        "        im_f = (X[i].reshape(28, 28))\n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  # 화상을 PIL으로\n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64로 확대\n",
        "        pil_img_f.save(file_path)  # 저장\n",
        "        count8 += 1 "
      ],
      "metadata": {
        "id": "0RknRAtje6EA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "KQD6AlAtfPpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_datapath_list():\n",
        "\n",
        "    train_img_list = list()  # 이미지 파일 경로를 저장\n",
        "\n",
        "    for img_idx in range(200):\n",
        "        img_path = \"./data/img_78/img_7_\" + str(img_idx) + '.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "        img_path = \"./data/img_78/img_8_\" + str(img_idx) + '.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "    return train_img_list"
      ],
      "metadata": {
        "id": "2t9NXcmmfNCb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 클래스\n",
        "class ImageTransform():\n",
        "\n",
        "    def __init__(self, mean, std):\n",
        "        self.data_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.data_transform(img)"
      ],
      "metadata": {
        "id": "khRIm2rjfaZZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리한 이미지의 텐서 형식 데이터 획득\n",
        "class GAN_Img_Dataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, file_list, transform):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.file_list[index]\n",
        "        img = Image.open(img_path) \n",
        "\n",
        "        img_transformed = self.transform(img)\n",
        "\n",
        "        return img_transformed"
      ],
      "metadata": {
        "id": "zcera59mfgtn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_list = make_datapath_list()\n",
        "\n",
        "mean = (0.5,)\n",
        "std = (0.5,)\n",
        "train_dataset = GAN_Img_Dataset(\n",
        "    file_list=train_img_list, transform=ImageTransform(mean, std))\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Data Loader\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "batch_iterator = iter(train_dataloader)  # 반복자로 변환\n",
        "imges = next(batch_iterator)  # 1번째 요소를 꺼냄\n",
        "print(imges.size())  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS8uzNSAfwMe",
        "outputId": "86921582-c42b-4df2-b8a2-4f61fd706e0b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "CBt30M5eiSXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(G, D, dataloader, num_epochs):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"사용 장치: \", device)\n",
        "    \n",
        "    # Optimizer\n",
        "    g_lr, d_lr = 0.0001, 0.0004\n",
        "    beta1, beta2 = 0.0, 0.9\n",
        "    g_optimizer = torch.optim.Adam(G.parameters(), g_lr, [beta1, beta2])\n",
        "    d_optimizer = torch.optim.Adam(D.parameters(), d_lr, [beta1, beta2])\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "    \n",
        "    # Parameter\n",
        "    z_dim = 20\n",
        "    mini_batch_size = 64\n",
        "\n",
        "    G.to(device)\n",
        "    D.to(device)\n",
        "\n",
        "    G.train()  \n",
        "    D.train()\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    num_train_imgs = len(dataloader.dataset)\n",
        "    batch_size = dataloader.batch_size\n",
        "\n",
        "    iteration = 1\n",
        "    logs = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        t_epoch_start = time.time()\n",
        "        epoch_g_loss = 0.0 \n",
        "        epoch_d_loss = 0.0 \n",
        "\n",
        "        print('-------------')\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-------------')\n",
        "        print('(train)')\n",
        "\n",
        "        # DataLoader에서 minibatch씩 꺼냄\n",
        "        for imges in dataloader:\n",
        "\n",
        "            # --------------------\n",
        "            # 1. Discriminator 학습\n",
        "            # --------------------\n",
        "            if imges.size()[0] == 1:\n",
        "                continue\n",
        "\n",
        "            imges = imges.to(device)\n",
        "            mini_batch_size = imges.size()[0]\n",
        "\n",
        "            label_real = torch.full((mini_batch_size,), 1).to(device)\n",
        "            label_fake = torch.full((mini_batch_size,), 0).to(device)\n",
        "            \n",
        "            # 진짜 이미지 판별\n",
        "            d_out_real, _, _ = D(imges)\n",
        "            \n",
        "            # 가짜 이미지 생성 & 판별\n",
        "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
        "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
        "            fake_images, _, _ = G(input_z)\n",
        "            d_out_fake, _, _ = D(fake_images)\n",
        "\n",
        "            # d_loss_real = criterion(d_out_real.view(-1), label_real)\n",
        "            # d_loss_fake = criterion(d_out_fake.view(-1), label_fake)\n",
        "\n",
        "            d_loss_real = torch.nn.ReLU()(1.0 - d_out_real).mean()\n",
        "            # 오차 d_out_real이 1이상에서 오차 0이 된다. d_out_real>1에서,\n",
        "            # 1.0 - d_out_real가 음수이면 ReLU로 0으로 한다\n",
        "\n",
        "            d_loss_fake = torch.nn.ReLU()(1.0 + d_out_fake).mean()\n",
        "            # 오차 d_out_fake가 -1 이하이면 오차 0이 된다. d_out_fake<-1에서,\n",
        "            # 1.0 + d_out_real가 음수이면 ReLU로 0으로 한다\n",
        "\n",
        "            d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "            # 역전파\n",
        "            g_optimizer.zero_grad()\n",
        "            d_optimizer.zero_grad()\n",
        "\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            # --------------------\n",
        "            # 2. Generator 학습\n",
        "            # --------------------\n",
        "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
        "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
        "            fake_images, _, _ = G(input_z)\n",
        "            d_out_fake, _, _ = D(fake_images)\n",
        "\n",
        "            # 오차를 계산→hinge version of the adversarial loss로 변경\n",
        "            #g_loss = criterion(d_out_fake.view(-1), label_real)\n",
        "            g_loss = - d_out_fake.mean()\n",
        "\n",
        "            # 역전파\n",
        "            g_optimizer.zero_grad()\n",
        "            d_optimizer.zero_grad()\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "            \n",
        "            # --------------------\n",
        "            # 3. 기록\n",
        "            # --------------------\n",
        "            epoch_d_loss += d_loss.item()\n",
        "            epoch_g_loss += g_loss.item()\n",
        "            iteration += 1\n",
        "\n",
        "        t_epoch_finish = time.time()\n",
        "        print('-------------')\n",
        "        print('epoch {} || Epoch_D_Loss:{:.4f} ||Epoch_G_Loss:{:.4f}'.format(\n",
        "            epoch, epoch_d_loss/batch_size, epoch_g_loss/batch_size))\n",
        "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
        "        t_epoch_start = time.time()\n",
        "\n",
        "    # print(\"총 반복 횟수: \", iteration)\n",
        "\n",
        "    return G, D"
      ],
      "metadata": {
        "id": "PiRVYozzf6Rz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        # Conv2d과 ConvTranspose2d 초기화\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        # BatchNorm2d 초기화\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "# 초기화 실시\n",
        "G.apply(weights_init)\n",
        "D.apply(weights_init)\n",
        "\n",
        "print(\"네트워크 초기화 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HebV0wnlxBu",
        "outputId": "c7ebd830-7755-4123-b3a6-ff1fbf6a87bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "네트워크 초기화 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 300\n",
        "G_update, D_update = train_model(G, D, dataloader=train_dataloader, num_epochs=num_epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "F5IKScuzl5ta",
        "outputId": "b95368f1-9ae3-49a2-fdb0-766c1354966a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용 장치:  cpu\n",
            "-------------\n",
            "Epoch 0/300\n",
            "-------------\n",
            "(train)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-cadb007210df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mG_update\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-59f22f954843>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(G, D, dataloader, num_epochs)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mg_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mg_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J9uGpl3Fl9h9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}