{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Efficient_GAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Efficient GAN 개요\n",
        "\n",
        "<br/>\n",
        "\n",
        "AnoGAN은 이상 탐지용 테스트 이미지와 가장 비슷한 이미지를 생성하는 노이즈를 생성 이미지와 테스트 이미지와의 오차를 활용하여 학습, 갱신.\n",
        "\n",
        "**AnoGAN의 생성 노이즈 z를 이상 탐지용 테스트 이미지를 입력으로 하여 구하는 모델(인코더)**를 구축\n",
        "\n",
        " - G의 역함수 역할을 하는 모델 (실제로는 E=G^-1이 되도록 모델링 하지 않음)\n",
        " - E의 학습 과정에서 학습용 지도 데이터를 활용할 수 있도록 GAN의 생성자, 판별자와 같이 훈련\n",
        "\n",
        "학습과 갱신을 반복하는 AnoGAN과 달리, 이상 탐지용 테스트 이미지를 인코더 E에 입력하면 생성 노이즈 z가 출력\n",
        "\n",
        "<br/>\n",
        "\n",
        "GAN을 학습시킨 후 개별적으로 인코더를 구축하는 전략은 비효율적 (학습 과정에서 지도 데이터를 전혀 활용하지 않는 문제)\n",
        "\n",
        "**BiGAN (Bidirectional GAN)활용** : 판별자에 이미지와 입력 노이즈를 쌍으로 입력   \n",
        "  - (x, E(x)) : 실제 학습용(지도) 이미지와, 학습용 이미지에 대해 인코더로 구한 입력 노이즈의 pair\n",
        "  - (G(z), z) : 생성자 G로 생성한 가짜 이미지, 생성시 사용한 입력 노이즈의 pair\n",
        "\n",
        "<br/>\n",
        "\n",
        "**생성자**는 x, G(z)가 같아지도록 학습\n",
        "\n",
        "**판별자**는 (x, E(x)), (G(z), z)를 잘 구별할 수 있도록 학습\n",
        "\n",
        "**인코더**는 판별자가 (x, E(x)), (G(z), z)를 구별할 수 없으면 E(x)가 z가 되도록 학습\n",
        "  \n",
        "  - 학습 끝에 판별자가 (x, E(x)), (G(z), z)를 정확하게 판정할 수 없게 되어 인코더가 관여ㅕ하는 (x, E(x))를 (G(z), z)라고 판정"
      ],
      "metadata": {
        "id": "wbR0TUIb699m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZDhs5L9S-5Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "\n",
        "AnoGAN과 달리 입력 이미지 크기를 64x64로 확대하지 않고 28x28 원본 사이즈 유지"
      ],
      "metadata": {
        "id": "kJI3dDaO-6qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import fetch_openml"
      ],
      "metadata": {
        "id": "gr-gF2YK-_FZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "ovmOHd4m-_Om"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "print(\"Python 버전：\",sys.version)\n",
        "print(\"PyTorch 버전：\", torch.__version__)\n",
        "print(\"GPU 확인\")\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pkn-LDCk_kvp",
        "outputId": "45d8d3f9-661a-4e3a-da60-9030da867d76"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 버전： 3.7.12 (default, Sep 10 2021, 00:21:48) \n",
            "[GCC 7.5.0]\n",
            "PyTorch 버전： 1.10.0+cu111\n",
            "GPU 확인\n",
            "Sun Jan 23 08:42:46 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 mnist 데이터\n",
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "mnist = fetch_openml('mnist_784', version=1, data_home=\"./data/\", as_frame=False)  \n",
        "\n",
        "X = mnist.data\n",
        "y = mnist.target"
      ],
      "metadata": {
        "id": "KDHhV4cB_BkV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir_path = \"./data/img_78/\"\n",
        "if not os.path.exists(data_dir_path):\n",
        "    os.mkdir(data_dir_path)"
      ],
      "metadata": {
        "id": "ocXA-YSBGG-4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count7=0\n",
        "count8=0\n",
        "max_num=200  \n",
        "\n",
        "for i in range(len(X)):\n",
        "    \n",
        "    if (y[i] is \"7\") and (count7<max_num):\n",
        "        file_path=\"./data/img_78/img_7_\"+str(count7)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  \n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8)) \n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  \n",
        "        pil_img_f.save(file_path)  \n",
        "        count7+=1 \n",
        "    \n",
        "    if (y[i] is \"8\") and (count8<max_num):\n",
        "        file_path=\"./data/img_78/img_8_\"+str(count8)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28)) \n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  \n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC) \n",
        "        pil_img_f.save(file_path)  \n",
        "        count8+=1\n",
        " \n",
        "    if (count7>=max_num) and (count8>=max_num):\n",
        "        break"
      ],
      "metadata": {
        "id": "Z38X9m7hGHE2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir_path = \"./data/test/\"\n",
        "if not os.path.exists(data_dir_path):\n",
        "    os.mkdir(data_dir_path)"
      ],
      "metadata": {
        "id": "XokG7fReGHIM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i_start = i+1\n",
        "print(i_start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QSKXBalGV95",
        "outputId": "35fb4bfd-0464-44a2-b8e0-e45333df7308"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count2=0\n",
        "count7=0\n",
        "count8=0\n",
        "max_num=5  #\n",
        "\n",
        "for i in range(i_start,len(X)):  \n",
        "    \n",
        "    if (y[i] is \"2\") and (count2<max_num):\n",
        "        file_path=\"./data/test/img_2_\"+str(count2)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  \n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  \n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC) \n",
        "        pil_img_f.save(file_path)  \n",
        "        count2+=1\n",
        "\n",
        "    if (y[i] is \"7\") and (count7<max_num):\n",
        "        file_path=\"./data/test/img_7_\"+str(count7)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28))  \n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  \n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  \n",
        "        pil_img_f.save(file_path)  \n",
        "        count7+=1 \n",
        "    \n",
        "    if (y[i] is \"8\") and (count8<max_num):\n",
        "        file_path=\"./data/test/img_8_\"+str(count8)+\".jpg\"\n",
        "        im_f=(X[i].reshape(28, 28)) \n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8)) \n",
        "        pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  \n",
        "        pil_img_f.save(file_path)  \n",
        "        count8+=1 "
      ],
      "metadata": {
        "id": "WQN--tUhGWAv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GAN 학습용 정상 데이터 (7, 8만)\n",
        "data_dir_path = \"./data/img_78_28size/\"\n",
        "if not os.path.exists(data_dir_path):\n",
        "    os.mkdir(data_dir_path)"
      ],
      "metadata": {
        "id": "GdnCmOwV_QA0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count7 = 0\n",
        "count8 = 0\n",
        "max_num = 200  \n",
        "\n",
        "for i in range(len(X)):\n",
        "    \n",
        "    if (y[i] is \"7\") and (count7 < max_num):\n",
        "        file_path = \"./data/img_78_28size/img_7_\" + str(count7) + \".jpg\"\n",
        "        im_f = (X[i].reshape(28, 28))  \n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8)) \n",
        "        pil_img_f.save(file_path)  \n",
        "        count7 += 1 \n",
        "    \n",
        "    if (y[i] is \"8\") and (count8 < max_num):\n",
        "        file_path = \"./data/img_78_28size/img_8_\" + str(count8) + \".jpg\"\n",
        "        im_f = (X[i].reshape(28, 28))  \n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  \n",
        "        pil_img_f.save(file_path) \n",
        "        count8 += 1\n",
        "    \n",
        "    if (count7 >= max_num) and (count8 >= max_num):\n",
        "        break"
      ],
      "metadata": {
        "id": "TACF55aU_Res"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이상 탐지용 테스트 데이터\n",
        "data_dir_path = \"./data/test_28size/\"\n",
        "if not os.path.exists(data_dir_path):\n",
        "    os.mkdir(data_dir_path)\n",
        "\n",
        "i_start = i+1  # train, test 중복 방지용\n",
        "print(i_start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv8SAxjl_TIz",
        "outputId": "23b963dc-8fc7-4e44-affb-d347d1c0ed68"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count2 = 0  # 이상치\n",
        "count7 = 0\n",
        "count8 = 0\n",
        "max_num = 5 \n",
        "\n",
        "for i in range(i_start, len(X)):  \n",
        "    \n",
        "    if (y[i] is \"2\") and (count2 < max_num):\n",
        "        file_path = \"./data/test_28size/img_2_\" + str(count2) + \".jpg\"\n",
        "        im_f = (X[i].reshape(28, 28))  \n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))\n",
        "        pil_img_f.save(file_path)  \n",
        "        count2 += 1 \n",
        "    \n",
        "    if (y[i] is \"7\") and (count7 < max_num):\n",
        "        file_path = \"./data/test_28size/img_7_\" + str(count7) + \".jpg\"\n",
        "        im_f = (X[i].reshape(28, 28))  \n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8))  \n",
        "        pil_img_f.save(file_path)  \n",
        "        count7 += 1 \n",
        "\n",
        "    if (y[i] is \"8\") and (count8 < max_num):\n",
        "        file_path = \"./data/test_28size/img_8_\" + str(count8) + \".jpg\"\n",
        "        im_f = (X[i].reshape(28, 28)) \n",
        "        pil_img_f = Image.fromarray(im_f.astype(np.uint8)) \n",
        "        pil_img_f.save(file_path)  \n",
        "        count8 += 1 "
      ],
      "metadata": {
        "id": "qEUp38hr_W4-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1vQFo0zf_YjQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "x7-L0AEr_Zow"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1234)\n",
        "torch.cuda.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "metadata": {
        "id": "62FR-IKNAf1Y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator"
      ],
      "metadata": {
        "id": "rpeGMmiaBrPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, z_dim=20):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(z_dim, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(1024, 7*7*128),\n",
        "            nn.BatchNorm1d(7*7*128),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "        self.last = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=64, out_channels=1, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.layer1(z)\n",
        "        out = self.layer2(out)  # (N, 6272)\n",
        "        out = out.view(z.shape[0], 128, 7, 7)  # (N, 128, 7, 7) - 전치 합성곱층의 입력으로 사용될 수 있도록 변환\n",
        "        out = self.layer3(out)\n",
        "        out = self.last(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "cfa_mQ-8_bBf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "G = Generator(z_dim=20)\n",
        "G.train()\n",
        "\n",
        "input_z = torch.randn(2, 20)  # BatchNorm이 있기 때문에 2 이상으로 설정해야 함\n",
        "\n",
        "fake_images = G(input_z)  # torch.Size([2, 1, 28, 28])\n",
        "img_transformed = fake_images[0][0].detach().numpy()\n",
        "plt.imshow(img_transformed, 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Bo_IjsjTA0-E",
        "outputId": "97f7abeb-b387-496a-9bb5-d72ad83bc222"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator\n",
        "\n",
        "이미지와 입력 노이즈의 pair를 입력으로 받음\n",
        "\n",
        "두 입력은 각각 합성곱, FC 층에서 독립적으로 처리뒨 후 결합, 결합된 텐서는 FC 층을 거쳐 최종 판정 결과 출력"
      ],
      "metadata": {
        "id": "g8hkYnZoBtet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, z_dim=20):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        # 이미지 입력 처리\n",
        "        self.x_layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        self.x_layer2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "        \n",
        "        # 노이즈 입력 처리\n",
        "        self.z_layer1 = nn.Linear(z_dim, 512)\n",
        "        \n",
        "        # 최종 판정 (결합된 입력 처리)\n",
        "        self.last1 = nn.Sequential(\n",
        "            nn.Linear(3648, 1024),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        self.last2 = nn.Linear(1024, 1)\n",
        "\n",
        "    def forward(self, x, z):\n",
        "        \n",
        "        # 이미지 입력 처리\n",
        "        x_out = self.x_layer1(x)\n",
        "        x_out = self.x_layer2(x_out)  # (N, 64, 7, 7)\n",
        "        x_out = x_out.view(-1, 64 * 7 * 7)  # (N, 3136)\n",
        "   \n",
        "        # 노이즈 입력 처리\n",
        "        z = z.view(z.shape[0], -1)  # (N, 20)\n",
        "        z_out = self.z_layer1(z)  # (N, 512)\n",
        "\n",
        "        # 최종 판정\n",
        "        out = torch.cat([x_out, z_out], dim=1)  # Concat (N, 3648), 3648=3136+512\n",
        "        out = self.last1(out)  # (N, 1024)\n",
        "\n",
        "        # AnoGAN과 마찬가지로 최종 출력 이전 층의 feature를 별도로 사용\n",
        "        feature = out\n",
        "        feature = feature.view(feature.size()[0], -1)  # (N, 1024)\n",
        "\n",
        "        out = self.last2(out)\n",
        "\n",
        "        return out, feature"
      ],
      "metadata": {
        "id": "XqikUkUAA85r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator(z_dim=20)\n",
        "\n",
        "input_z = torch.randn(2, 20)\n",
        "fake_images = G(input_z)\n",
        "\n",
        "d_out, _ = D(fake_images, input_z)\n",
        "\n",
        "print(nn.Sigmoid()(d_out))  # 0 ~ 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeWF5X4rA-qZ",
        "outputId": "53ebd35a-766e-4a9e-be3a-503874c7b089"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4322],\n",
            "        [0.4629]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder\n",
        "\n",
        "이미지를 노이즈 z로 변환\n",
        "\n",
        "판별자와 비슷한 형태. 출력 차원=z_dim"
      ],
      "metadata": {
        "id": "2oZvfPf9GPXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, z_dim=20):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1, inplace=True))\n",
        "        \n",
        "        self.last = nn.Linear(128 * 7 * 7, z_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        \n",
        "        out = out.view(-1, 128 * 7 * 7)\n",
        "        out = self.last(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "zt0mReLXEmi1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "E = Encoder(z_dim=20)\n",
        "\n",
        "x = fake_images  # 생성자로 생성한 가짜 이미지 (input_z를 입력으로 받음)\n",
        "\n",
        "# Image to Noise mapping\n",
        "z = E(x)\n",
        "\n",
        "print(z.shape)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyVhSflcHMOj",
        "outputId": "19a1cad1-7e35-4d20-c5e5-e9bf8a2b3cd8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 20])\n",
            "tensor([[-0.0669, -0.2844, -0.3601,  0.1404, -0.2922, -0.4834, -0.0025,  0.0258,\n",
            "         -0.1298, -0.2613, -0.4292, -0.2584, -0.6141, -0.1440,  0.1142,  0.2175,\n",
            "          0.0730,  0.0323, -0.7176, -0.7410],\n",
            "        [ 0.4822,  0.3681, -0.0647, -0.0773,  0.0989,  0.3012,  0.8054,  0.4399,\n",
            "          1.0848, -0.2809,  0.0619, -0.3179, -0.2963, -0.1192,  0.6562, -0.1707,\n",
            "          0.1287, -0.6156,  0.3127, -0.4819]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9daWvrxHVzK",
        "outputId": "300412cf-bfe0-409c-d2dc-fa8f80ebe07d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1554, -1.0886,  1.6625, -0.2912,  0.5645, -0.2161,  0.4823,  0.2058,\n",
              "          0.1170, -0.9420, -2.7554, -0.1196, -0.2979,  1.2070, -0.4066,  0.1869,\n",
              "         -0.4447, -1.9914,  0.8704, -0.4112],\n",
              "        [-0.4780, -0.0311,  0.3894, -0.3777, -0.8123,  2.0157,  1.3826, -0.4303,\n",
              "          2.0753,  0.6294,  0.8359, -1.4538,  0.2111,  0.2027,  0.8474, -0.2811,\n",
              "         -0.7316, -0.6328, -0.8258,  0.0790]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader"
      ],
      "metadata": {
        "id": "TEkE5r9RHu6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_datapath_list():\n",
        "\n",
        "    train_img_list = list()  \n",
        "\n",
        "    for img_idx in range(200):\n",
        "        img_path = \"./data/img_78_28size/img_7_\" + str(img_idx)+'.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "        img_path = \"./data/img_78_28size/img_8_\" + str(img_idx)+'.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "    return train_img_list\n",
        "\n",
        "class ImageTransform():\n",
        "\n",
        "    def __init__(self, mean, std):\n",
        "        self.data_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.data_transform(img)\n",
        "\n",
        "# Dataset\n",
        "class GAN_Img_Dataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, file_list, transform):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img_path = self.file_list[index]\n",
        "        img = Image.open(img_path)  \n",
        "\n",
        "        img_transformed = self.transform(img)\n",
        "\n",
        "        return img_transformed"
      ],
      "metadata": {
        "id": "2dLXXGw3HoPl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_list = make_datapath_list()\n",
        "\n",
        "mean = (0.5, )\n",
        "std = (0.5, )\n",
        "train_dataset = GAN_Img_Dataset(file_list=train_img_list, transform=ImageTransform(mean, std))\n",
        "\n",
        "# DataLoader \n",
        "batch_size = 64\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 동작 확인\n",
        "batch_iterator = iter(train_dataloader)  # 반복자 변환\n",
        "imges = next(batch_iterator)  # 1번째 요소를 꺼낸다\n",
        "print(imges.size())  # torch.Size([64, 1, 64, 64])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOOJaaprIXbY",
        "outputId": "954114f1-8a39-4d1f-8dc1-942c9e3a0a36"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train\n",
        "\n",
        "판별자를 학습시킨 후, 생성자와 인코더를 학습 (인코더가 추가된 것 외에는 일반적인 GAN 학습과 동일함)\n",
        "\n",
        "판별자는 이미지와 노이즈 쌍을 입력으로 받아 진위 여부를 식별하기 때문에 이미지만 있는 경우보다 식별하기 쉬운 상태\n",
        "\n",
        "-> 생성자, 인코더보다 학습률을 낮게 설정"
      ],
      "metadata": {
        "id": "j4eeML7eIhTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(G, D, E, dataloader, num_epochs):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"사용 장치: \", device)\n",
        "\n",
        "    lr_ge = 0.0001\n",
        "    lr_d = 0.0001 / 4  # 판별자 학습률을 상대적으로 낮게 설정\n",
        "    beta1, beta2 = 0.5, 0.999\n",
        "    g_optimizer = torch.optim.Adam(G.parameters(), lr_ge, [beta1, beta2])\n",
        "    e_optimizer = torch.optim.Adam(E.parameters(), lr_ge, [beta1, beta2])\n",
        "    d_optimizer = torch.optim.Adam(D.parameters(), lr_d, [beta1, beta2])\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "\n",
        "    z_dim = 20\n",
        "    mini_batch_size = 64\n",
        "\n",
        "    G.to(device)\n",
        "    E.to(device)\n",
        "    D.to(device)\n",
        "\n",
        "    G.train()  \n",
        "    E.train()  \n",
        "    D.train()  \n",
        "\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    num_train_imgs = len(dataloader.dataset)\n",
        "    batch_size = dataloader.batch_size\n",
        "\n",
        "    iteration = 1\n",
        "    logs = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        t_epoch_start = time.time()\n",
        "        epoch_g_loss = 0.0 \n",
        "        epoch_e_loss = 0.0 \n",
        "        epoch_d_loss = 0.0  \n",
        "\n",
        "        print('-------------')\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-------------')\n",
        "        print('(train)')\n",
        "\n",
        "        for imges in dataloader:\n",
        "\n",
        "            if imges.size()[0] == 1:\n",
        "                continue\n",
        "\n",
        "            mini_batch_size = imges.size()[0]\n",
        "            label_real = torch.full((mini_batch_size,), 1).to(device)\n",
        "            label_fake = torch.full((mini_batch_size,), 0).to(device)\n",
        "\n",
        "            imges = imges.to(device)\n",
        "\n",
        "            # --------------------\n",
        "            # 1. Discriminator 학습\n",
        "            # --------------------\n",
        "            # 진짜 이미지 판정\n",
        "            z_out_real = E(imges)  # E(x)\n",
        "            d_out_real, _ = D(imges, z_out_real)  # D(x, E(x))\n",
        "\n",
        "            # 가짜 이미지 생성 & 판정\n",
        "            input_z = torch.randn(mini_batch_size, z_dim).to(device)  # z\n",
        "            fake_images = G(input_z)  # G(z)\n",
        "            d_out_fake, _ = D(fake_images, input_z)  # D(G(z), z)\n",
        "\n",
        "            # loss (https://github.com/YutaroOgawa/pytorch_advanced/issues/144)\n",
        "            label_real = label_real.type_as(d_out_real.view(-1))\n",
        "            d_loss_real = criterion(d_out_real.view(-1), label_real)  # D(x, E(x))를 진짜라고 판별하도록 학습\n",
        "\n",
        "            label_fake = label_real.type_as(d_out_fake.view(-1))\n",
        "            d_loss_fake = criterion(d_out_fake.view(-1), label_fake)  # D(G(z), z)를 가짜라고 판별하도록 학습\n",
        "\n",
        "            d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "            # 역전파\n",
        "            d_optimizer.zero_grad()\n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            # --------------------\n",
        "            # 2. Generator 학습\n",
        "            # --------------------\n",
        "            # 가짜 이미지 생성 & 판정\n",
        "            input_z = torch.randn(mini_batch_size, z_dim).to(device)  # z\n",
        "            fake_images = G(input_z)  # G(z)\n",
        "            d_out_fake, _ = D(fake_images, input_z)  # D(G(z), z)\n",
        "\n",
        "            # loss\n",
        "            g_loss = criterion(d_out_fake.view(-1), label_real)  # D(G(z), z)를 진짜라고 판별하도록 학습 (판별자를 속이도록) \n",
        "\n",
        "            # 역전파\n",
        "            g_optimizer.zero_grad()\n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "\n",
        "            # --------------------\n",
        "            # 3. Encoder 학습\n",
        "            # --------------------\n",
        "            # 지도(학습용) 이미지로부터 노이즈 z 추정\n",
        "            z_out_real = E(imges)  # E(x)\n",
        "            d_out_real, _ = D(imges, z_out_real)  # D(x, E(x))\n",
        "\n",
        "            # loss\n",
        "            e_loss = criterion(d_out_real.view(-1), label_fake)  # (x, E(x))를 가짜((G(z), z))라고 판정하도록 학습\n",
        "                                                                 # 판별자가 (x, E(x))와 (G(z), z)를 제대로 판정하지 못하도록 학습\n",
        "            # 역전파\n",
        "            e_optimizer.zero_grad()\n",
        "            e_loss.backward()\n",
        "            e_optimizer.step()\n",
        "\n",
        "            # --------------------\n",
        "            # 4. 기록\n",
        "            # --------------------\n",
        "            epoch_d_loss += d_loss.item()\n",
        "            epoch_g_loss += g_loss.item()\n",
        "            epoch_e_loss += e_loss.item()\n",
        "            iteration += 1\n",
        "\n",
        "        # epoch의 phase별 loss와 정답률\n",
        "        t_epoch_finish = time.time()\n",
        "        print('-------------')\n",
        "        print('epoch {} || Epoch_D_Loss:{:.4f} ||Epoch_G_Loss:{:.4f} ||Epoch_E_Loss:{:.4f}'.format(\n",
        "            epoch, epoch_d_loss/batch_size, epoch_g_loss/batch_size, epoch_e_loss/batch_size))\n",
        "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
        "        t_epoch_start = time.time()\n",
        "\n",
        "    print(\"총 반복 횟수: \", iteration)\n",
        "\n",
        "    return G, D, E"
      ],
      "metadata": {
        "id": "1w6jEt5ZIgOG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 네트워크 초기화\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "        \n",
        "    elif classname.find('Linear') != -1:\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "# Init\n",
        "G.apply(weights_init)\n",
        "E.apply(weights_init)\n",
        "D.apply(weights_init)\n",
        "\n",
        "print(\"네트워크 초기화 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQUs0wWQM8W3",
        "outputId": "afb96e3e-e8b8-49d8-e145-99593b4e6958"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "네트워크 초기화 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1500  # 1500 권장\n",
        "G_update, D_update, E_update = train_model(G, D, E, dataloader=train_dataloader, num_epochs=num_epochs)"
      ],
      "metadata": {
        "id": "qvfBL166HVgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "batch_size = 8\n",
        "z_dim = 20\n",
        "fixed_z = torch.randn(batch_size, z_dim)\n",
        "\n",
        "# eval\n",
        "G_update.eval()\n",
        "fake_images = G_update(fixed_z.to(device))\n",
        "\n",
        "batch_iterator = iter(train_dataloader)  # 반복자로 변환\n",
        "imges = next(batch_iterator)  # 1번째 요소를 꺼낸다\n",
        "\n",
        "# 상단 : 학습용 실제 / 하단 : 생성된 가찌 이미지\n",
        "fig = plt.figure(figsize=(15, 6))\n",
        "for i in range(0, 5):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
        "\n",
        "    plt.subplot(2, 5, 5+i+1)\n",
        "    plt.imshow(fake_images[i][0].cpu().detach().numpy(), 'gray')"
      ],
      "metadata": {
        "id": "6Zh0MzedNGdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트 데이터를 사용하여 이상 탐지"
      ],
      "metadata": {
        "id": "kX8Nmae3NY6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_test_datapath_list():\n",
        "\n",
        "    train_img_list = list()  \n",
        "\n",
        "    for img_idx in range(5):\n",
        "        img_path = \"./data/test_28size/img_7_\" + str(img_idx)+'.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "        img_path = \"./data/test_28size/img_8_\" + str(img_idx)+'.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "        img_path = \"./data/test_28size/img_2_\" + str(img_idx)+'.jpg'\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "    return train_img_list\n",
        "\n",
        "test_img_list = make_test_datapath_list()\n",
        "\n",
        "# Dataset \n",
        "mean = (0.5,)\n",
        "std = (0.5,)\n",
        "test_dataset = GAN_Img_Dataset(file_list=test_img_list, transform=ImageTransform(mean, std))\n",
        "\n",
        "# DataLoader\n",
        "batch_size = 5\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "EPeU8sJnNXWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_iterator = iter(test_dataloader)  \n",
        "imges = next(batch_iterator)  \n",
        "\n",
        "# 테스트 데이터 확인 (정상 : 7, 8 / 이상치 : 2)\n",
        "fig = plt.figure(figsize=(15, 6))\n",
        "for i in range(0, 5):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')"
      ],
      "metadata": {
        "id": "spI8elRGNXeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래의 Anomaly score는 AnoGAN과 동일하나 입력이 조금 다름 (BiGAN의 형태로 판별자 사용)"
      ],
      "metadata": {
        "id": "e6A8g6ImODTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Anomaly_score(x, fake_img, z_out_real, D, Lambda=0.1):  # 노이즈 추가\n",
        "    \n",
        "    # 테스트 이미지 x, 생성된 이미지 간의 픽셀 별 차이의 절댓값 계산 & minibatch마다 합 계산\n",
        "    residual_loss = torch.abs(x - fake_img)  # (N, 1, 28, 28)\n",
        "    residual_loss = residual_loss.view(residual_loss.size()[0], -1)  # (N, 784)\n",
        "    residual_loss = torch.sum(residual_loss, dim=1)  # (N, )\n",
        "\n",
        "    # 테스트 이미지, 생성된 이미지를 D에 입력하여 feature 출력\n",
        "    _, x_feature = D(x, z_out_real)\n",
        "    _, G_feature = D(fake_img, z_out_real)\n",
        "\n",
        "    # 테스트 이미지의 feature, 생성된 이미지의 feature 간의 픽셀 별 차이의 절댓값 계산 & minibatch마다 합 계산\n",
        "    discrimination_loss = torch.abs(x_feature - G_feature)  # (N, 1024)\n",
        "    discrimination_loss = discrimination_loss.view(discrimination_loss.size()[0], -1)  # (N, 1024)\n",
        "    discrimination_loss = torch.sum(discrimination_loss, dim=1)  # (N, )\n",
        "\n",
        "    # Total loss\n",
        "    loss_each = (1 - Lambda) * residual_loss + Lambda * discrimination_loss  # minibatch마다 위의 2 종류의 손실을 더함\n",
        "    total_loss = torch.sum(loss_each)  # 모든 minibatch의 손실 계산\n",
        "\n",
        "    return total_loss, loss_each, residual_loss"
      ],
      "metadata": {
        "id": "RzLlMGRzNq_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = imges[0:5]  # 이상 탐지용\n",
        "x = x.to(device)\n",
        "\n",
        "# 테스트용 지도 이미지를 z로 변환(encoding) & 학습된 생성자를 이용하여 생성\n",
        "E_update.eval()\n",
        "G_update.eval()\n",
        "z_out_real = E_update(imges.to(device))  # E(x)=z (테스트 이미지를 인코더에 입력하여 생성 노이즈 z를 출력)\n",
        "imges_reconstract = G_update(z_out_real)  # G(E(x))=G(z) (테스트 이미지들을 가장 그럴듯 하게 생성하는 노이즈를 이용하여 가짜 이미지 생성)\n",
        "\n",
        "# loss\n",
        "loss, loss_each, residual_loss_each = Anomaly_score(x, imges_reconstract, z_out_real, D_update, Lambda=0.1)\n",
        "loss_each = loss_each.cpu().detach().numpy()\n",
        "print(\"total loss: \", np.round(loss_each, 0))\n",
        "\n",
        "# 확인 (상단 : 이상 탐지용 이미지 / 하단 : 생성된 이미지)\n",
        "fig = plt.figure(figsize=(15, 6))\n",
        "for i in range(0, 5):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(imges[i][0].cpu().detach().numpy(), 'gray')\n",
        "\n",
        "    plt.subplot(2, 5, 5+i+1)\n",
        "    plt.imshow(imges_reconstract[i][0].cpu().detach().numpy(), 'gray')"
      ],
      "metadata": {
        "id": "wWi3AccIOeym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트 이미지들을 가장 그럴듯하게 복원할 수 있는 생성 노이즈를 활용했음에도 불구하고 학습용 지도 데이터에 없는 이상치 2 이미지는 제대로 생성하지 못하는 것을 확인.\n",
        "\n",
        "\n",
        "결과 참고 : https://github.com/YutaroOgawa/pytorch_advanced/blob/master/6_gan_anomaly_detection/6_4_EfficientGAN_GoogleClab.ipynb"
      ],
      "metadata": {
        "id": "HtfNA7lw35lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "inrPvgF92KZC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}