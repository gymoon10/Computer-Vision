{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile"
      ],
      "metadata": {
        "id": "B_NgS07XreeW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)"
      ],
      "metadata": {
        "id": "UDBSRlj1rehD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-trained된 fastText 모델 다운로드"
      ],
      "metadata": {
        "id": "MqhPc6qlrmTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\"\n",
        "save_path = \"./data/wiki-news-300d-1M.vec.zip\"\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)  "
      ],
      "metadata": {
        "id": "xe7TqztmpzfU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Zip = zipfile.ZipFile(\"./data/wiki-news-300d-1M.vec.zip\")\n",
        "Zip.extractall(\"./data/\")  # ZIP 압축 해제\n",
        "Zip.close()  \n",
        "# \"wiki-news-300d-1M.vec\""
      ],
      "metadata": {
        "id": "Fqy7A35Trhnu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "jmYkaE_0sNZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "save_path = \"./data/aclImdb_v1.tar.gz\"\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)"
      ],
      "metadata": {
        "id": "AZc19yIorhqQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tar = tarfile.open('./data/aclImdb_v1.tar.gz')\n",
        "tar.extractall('./data/')  # 압축 해제\n",
        "tar.close()  \n",
        "# \"aclImdb\" "
      ],
      "metadata": {
        "id": "IWGvyGCHrhwf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import io\n",
        "import string\n",
        "\n",
        "\n",
        "# 학습 데이터의 tsv 파일을 작성\n",
        "f = open('./data/IMDb_train.tsv', 'w')\n",
        "\n",
        "path = './data/aclImdb/train/pos/'\n",
        "for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "    with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "        text = ff.readline()\n",
        "        text = text.replace('\\t', \" \")\n",
        "        text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "        f.write(text)\n",
        "\n",
        "path = './data/aclImdb/train/neg/'\n",
        "for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "    with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "        text = ff.readline()\n",
        "        text = text.replace('\\t', \" \")\n",
        "        text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "        f.write(text)\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "-Fq2qi1KsbhI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터 작성\n",
        "f = open('./data/IMDb_test.tsv', 'w')\n",
        "\n",
        "path = './data/aclImdb/test/pos/'\n",
        "for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "    with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "        text = ff.readline()\n",
        "        text = text.replace('\\t', \" \")\n",
        "        text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "        f.write(text)\n",
        "\n",
        "\n",
        "path = './data/aclImdb/test/neg/'\n",
        "\n",
        "for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "    with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "        text = ff.readline()\n",
        "        text = text.replace('\\t', \" \")\n",
        "\n",
        "        text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "        f.write(text)\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "aB9WLvBDsbkH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "# 다음 기호는 스페이스(공백)으로 치환합니다(쉼표, 마침표 제외).\n",
        "# punctuation은 구두점입니다\n",
        "print(\"구두점 문자: \", string.punctuation)\n",
        "# !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "\n",
        "# 전처리\n",
        "def preprocessing_text(text):\n",
        "    # 개행 코드 삭제\n",
        "    text = re.sub('<br />', '', text)\n",
        "\n",
        "    # 쉼표, 마침표 이외의 기호를 공백으로 치환\n",
        "    for p in string.punctuation:\n",
        "        if (p == \".\") or (p == \",\"):\n",
        "            continue\n",
        "        else:\n",
        "            text = text.replace(p, \" \")\n",
        "\n",
        "    # 쉼표, 마침표의 전후에 공백 추가\n",
        "    text = text.replace(\".\", \" . \")\n",
        "    text = text.replace(\",\", \" , \")\n",
        "    return text\n",
        "\n",
        "# 띄어쓰기(이번에는 영어 데이터이며, 임시로 공백으로 구분)\n",
        "def tokenizer_punctuation(text):\n",
        "    return text.strip().split()\n",
        "\n",
        "# 전처리 및 띄어쓰기를 포함한 함수 정의\n",
        "def tokenizer_with_preprocessing(text):\n",
        "    text = preprocessing_text(text)\n",
        "    ret = tokenizer_punctuation(text)\n",
        "    return ret\n",
        "\n",
        "# 동작을 확인합니다\n",
        "print(tokenizer_with_preprocessing('I like cats.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUP39FRXsbm9",
        "outputId": "f3674040-a35e-44e1-bd93-f4bc65c15bd4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "구두점 문자:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "['I', 'like', 'cats', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader"
      ],
      "metadata": {
        "id": "_v2-RHT6s1w1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "from torchtext.legacy import data\n",
        "\n",
        "max_length = 256\n",
        "TEXT = torchtext.legacy.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
        "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, init_token=\"<cls>\", eos_token=\"<eos>\")\n",
        "LABEL = torchtext.legacy.data.Field(sequential=False, use_vocab=False)"
      ],
      "metadata": {
        "id": "8pdnKhoisbqH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_ds, test_ds = torchtext.legacy.data.TabularDataset.splits(\n",
        "    path='./data/', train='IMDb_train.tsv',\n",
        "    test='IMDb_test.tsv', format='tsv',\n",
        "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
        "\n",
        "print('훈련 및 검증 데이터 수', len(train_val_ds))\n",
        "print('첫번째 훈련 및 검증 데이터', vars(train_val_ds[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9YwbZ1dtv-L",
        "outputId": "f115d653-8548-4e79-a201-f59998bbc54b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 및 검증 데이터 수 25000\n",
            "첫번째 훈련 및 검증 데이터 {'Text': ['this', 'is', 'one', 'of', 'the', 'best', 'movies', 'i', 've', 'ever', 'seen', '.', 'it', 'has', 'very', 'good', 'acting', 'by', 'hanks', ',', 'newman', ',', 'and', 'everyone', 'else', '.', 'definitely', 'jude', 'law', 's', 'best', 'performance', '.', 'the', 'cinematography', 'is', 'excellent', ',', 'the', 'editing', 'is', 'about', 'as', 'good', ',', 'and', 'includes', 'a', 'great', 'original', 'score', 'that', 'really', 'fits', 'in', 'with', 'the', 'mood', 'of', 'the', 'movie', '.', 'the', 'production', 'design', 'is', 'also', 'a', 'factor', 'in', 'what', 'makes', 'this', 'movie', 'special', '.', 'to', 'me', ',', 'it', 'takes', 'a', 'lot', 'to', 'beat', 'godfather', ',', 'but', 'the', 'fantastic', 'cinematography', 'displayed', 'wins', 'this', 'contest', '.', 'definitely', 'a', 'best', 'picture', 'nominee', 'in', 'my', 'book', '.'], 'Label': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "train_ds, val_ds = train_val_ds.split(\n",
        "    split_ratio=0.8, random_state=random.seed(1234))\n",
        "\n",
        "print('훈련 데이터의 수', len(train_ds))\n",
        "print('검증 데이터의 수', len(val_ds))\n",
        "print('첫번째 훈련 데이터', vars(train_ds[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx8i5OWbtwBT",
        "outputId": "4383b258-63a6-431a-ff08-388597864fd4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 수 20000\n",
            "검증 데이터의 수 5000\n",
            "첫번째 훈련 데이터 {'Text': ['this', 'film', 'was', 'really', 'bad', 'whether', 'you', 'take', 'it', 'as', 'a', 'sci', 'fi', 'movie', ',', 'as', 'a', 'horror', 'one', 'or', 'even', 'as', 'a', 'comedy', '.', 'the', 'whole', 'thing', 'is', 'ridiculous', '.', 'the', 'film', 'looks', 'and', 'is', 'definitely', 'cheap', ',', 'the', 'actors', 'have', 'no', 'idea', 'of', 'what', 'acting', 'is', 'and', 'the', 'script', 'shows', 'clearly', 'that', 'it', 'was', 'being', 'made', 'along', 'with', 'the', 'shooting', '.', 'it', 'is', 'obvious', 'that', 'the', 'monster', 'in', 'the', 'closet', 'was', 'added', 'because', 'the', 'living', 'head', 'was', 'not', 'scary', 'at', 'all', 'she', 'was', 'even', 'pretty', 'and', 'they', 'thought', 'they', 'needed', 'something', 'more', 'impressive', 'they', 'failed', 'here', 'too', 'the', 'make', 'up', 'is', 'awful', 'even', 'for', 'the', 'late', '50', 's', ',', 'rather', 'funny', '.', 'the', 'film', 'shows', 'clearly', 'why', 'director', 'joseph', 'green', 's', 'career', 'as', 'such', 'and', 'also', 'as', 'a', 'writer', 'never', 'materialized', 'he', 'was', 'really', 'bad', 'at', 'both', '.', 'same', 'goes', 'to', 'the', 'actors', ',', 'leading', 'and', 'supporting', '.', 'the', 'brain', 'that', 'wouldn', 't', 'die', 's', 'best', 'achievement', 'is', 'its', 'short', 'running', 'time', '.'], 'Label': '0'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vocabulary"
      ],
      "metadata": {
        "id": "VSxRhOzHt82U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import Vectors\n",
        "\n",
        "english_fasttext_vectors = Vectors(name='data/wiki-news-300d-1M.vec')\n",
        "\n",
        "# 단어 벡터의 내용 확인\n",
        "print(\"한 단어를 표현하는 차원 수: \", english_fasttext_vectors.dim)\n",
        "print(\"단어 수: \", len(english_fasttext_vectors.itos))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1GHhef8t7mM",
        "outputId": "b576ec1a-9737-4f6e-dc66-19b074228ae8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한 단어를 표현하는 차원 수:  300\n",
            "단어 수:  999994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorized Vocabulary\n",
        "TEXT.build_vocab(train_ds, vectors=english_fasttext_vectors, min_freq=10)\n",
        "\n",
        "print(TEXT.vocab.vectors.shape)  # 17916개의 단어가 300차원 벡터로 표현되어 있음\n",
        "TEXT.vocab.vectors\n",
        "\n",
        "# vocabulary 단어 순서 확인\n",
        "# TEXT.vocab.stoi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-fGcgrct7pN",
        "outputId": "e97dd4fb-cdfb-4ff6-fa4b-8367746253b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([17887, 300])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        ...,\n",
              "        [-0.0276,  0.0025, -0.1891,  ...,  0.0869, -0.0658, -0.1441],\n",
              "        [-0.1011, -0.0481,  0.1376,  ...,  0.0959,  0.0863, -0.0949],\n",
              "        [ 0.0147, -0.0415,  0.0006,  ...,  0.0387, -0.0181, -0.0128]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = torchtext.legacy.data.Iterator(train_ds, batch_size=24, train=True)\n",
        "\n",
        "val_dl = torchtext.legacy.data.Iterator(\n",
        "    val_ds, batch_size=24, train=False, sort=False)\n",
        "\n",
        "test_dl = torchtext.legacy.data.Iterator(\n",
        "    test_ds, batch_size=24, train=False, sort=False)\n",
        "\n",
        "# 동작 확인\n",
        "batch = next(iter(val_dl))\n",
        "print(batch.Text)\n",
        "print(batch.Label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY3ps-CPuUI4",
        "outputId": "2faebf45-e3c3-4062-ca96-78ac4ac491ed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[   2,   52,    8,  ...,    1,    1,    1],\n",
            "        [   2,   52,   17,  ...,    1,    1,    1],\n",
            "        [   2,   14, 1634,  ...,    1,    1,    1],\n",
            "        ...,\n",
            "        [   2,   21,    8,  ...,    1,    1,    1],\n",
            "        [   2,   15,   11,  ...,  134, 2910,    3],\n",
            "        [   2,   35,   26,  ...,    1,    1,    1]]), tensor([140, 211, 139, 256, 146, 109, 256, 256, 256,  58, 256, 177, 256, 256,\n",
            "        139, 165, 256, 256, 256, 160, 164, 187, 256, 223]))\n",
            "tensor([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torchtext"
      ],
      "metadata": {
        "id": "qTC0bUr_pzij"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding"
      ],
      "metadata": {
        "id": "o0ehK5A5p361"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedder(nn.Module):\n",
        "    '''개별 단어의 ID에 따라 단어의 벡터 표현 반환'''\n",
        "    \n",
        "    def __init__(self, text_embedding_vectors):\n",
        "        super(Embedder, self).__init__()\n",
        "        \n",
        "        # fasttext의 pre-trained된 벡터 표현 이용  \n",
        "        self.embeddings = nn.Embedding.from_pretrained(\n",
        "            embeddings=text_embedding_vectors, freeze=True)  # 역전파에 의해 갱신되지 않도록 가중치 '동결'\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x_vec = self.embeddings(x)  # 단어 수 x 300(Embedding에 의한 분산 표현의 차원)\n",
        "\n",
        "        return x_vec"
      ],
      "metadata": {
        "id": "XVLlIbWjpz_o"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gymoon10/utils.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsm1doMsuygN",
        "outputId": "c93ad6f8-611b-4bd4-cdd8-da1bd9e3c8a3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'utils' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dl))\n",
        "\n",
        "# Embedding\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # 단어를 벡터로\n",
        "\n",
        "print(\"입력 텐서 크기: \", x.shape)  # 24개의 sequence는 각각 256개의 단어들로 구성되어 있음\n",
        "print(\"Embedding된 출력 텐서 크기: \", x1.shape)  # 256개의 각 단어가 300차원의 분산 표현 벡터로 변환됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA5qDmftqyr7",
        "outputId": "1dadafa0-f210-468e-f9a2-b04305f5a75a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 텐서 크기:  torch.Size([24, 256])\n",
            "Embedding된 출력 텐서 크기:  torch.Size([24, 256, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Encoding\n",
        "\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/150710146-0db579e8-3c76-4965-827e-415b2efabdd7.png)"
      ],
      "metadata": {
        "id": "8XW_-DQkywUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "    '''단어의 위치 정보를 표현하는 벡터 (위의 Embedding 차원과 동일한 크기)\n",
        "       (단어 수, 분산 표현의 차원 수) 크기의 Embedding된 단어 벡터를 입력으로 받음'''\n",
        "    \n",
        "    def __init__(self, d_model=300, max_seq_len=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model  # 개별 단어 벡터의 분산 표현 차원 (fastText : 300)\n",
        "        pe = torch.zeros(max_seq_len, d_model)  # (단어 수 x 분산 표현의 차원수) - (256, 300)\n",
        "\n",
        "        #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        #pe = pe.to(device)\n",
        "\n",
        "        for pos in range(max_seq_len):  # 각 단어 별로 처리\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / d_model)))  # 수식 참고\n",
        "                pe[pos, i+1] = math.cos(pos / (10000 ** ((2 * i) / d_model)))\n",
        "\n",
        "        self.pe = pe.unsqueeze(0)  # (1, 256, 300) - minibatch의 차원 추가\n",
        "        self.pe.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        ret = math.sqrt(self.d_model)*x + self.pe\n",
        "        \n",
        "        return ret"
      ],
      "metadata": {
        "id": "AEhZfq5DrRAy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # 단어 -> 벡터\n",
        "x2 = net2(x1)  # Positional encoding\n",
        "\n",
        "print(\"Embedding된 입력 텐서 크기: \", x1.shape)\n",
        "print(\"위치 정보가 더해진 출력 텐서 크기: \", x2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTEWFzRn1Hc_",
        "outputId": "def0897f-ce79-425d-9c67-514a1aefc5eb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding된 입력 텐서 크기:  torch.Size([24, 256, 300])\n",
            "위치 정보가 더해진 출력 텐서 크기:  torch.Size([24, 256, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention\n",
        "\n",
        "Scaled-dot (single head)\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/150711518-3bdd8fa6-1f3b-4482-b9c2-2cc207385926.png)"
      ],
      "metadata": {
        "id": "NIdPYgpd2EH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):  \n",
        "\n",
        "    def __init__(self, d_model=300):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Query Key Value\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # scale 조정 변수\n",
        "        self.d_k = d_model\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        q = self.q_linear(q)  # (24, 256, 300)\n",
        "        k = self.k_linear(k)\n",
        "        v = self.v_linear(v)\n",
        "        \n",
        "        # Attention value 계산\n",
        "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)  # (24, 256, 256)\n",
        "\n",
        "        # Masking\n",
        "        mask = mask.unsqueeze(1)  # (24, 1, 256)\n",
        "        weights = weights.masked_fill(mask==0, -1e9)  # mask=0인 부분을 지정된 값으로 채움\n",
        "        \n",
        "        # Attention Map\n",
        "        normalized_weights = F.softmax(weights, dim=-1)\n",
        "        output = torch.matmul(normalized_weights, v)  # (24, 256, 300)  \n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, normalized_weights"
      ],
      "metadata": {
        "id": "KrF3s3Qf1Hjt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Position Wise Feed-Forward"
      ],
      "metadata": {
        "id": "aPU1UXhM5RkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.dropout(F.relu(x))\n",
        "        x = self.linear_2(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "q6su8uUc5Qbb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer"
      ],
      "metadata": {
        "id": "xQb9E_S45z4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Layer Normalization layer\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "        \n",
        "        # Attention layer\n",
        "        self.attn = Attention(d_model)\n",
        "        \n",
        "        # Position wise Feed-Forward layer\n",
        "        self.ff = FeedForward(d_model)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):  # x : (24, 256, 300) / mask : (24, 256)\n",
        "        x_normalized = self.norm_1(x)\n",
        "        output, normalized_weights = self.attn(x_normalized, x_normalized, x_normalized, mask)  # output : (24, 256, 300)  \n",
        "        \n",
        "        # skip-conn\n",
        "        x2 = x + self.dropout_1(output)  # (24, 256, 300)\n",
        "        \n",
        "        x_normalized2 = self.norm_2(x2)\n",
        "        output = x2 + self.dropout_2(self.ff(x_normalized2))\n",
        "\n",
        "        return output, normalized_weights"
      ],
      "metadata": {
        "id": "eM3_aRgG5g8n"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "net3 = TransformerBlock(d_model=300)\n",
        "\n",
        "# Mask\n",
        "x = batch.Text[0]  # (24, 256) - 256개의 단어들에 Attention 연산을 적용할 지 여부 (1:적용 / 0:미적용)\n",
        "input_pad = 1\n",
        "input_mask = torch.where(x != input_pad, 1, 0)\n",
        "\n",
        "x1 = net1(x)  \n",
        "x2 = net2(x1)  \n",
        "x3, normalized_weights = net3(x2, input_mask) \n",
        "\n",
        "print(\"입력 텐서 크기: \", x2.shape)\n",
        "print(\"출력 텐서 크기: \", x3.shape)\n",
        "print(\"Attention 크기: \", normalized_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR-fSxPi7qvk",
        "outputId": "959c83d4-9333-4ff3-8092-5cea9a441bd6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 텐서 크기:  torch.Size([24, 256, 300])\n",
            "출력 텐서 크기:  torch.Size([24, 256, 300])\n",
            "Attention 크기:  torch.Size([24, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('입력 단어 벡터 :')\n",
        "print(x[1])\n",
        "print()\n",
        "print('Mask 벡터:')\n",
        "print(input_mask[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkfMIk98PUbb",
        "outputId": "6b2bac09-bacc-42bc-e56d-c0924e9b8380"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 단어 벡터 :\n",
            "tensor([    2,    12,    11,    28,     4,   175,    19,     4,    85,   110,\n",
            "           48,  1102,     5,     8,   176,  1220,    80,   259,   525,    42,\n",
            "         1102,     5,  1026,     4,  1102,   110,    13,   340,     6,     4,\n",
            "          107,    13,    15,    24,    30,    28,  2183,    46,   872,   188,\n",
            "           80,     5,    37,    30,   287,    16,    26,   205,    70,  2735,\n",
            "           13,   134, 13264,     5,    37,    30,    53,  4388,    48,    71,\n",
            "          461,     7,   421,   174,   525,     7,    71,  1317,    42,  1102,\n",
            "            5,    15,  2443,    75,    57,  1656,     5,     3,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1])\n",
            "\n",
            "Mask 벡터:\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention 연산 개요"
      ],
      "metadata": {
        "id": "zV731cOS8d_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = x2  # (24, 256, 300)\n",
        "mask = input_mask  # (24, 256)\n",
        "d_model = 300\n",
        "d_k = 300\n",
        "\n",
        "q_linear = nn.Linear(d_model, d_model)\n",
        "v_linear = nn.Linear(d_model, d_model)\n",
        "k_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "k = k_linear(input)  # (24, 256, 300)\n",
        "q = q_linear(input)\n",
        "v = v_linear(input)\n",
        "\n",
        "weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(d_k)  # (24, 256, 256)\n",
        "\n",
        "mask = mask.unsqueeze(1) # (24, 1, 256)\n",
        "weights = weights.masked_fill(mask == 0, -1e9) # (24, 256, 256)\n",
        "\n",
        "normalized_weights = F.softmax(weights, dim=-1)  # (24, 256, 256)\n",
        "output = torch.matmul(normalized_weights, v)  # (24, 256, 300)"
      ],
      "metadata": {
        "id": "OY86VB5K93wp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification Head\n",
        "\n",
        "TransformerBlock 모듈을 반복하여 나온 출력을 입력 받아 분류 예측 수행"
      ],
      "metadata": {
        "id": "pJsgXBnB8rvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    '''Transformer_Block의 출력을 사용하여 긍정/부정 분류 수행'''\n",
        "\n",
        "    def __init__(self, d_model=300, output_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear = nn.Linear(d_model, output_dim)  \n",
        "        \n",
        "        # 가중치 초기화\n",
        "        nn.init.normal_(self.linear.weight, std=0.02)\n",
        "        nn.init.normal_(self.linear.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = x[:, 0, :]  # 각 미니 배치(문장 sequence)에서 첫 번째 단어([CLS])의 representation추출\n",
        "        out = self.linear(x0)  # 감성 분류 수행\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "0Y-B0lMrBajn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dl))\n",
        "\n",
        "net1 = Embedder(TEXT.vocab.vectors)\n",
        "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
        "net3 = TransformerBlock(d_model=300)\n",
        "net4 = ClassificationHead(output_dim=2, d_model=300)\n",
        "\n",
        "x = batch.Text[0]\n",
        "x1 = net1(x)  # word embedding\n",
        "x2 = net2(x1)  # add positon embedding\n",
        "x3, normlized_weights = net3(x2, input_mask)  # Self-Attention\n",
        "x4 = net4(x3)  # 최종 출력의 0번째 단어를([CLS]) 사용하여, 분류 결과 출력\n",
        "\n",
        "print(\"입력 텐서 사이즈: \", x3.shape)\n",
        "print(\"출력 텐서 사이즈: \", x4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyie4Z189FH_",
        "outputId": "c5dd2435-b09a-41b5-93ae-157fdda67a38"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 텐서 사이즈:  torch.Size([24, 256, 300])\n",
            "출력 텐서 사이즈:  torch.Size([24, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTgrjsPa-tKr",
        "outputId": "2bfe36a1-8ba8-4aae-bfe1-79fa336527f9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.0942,  0.6606],\n",
              "        [-2.0327,  0.7043],\n",
              "        [-2.0396,  0.7601],\n",
              "        [-2.0260,  0.7558],\n",
              "        [-2.0614,  0.6709],\n",
              "        [-2.0653,  0.7512],\n",
              "        [-2.0462,  0.6340],\n",
              "        [-2.0345,  0.6139],\n",
              "        [-2.0876,  0.6783],\n",
              "        [-2.1357,  0.6143],\n",
              "        [-1.9574,  0.7648],\n",
              "        [-1.9603,  0.7537],\n",
              "        [-1.9933,  0.6586],\n",
              "        [-2.0521,  0.7081],\n",
              "        [-2.0625,  0.6678],\n",
              "        [-2.0148,  0.6663],\n",
              "        [-2.0907,  0.6845],\n",
              "        [-1.9380,  0.6660],\n",
              "        [-2.0109,  0.7194],\n",
              "        [-2.0861,  0.6188],\n",
              "        [-1.9956,  0.6884],\n",
              "        [-1.9384,  0.6976],\n",
              "        [-2.0447,  0.7043],\n",
              "        [-2.1579,  0.7072]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 최종 Transformer 모듈 Class"
      ],
      "metadata": {
        "id": "BZCaFbJG_iBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassification(nn.Module):\n",
        "\n",
        "    def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=256, output_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.net1 = Embedder(text_embedding_vectors)\n",
        "        self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
        "        self.net3_1 = TransformerBlock(d_model=d_model)\n",
        "        self.net3_2 = TransformerBlock(d_model=d_model)\n",
        "        self.net4 = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x1 = self.net1(x)  \n",
        "        x2 = self.net2(x1)  \n",
        "        x3_1, normlized_weights_1 = self.net3_1(x2, mask)  \n",
        "        x3_2, normlized_weights_2 = self.net3_2(x3_1, mask)  \n",
        "        x4 = self.net4(x3_2)  \n",
        "\n",
        "        return x4, normlized_weights_1, normlized_weights_2"
      ],
      "metadata": {
        "id": "D-TXK_wq-gYJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Module\n",
        "net = TransformerClassification(\n",
        "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=2)\n",
        "\n",
        "x = batch.Text[0]\n",
        "input_mask = (x != input_pad)\n",
        "out, normlized_weights_1, normlized_weights_2 = net(x, input_mask)\n",
        "\n",
        "print(\"출력 텐서 크기: \", out.shape)\n",
        "print(\"출력 텐서의 sigmoid: \", F.softmax(out, dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYcq10B_Af3N",
        "outputId": "8b675ccb-2b39-490c-ec80-8ceb6d17b5e3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "출력 텐서 크기:  torch.Size([24, 2])\n",
            "출력 텐서의 sigmoid:  tensor([[0.3377, 0.6623],\n",
            "        [0.3233, 0.6767],\n",
            "        [0.3259, 0.6741],\n",
            "        [0.3443, 0.6557],\n",
            "        [0.3231, 0.6769],\n",
            "        [0.3467, 0.6533],\n",
            "        [0.3252, 0.6748],\n",
            "        [0.3255, 0.6745],\n",
            "        [0.3040, 0.6960],\n",
            "        [0.3249, 0.6751],\n",
            "        [0.3414, 0.6586],\n",
            "        [0.3187, 0.6813],\n",
            "        [0.3625, 0.6375],\n",
            "        [0.2948, 0.7052],\n",
            "        [0.3440, 0.6560],\n",
            "        [0.3079, 0.6921],\n",
            "        [0.3238, 0.6762],\n",
            "        [0.2876, 0.7124],\n",
            "        [0.3664, 0.6336],\n",
            "        [0.3343, 0.6657],\n",
            "        [0.3550, 0.6450],\n",
            "        [0.3269, 0.6731],\n",
            "        [0.3200, 0.6800],\n",
            "        [0.3329, 0.6671]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "gpu 사용에 에러가 발생하여 위의 과정으로 구현한 Transformer 모듈을 import 해서 사용하는 방식으로 학습 진행\n",
        "\n",
        "https://github.com/YutaroOgawa/pytorch_advanced/tree/master/7_nlp_sentiment_transformer/utils"
      ],
      "metadata": {
        "id": "fcj-JaooBO_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "net = TransformerClassification(\n",
        "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=2)\n",
        "\n",
        "# Init\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Linear') != -1:\n",
        "        nn.init.kaiming_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "# Train\n",
        "net.train()\n",
        "\n",
        "# TransformerBlock 초기화\n",
        "net.net3_1.apply(weights_init)\n",
        "net.net3_2.apply(weights_init)\n",
        "\n",
        "print('네트워크 설정 완료')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--uiRQDPAlQO",
        "outputId": "301b7a21-cba2-4f66-c06d-13959b25049c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "네트워크 설정 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# nn.LogSoftmax()을 계산한 뒤 nn.NLLLoss(negative log likelihood loss)를 계산\n",
        "\n",
        "# 최적화 기법 설정\n",
        "learning_rate = 2e-5\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "6QTbpQ9oBcsn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"사용 장치: \", device)\n",
        "    print('-----start-------')\n",
        "\n",
        "    net.cuda()\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  \n",
        "            else:\n",
        "                net.eval()   \n",
        "\n",
        "            epoch_loss = 0.0  # epoch별 total loss\n",
        "            epoch_corrects = 0  # epoch별 정답의 수 \n",
        "\n",
        "            for batch in (dataloaders_dict[phase]):  # batch는 Text와 Lable의 사전 오브젝트\n",
        "\n",
        "                #inputs = batch.Text[0]  # 문장 sequence\n",
        "                #labels = batch.Label  # 정답 label\n",
        "\n",
        "                inputs = batch.Text[0].cuda()  # 문장\n",
        "                labels = batch.Label.cuda()  # 라벨\n",
        "\n",
        "                # optimizer 초기화\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # mask 작성\n",
        "                    input_pad = 1  # 단어 ID에 있어서, '<pad>': 1이므로\n",
        "                    input_mask = (inputs != input_pad)\n",
        "\n",
        "                    # minibatch의 문장 sequence, mask를 Transformer에 입력\n",
        "                    outputs, _, _ = net(inputs, input_mask)\n",
        "                    loss = criterion(outputs, labels)  # loss\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  # prediction\n",
        "\n",
        "                    # 학습 시에는 역전파 수행\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # 결과 계산\n",
        "                    epoch_loss += loss.item() * inputs.size(0)  #\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epoch별 loss와 정답률\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return net"
      ],
      "metadata": {
        "id": "ygUwDVV5CicB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}"
      ],
      "metadata": {
        "id": "W-1OAqZLEN2Q"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "net_trained = train_model(net, dataloaders_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "md6wMrgbDXVN",
        "outputId": "ff9a004c-fc79-41b7-9b74-5d1490ed4768"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용 장치:  cuda:0\n",
            "-----start-------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-b2b7db09cbfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m net_trained = train_model(net, dataloaders_dict,\n\u001b[0;32m----> 3\u001b[0;31m                           criterion, optimizer, num_epochs=num_epochs)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-3a281350290e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, dataloaders_dict, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0;31m# minibatch의 문장 sequence, mask를 Transformer에 입력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-57f4323fee3d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx3_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormlized_weights_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet3_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx3_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormlized_weights_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet3_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-e0527d711530>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 구현된 module을 import해서 학습"
      ],
      "metadata": {
        "id": "upx5zTwbU5S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gymoon10/utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caHMCj5hRn5P",
        "outputId": "1e7e3579-5b31-49c9-f8ca-e6ea46eb7ddc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'utils' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.transformer import TransformerClassification\n",
        "\n",
        "net = TransformerClassification(\n",
        "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=2)"
      ],
      "metadata": {
        "id": "Iao54Z6SRn9x"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.train()\n",
        "\n",
        "net.net3_1.apply(weights_init)\n",
        "net.net3_2.apply(weights_init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJoFjkqtRoAj",
        "outputId": "ebe7e696-ac3a-433c-a9d4-b2ef45cf2ef1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerBlock(\n",
              "  (norm_1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
              "  (norm_2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
              "  (attn): Attention(\n",
              "    (q_linear): Linear(in_features=300, out_features=300, bias=True)\n",
              "    (v_linear): Linear(in_features=300, out_features=300, bias=True)\n",
              "    (k_linear): Linear(in_features=300, out_features=300, bias=True)\n",
              "    (out): Linear(in_features=300, out_features=300, bias=True)\n",
              "  )\n",
              "  (ff): FeedForward(\n",
              "    (linear_1): Linear(in_features=300, out_features=1024, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (linear_2): Linear(in_features=1024, out_features=300, bias=True)\n",
              "  )\n",
              "  (dropout_1): Dropout(p=0.1, inplace=False)\n",
              "  (dropout_2): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 2e-5\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "we3P1ynVU1Dr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "net_trained = train_model(net, dataloaders_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAiiv4CrRoDU",
        "outputId": "f7ff280d-3ff5-44f5-fb2c-ddf03521d9f6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용 장치:  cuda:0\n",
            "-----start-------\n",
            "Epoch 1/10 | train |  Loss: 0.5282 Acc: 0.7212\n",
            "Epoch 1/10 |  val  |  Loss: 0.3875 Acc: 0.8228\n",
            "Epoch 2/10 | train |  Loss: 0.3997 Acc: 0.8209\n",
            "Epoch 2/10 |  val  |  Loss: 0.3582 Acc: 0.8372\n",
            "Epoch 3/10 | train |  Loss: 0.3747 Acc: 0.8356\n",
            "Epoch 3/10 |  val  |  Loss: 0.3433 Acc: 0.8534\n",
            "Epoch 4/10 | train |  Loss: 0.3585 Acc: 0.8430\n",
            "Epoch 4/10 |  val  |  Loss: 0.3723 Acc: 0.8388\n",
            "Epoch 5/10 | train |  Loss: 0.3463 Acc: 0.8494\n",
            "Epoch 5/10 |  val  |  Loss: 0.3253 Acc: 0.8594\n",
            "Epoch 6/10 | train |  Loss: 0.3423 Acc: 0.8518\n",
            "Epoch 6/10 |  val  |  Loss: 0.3224 Acc: 0.8624\n",
            "Epoch 7/10 | train |  Loss: 0.3339 Acc: 0.8557\n",
            "Epoch 7/10 |  val  |  Loss: 0.3174 Acc: 0.8678\n",
            "Epoch 8/10 | train |  Loss: 0.3253 Acc: 0.8600\n",
            "Epoch 8/10 |  val  |  Loss: 0.3173 Acc: 0.8684\n",
            "Epoch 9/10 | train |  Loss: 0.3173 Acc: 0.8628\n",
            "Epoch 9/10 |  val  |  Loss: 0.3290 Acc: 0.8626\n",
            "Epoch 10/10 | train |  Loss: 0.3112 Acc: 0.8676\n",
            "Epoch 10/10 |  val  |  Loss: 0.3218 Acc: 0.8656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "mA7_Kg6ZJK1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net_trained.eval()   \n",
        "net_trained.to(device)\n",
        "\n",
        "epoch_corrects = 0 \n",
        "\n",
        "for batch in (test_dl):  # test 데이터의 DataLoader\n",
        "\n",
        "    inputs = batch.Text[0].to(device)  \n",
        "    labels = batch.Label.to(device)  \n",
        "\n",
        "    # 순전파(forward) 계산\n",
        "    with torch.set_grad_enabled(False):\n",
        "\n",
        "        # mask 작성\n",
        "        input_pad = 1  # 단어 ID에 있어서, '<pad>': 1이므로\n",
        "        input_mask = (inputs != input_pad)\n",
        "\n",
        "        # Transformer에 입력\n",
        "        outputs, _, _ = net_trained(inputs, input_mask)\n",
        "        _, preds = torch.max(outputs, 1)  # 라벨을 예측\n",
        "\n",
        "        # 결과 계산\n",
        "        # 정답수의 합계를 갱신\n",
        "        epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "# 정답률\n",
        "epoch_acc = epoch_corrects.double() / len(test_dl.dataset)\n",
        "\n",
        "print('테스트 데이터 {}개의 정답률: {:.4f}'.format(len(test_dl.dataset),epoch_acc))"
      ],
      "metadata": {
        "id": "k5IQfv-oEGxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97549277-3ef3-4737-b945-b2aaff9c06a1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터 25000개의 정답률: 0.8532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HTML 작성 함수 구현\n",
        "def highlight(word, attn):\n",
        "    \"Attention 값이 클 때 문자 배경을 진한 빨간색으로 하는 html을 출력하는 함수\"\n",
        "\n",
        "    html_color = '#%02X%02X%02X' % (\n",
        "        255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
        "    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, word)\n",
        "\n",
        "\n",
        "def mk_html(index, batch, preds, normalized_weights_1, normalized_weights_2, TEXT):\n",
        "    \"HTML 데이터를 작성한다\"\n",
        "\n",
        "    # index에 해당하는 결과 추출\n",
        "    sentence = batch.Text[0][index]  # Sentence\n",
        "    label = batch.Label[index]  # Label\n",
        "    pred = preds[index]  # Prediction\n",
        "\n",
        "    # index에 해당하는 Attention map 추출\n",
        "    attens1 = normalized_weights_1[index, 0, :]  # 0번째의 <cls>의 Attention\n",
        "    attens1 /= attens1.max()\n",
        "\n",
        "    attens2 = normalized_weights_2[index, 0, :]  # 0번째의 <cls>의 Attention\n",
        "    attens2 /= attens2.max()\n",
        "\n",
        "    if label == 0:\n",
        "        label_str = \"Negative\"\n",
        "    else:\n",
        "        label_str = \"Positive\"\n",
        "\n",
        "    if pred == 0:\n",
        "        pred_str = \"Negative\"\n",
        "    else:\n",
        "        pred_str = \"Positive\"\n",
        "\n",
        "    # 표시용 HTML 작성\n",
        "    html = '정답 라벨: {}<br>추론 라벨: {}<br><br>'.format(label_str, pred_str)\n",
        "\n",
        "    # 첫번째 단의 Attention\n",
        "    html += '[TransformerBlock의 첫번째 단의 Attention을 시각화]<br>'\n",
        "    for word, attn in zip(sentence, attens1):\n",
        "        html += highlight(TEXT.vocab.itos[word], attn)\n",
        "    html += \"<br><br>\"\n",
        "\n",
        "    # 두번째 단의 Attention\n",
        "    html += '[TransformerBlock의 두번째 단의 Attention을 시각화]<br>'\n",
        "    for word, attn in zip(sentence, attens2):\n",
        "        html += highlight(TEXT.vocab.itos[word], attn)\n",
        "\n",
        "    html += \"<br><br>\"\n",
        "\n",
        "    return html"
      ],
      "metadata": {
        "id": "sa0Tz1kITQKZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "# Transformer로 처리\n",
        "\n",
        "# 미니 배치 준비\n",
        "batch = next(iter(test_dl))\n",
        "\n",
        "# GPU가 사용 가능하면 GPU로 데이터를 보낸다\n",
        "inputs = batch.Text[0].to(device)  # 문장\n",
        "labels = batch.Label.to(device)  # 라벨\n",
        "\n",
        "# mask 작성\n",
        "input_pad = 1  # 단어 ID에 있어서, '<pad>': 1이므로\n",
        "input_mask = (inputs != input_pad)\n",
        "\n",
        "# Transformer에 입력\n",
        "outputs, normalized_weights_1, normalized_weights_2 = net_trained(\n",
        "    inputs, input_mask)\n",
        "_, preds = torch.max(outputs, 1)  # 예측"
      ],
      "metadata": {
        "id": "BVuQqIqTWtL4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 3  # 출력할 데이터\n",
        "html_output = mk_html(index, batch, preds, normalized_weights_1,\n",
        "                      normalized_weights_2, TEXT)  # HTML 작성\n",
        "HTML(html_output)  # HTML 형식으로 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "-u-XsndVX7SE",
        "outputId": "70ce8055-71a0-4bf8-ba46-4fa2ac3b8bdf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "정답 라벨: Positive<br>추론 라벨: Positive<br><br>[TransformerBlock의 첫번째 단의 Attention을 시각화]<br><span style=\"background-color: #FFFDFD\"> <cls></span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> story</span><span style=\"background-color: #FFFDFD\"> of</span><span style=\"background-color: #FFFDFD\"> tom</span><span style=\"background-color: #FFFDFD\"> garner</span><span style=\"background-color: #FFFEFE\"> opens</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> grand</span><span style=\"background-color: #FFFDFD\"> funeral</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFBFB\"> told</span><span style=\"background-color: #FFFEFE\"> through</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFEFE\"> series</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFEDED\"> elegant</span><span style=\"background-color: #FFFEFE\"> flashbacks</span><span style=\"background-color: #FFFEFE\"> narrated</span><span style=\"background-color: #FFFEFE\"> by</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFDFD\"> faithful</span><span style=\"background-color: #FFF7F7\"> lifetime</span><span style=\"background-color: #FFFEFE\"> friend</span><span style=\"background-color: #FFFDFD\"> henry</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> henry</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> wife</span><span style=\"background-color: #FFF9F9\"> debate</span><span style=\"background-color: #FFFEFE\"> whether</span><span style=\"background-color: #FFFDFD\"> tom</span><span style=\"background-color: #FFFDFD\"> was</span><span style=\"background-color: #FFFCFC\"> a</span><span style=\"background-color: #FFDFDF\"> great</span><span style=\"background-color: #FFFEFE\"> man</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFF4F4\"> genius</span><span style=\"background-color: #FFFEFE\"> or</span><span style=\"background-color: #FFFEFE\"> an</span><span style=\"background-color: #FFE1E1\"> utterly</span><span style=\"background-color: #FFF1F1\"> worthless</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> film</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFDDDD\"> beautifully</span><span style=\"background-color: #FFFEFE\"> written</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFDFD\"> acted</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFDFD\"> directed</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFCCCC\"> highly</span><span style=\"background-color: #FFF3F3\"> recommend</span><span style=\"background-color: #FFFEFE\"> it</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> tom</span><span style=\"background-color: #FFFDFD\"> was</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFF2F2\"> rich</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFF2F2\"> successful</span><span style=\"background-color: #FFFEFE\"> owner</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFCFC\"> a</span><span style=\"background-color: #FFF9F9\"> large</span><span style=\"background-color: #FFFEFE\"> railroad</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFEDED\"> dominating</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> board</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> directors</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFCFC\"> competition</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFCFC\"> terrorizing</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFDFD\"> employees</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFE9E9\"> slaughtering</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> tom</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFCFC\"> ambitious</span><span style=\"background-color: #FFFEFE\"> wife</span><span style=\"background-color: #FFFDFD\"> sally</span><span style=\"background-color: #FFFDFD\"> was</span><span style=\"background-color: #FFF5F5\"> responsible</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFBFB\"> all</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFDFD\"> tom</span><span style=\"background-color: #FFFDFD\"> s</span><span style=\"background-color: #FFE6E6\"> success</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> when</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFDFD\"> met</span><span style=\"background-color: #FFFEFE\"> her</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFDFD\"> was</span><span style=\"background-color: #FFEEEE\"> illiterate</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFAFA\"> entirely</span><span style=\"background-color: #FFFCFC\"> content</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> work</span><span style=\"background-color: #FFFEFE\"> as</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> railroad</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> sally</span><span style=\"background-color: #FFFEFE\"> teaches</span><span style=\"background-color: #FFFEFE\"> him</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> read</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> takes</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFF9F9\"> job</span><span style=\"background-color: #FFFCFC\"> while</span><span style=\"background-color: #FFFDFD\"> tom</span><span style=\"background-color: #FFFEFE\"> goes</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> school</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFEFE\"> starts</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFF9F9\"> rise</span><span style=\"background-color: #FFFDFD\"> one</span><span style=\"background-color: #FFFDFD\"> step</span><span style=\"background-color: #FFFEFE\"> at</span><span style=\"background-color: #FFFBFB\"> a</span><span style=\"background-color: #FFFCFC\"> time</span><span style=\"background-color: #FFFEFE\"> through</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> railroad</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> until</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFEFE\"> eventually</span><span style=\"background-color: #FFFEFE\"> takes</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFFEFE\"> as</span><span style=\"background-color: #FFFDFD\"> president</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> but</span><span style=\"background-color: #FFFEFE\"> as</span><span style=\"background-color: #FFFDFD\"> tom</span><span style=\"background-color: #FFFEFE\"> becomes</span><span style=\"background-color: #FFFBFB\"> a</span><span style=\"background-color: #FFFEFE\"> business</span><span style=\"background-color: #FFFEFE\"> tycoon</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFDFD\"> marriage</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFDFD\"> sally</span><span style=\"background-color: #FFFDFD\"> gradually</span><span style=\"background-color: #FFFEFE\"> falls</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> pieces</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFE2E2\"> spoiled</span><span style=\"background-color: #FFFDFD\"> son</span><span style=\"background-color: #FFFDFD\"> <unk></span><span style=\"background-color: #FFFEFE\"> him</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> he</span><span style=\"background-color: #FFFEFE\"> takes</span><span style=\"background-color: #FFFEFE\"> up</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFFCFC\"> a</span><span style=\"background-color: #FFF0F0\"> much</span><span style=\"background-color: #FFFBFB\"> younger</span><span style=\"background-color: #FFFEFE\"> woman</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFE5E5\"> aptly</span><span style=\"background-color: #FFFBFB\"> named</span><span style=\"background-color: #FFFEFE\"> eve</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FF8C8C\"> predictably</span><span style=\"background-color: #FF7B7B\"> catastrophic</span><span style=\"background-color: #FFF4F4\"> consequences</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFDFD\"> his</span><span style=\"background-color: #FFFEFE\"> business</span><span style=\"background-color: #FFFDFD\"> life</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFCFC\"> tom</span><span style=\"background-color: #FFFCFC\"> is</span><span style=\"background-color: #FFFAFA\"> a</span><span style=\"background-color: #FFF5F5\"> total</span><span style=\"background-color: #FFE0E0\"> success</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFDFD\"> his</span><span style=\"background-color: #FFFAFA\"> personal</span><span style=\"background-color: #FFFDFD\"> life</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFBFB\"> a</span><span style=\"background-color: #FFABAB\"> disastrous</span><span style=\"background-color: #FFC0C0\"> failure</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFEFEF\"> much</span><span style=\"background-color: #FFFBFB\"> like</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> hearst</span><span style=\"background-color: #FFFEFE\"> figure</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> citizen</span><span style=\"background-color: #FFFEFE\"> kane</span><span style=\"background-color: #FFFEFE\"> ,</span><span style=\"background-color: #FFFDFD\"> tom</span><span style=\"background-color: #FFFBFB\"> symbolizes</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFC8C8\"> best</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FF0000\"> worst</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFBFB\"> capitalist</span><span style=\"background-color: #FFF1F1\"> system</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> spencer</span><span style=\"background-color: #FFFEFE\"> tracy</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FF9090\"> terrific</span><span style=\"background-color: #FFFEFE\"> in</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> role</span><span style=\"background-color: #FFFEFE\"> <eos></span><br><br>[TransformerBlock의 두번째 단의 Attention을 시각화]<br><span style=\"background-color: #FFFEFE\"> <cls></span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> story</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> tom</span><span style=\"background-color: #FFF4F4\"> garner</span><span style=\"background-color: #FFFCFC\"> opens</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> grand</span><span style=\"background-color: #FFFEFE\"> funeral</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFDFD\"> told</span><span style=\"background-color: #FFFCFC\"> through</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFCFC\"> series</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> elegant</span><span style=\"background-color: #FFFEFE\"> flashbacks</span><span style=\"background-color: #FFFEFE\"> narrated</span><span style=\"background-color: #FFFEFE\"> by</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> faithful</span><span style=\"background-color: #FFFCFC\"> lifetime</span><span style=\"background-color: #FFFEFE\"> friend</span><span style=\"background-color: #FFF6F6\"> henry</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFF7F7\"> henry</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> wife</span><span style=\"background-color: #FFFEFE\"> debate</span><span style=\"background-color: #FFFEFE\"> whether</span><span style=\"background-color: #FFFEFE\"> tom</span><span style=\"background-color: #FFFDFD\"> was</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFEFE\"> great</span><span style=\"background-color: #FFFEFE\"> man</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> genius</span><span style=\"background-color: #FFFEFE\"> or</span><span style=\"background-color: #FFFEFE\"> an</span><span style=\"background-color: #FFF9F9\"> utterly</span><span style=\"background-color: #FFA4A4\"> worthless</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> film</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFEDED\"> beautifully</span><span style=\"background-color: #FFFDFD\"> written</span><span style=\"background-color: #FFF7F7\"> ,</span><span style=\"background-color: #FFFEFE\"> acted</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> directed</span><span style=\"background-color: #FFFAFA\"> ,</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFDFD\"> i</span><span style=\"background-color: #FFFEFE\"> highly</span><span style=\"background-color: #FFFCFC\"> recommend</span><span style=\"background-color: #FFD9D9\"> it</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> tom</span><span style=\"background-color: #FFFEFE\"> was</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> rich</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> successful</span><span style=\"background-color: #FFF9F9\"> owner</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> large</span><span style=\"background-color: #FFFEFE\"> railroad</span><span style=\"background-color: #FFF3F3\"> ,</span><span style=\"background-color: #FFFEFE\"> dominating</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> board</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> directors</span><span style=\"background-color: #FFFEFE\"> and</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> competition</span><span style=\"background-color: #FFF6F6\"> ,</span><span style=\"background-color: #FFFEFE\"> terrorizing</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> employees</span><span style=\"background-color: #FFEDED\"> ,</span><span style=\"background-color: #FFFEFE\"> slaughtering</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> tom</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFEFE\"> ambitious</span><span style=\"background-color: #FFFEFE\"> wife</span><span style=\"background-color: #FFFEFE\"> sally</span><span style=\"background-color: #FFFEFE\"> was</span><span style=\"background-color: #FFFEFE\"> responsible</span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFDFD\"> all</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> tom</span><span style=\"background-color: #FFFEFE\"> s</span><span style=\"background-color: #FFFEFE\"> success</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFDFD\"> when</span><span style=\"background-color: #FFF0F0\"> he</span><span style=\"background-color: #FFFEFE\"> met</span><span style=\"background-color: #FFFEFE\"> her</span><span style=\"background-color: #FFDFDF\"> ,</span><span style=\"background-color: #FFEEEE\"> he</span><span style=\"background-color: #FFFDFD\"> was</span><span style=\"background-color: #FF0000\"> illiterate</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFEFE\"> entirely</span><span style=\"background-color: #FFFEFE\"> content</span><span style=\"background-color: #FFFDFD\"> with</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> work</span><span style=\"background-color: #FFFAFA\"> as</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> for</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> railroad</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> sally</span><span style=\"background-color: #FFFEFE\"> teaches</span><span style=\"background-color: #FFFEFE\"> him</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> read</span><span style=\"background-color: #FFFCFC\"> and</span><span style=\"background-color: #FFFEFE\"> takes</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> job</span><span style=\"background-color: #FFEBEB\"> while</span><span style=\"background-color: #FFFEFE\"> tom</span><span style=\"background-color: #FFFEFE\"> goes</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> school</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF7F7\"> he</span><span style=\"background-color: #FFFBFB\"> starts</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> rise</span><span style=\"background-color: #FFF0F0\"> one</span><span style=\"background-color: #FFFDFD\"> step</span><span style=\"background-color: #FFFDFD\"> at</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFBFB\"> time</span><span style=\"background-color: #FFFCFC\"> through</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> railroad</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFCFC\"> until</span><span style=\"background-color: #FFFAFA\"> he</span><span style=\"background-color: #FFE5E5\"> eventually</span><span style=\"background-color: #FFFEFE\"> takes</span><span style=\"background-color: #FFFEFE\"> over</span><span style=\"background-color: #FFFDFD\"> as</span><span style=\"background-color: #FFFAFA\"> president</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFF7F7\"> but</span><span style=\"background-color: #FFFBFB\"> as</span><span style=\"background-color: #FFFEFE\"> tom</span><span style=\"background-color: #FFFEFE\"> becomes</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFEFE\"> business</span><span style=\"background-color: #FFF8F8\"> tycoon</span><span style=\"background-color: #FFF3F3\"> ,</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> marriage</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFEFE\"> sally</span><span style=\"background-color: #FFFBFB\"> gradually</span><span style=\"background-color: #FFFDFD\"> falls</span><span style=\"background-color: #FFFEFE\"> to</span><span style=\"background-color: #FFFBFB\"> pieces</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFDFD\"> spoiled</span><span style=\"background-color: #FFFEFE\"> son</span><span style=\"background-color: #FFFEFE\"> <unk></span><span style=\"background-color: #FFFEFE\"> him</span><span style=\"background-color: #FFE6E6\"> ,</span><span style=\"background-color: #FFFBFB\"> and</span><span style=\"background-color: #FFF1F1\"> he</span><span style=\"background-color: #FFFEFE\"> takes</span><span style=\"background-color: #FFFCFC\"> up</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFEFE\"> much</span><span style=\"background-color: #FFFEFE\"> younger</span><span style=\"background-color: #FFF3F3\"> woman</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFF9F9\"> aptly</span><span style=\"background-color: #FFFEFE\"> named</span><span style=\"background-color: #FFFEFE\"> eve</span><span style=\"background-color: #FFF1F1\"> ,</span><span style=\"background-color: #FFFEFE\"> with</span><span style=\"background-color: #FFF1F1\"> predictably</span><span style=\"background-color: #FFFDFD\"> catastrophic</span><span style=\"background-color: #FFFEFE\"> consequences</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFDFD\"> in</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> business</span><span style=\"background-color: #FFFEFE\"> life</span><span style=\"background-color: #FFF2F2\"> ,</span><span style=\"background-color: #FFFEFE\"> tom</span><span style=\"background-color: #FFFEFE\"> is</span><span style=\"background-color: #FFFEFE\"> a</span><span style=\"background-color: #FFFDFD\"> total</span><span style=\"background-color: #FFFEFE\"> success</span><span style=\"background-color: #FFFCFC\"> in</span><span style=\"background-color: #FFFEFE\"> his</span><span style=\"background-color: #FFFEFE\"> personal</span><span style=\"background-color: #FFFDFD\"> life</span><span style=\"background-color: #FFE1E1\"> ,</span><span style=\"background-color: #FFFDFD\"> a</span><span style=\"background-color: #FFFEFE\"> disastrous</span><span style=\"background-color: #FFFAFA\"> failure</span><span style=\"background-color: #FFFDFD\"> .</span><span style=\"background-color: #FFFEFE\"> much</span><span style=\"background-color: #FFFBFB\"> like</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFEFE\"> hearst</span><span style=\"background-color: #FFF7F7\"> figure</span><span style=\"background-color: #FFFCFC\"> in</span><span style=\"background-color: #FFFEFE\"> citizen</span><span style=\"background-color: #FFF9F9\"> kane</span><span style=\"background-color: #FFF4F4\"> ,</span><span style=\"background-color: #FFFEFE\"> tom</span><span style=\"background-color: #FFFEFE\"> symbolizes</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFDFD\"> best</span><span style=\"background-color: #FFFDFD\"> and</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FF9D9D\"> worst</span><span style=\"background-color: #FFFEFE\"> of</span><span style=\"background-color: #FFFEFE\"> the</span><span style=\"background-color: #FFFCFC\"> capitalist</span><span style=\"background-color: #FFFCFC\"> system</span><span style=\"background-color: #FFFEFE\"> .</span><span style=\"background-color: #FFFEFE\"> spencer</span><span style=\"background-color: #FFFCFC\"> tracy</span><span style=\"background-color: #FFFDFD\"> is</span><span style=\"background-color: #FFFCFC\"> terrific</span><span style=\"background-color: #FFF9F9\"> in</span><span style=\"background-color: #FFFDFD\"> the</span><span style=\"background-color: #FFFEFE\"> role</span><span style=\"background-color: #FFFEFE\"> <eos></span><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 5  # 출력할 데이터\n",
        "html_output = mk_html(index, batch, preds, normlized_weights_1,\n",
        "                      normlized_weights_2, TEXT)  # HTML 작성\n",
        "HTML(html_output)  # HTML 형식으로 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "SMxn1divbV8q",
        "outputId": "3ee1725a-7696-4dd8-c991-6fd19f5de780"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "정답 라벨: Positive<br>추론 라벨: Positive<br><br>[TransformerBlock의 첫번째 단의 Attention을 시각화]<br><span style=\"background-color: #FF4040\"> <cls></span><span style=\"background-color: #FF7070\"> great</span><span style=\"background-color: #FF6161\"> underrated</span><span style=\"background-color: #FF9393\"> movie</span><span style=\"background-color: #FF9494\"> great</span><span style=\"background-color: #FF8D8D\"> action</span><span style=\"background-color: #FF2929\"> good</span><span style=\"background-color: #FF0808\"> actors</span><span style=\"background-color: #FF4343\"> and</span><span style=\"background-color: #FF8A8A\"> a</span><span style=\"background-color: #FF4343\"> wonderful</span><span style=\"background-color: #FF5E5E\"> story</span><span style=\"background-color: #FF6B6B\"> line</span><span style=\"background-color: #FF5D5D\"> .</span><span style=\"background-color: #FF4444\"> wesley</span><span style=\"background-color: #FF5757\"> is</span><span style=\"background-color: #FF5656\"> <unk></span><span style=\"background-color: #FF7171\"> good</span><span style=\"background-color: #FF9393\"> and</span><span style=\"background-color: #FF9494\"> the</span><span style=\"background-color: #FF9595\"> villain</span><span style=\"background-color: #FF6262\"> the</span><span style=\"background-color: #FF4545\"> bad</span><span style=\"background-color: #FF6363\"> guy</span><span style=\"background-color: #FF9F9F\"> is</span><span style=\"background-color: #FF8D8D\"> wonderful</span><span style=\"background-color: #FF6A6A\"> the</span><span style=\"background-color: #FF2222\"> girl</span><span style=\"background-color: #FF5959\"> plays</span><span style=\"background-color: #FF4D4D\"> a</span><span style=\"background-color: #FFC8C8\"> nice</span><span style=\"background-color: #FF6262\"> role</span><span style=\"background-color: #FF5656\"> and</span><span style=\"background-color: #FF6464\"> the</span><span style=\"background-color: #FF5C5C\"> comedy</span><span style=\"background-color: #FF9D9D\"> mixed</span><span style=\"background-color: #FF6262\"> with</span><span style=\"background-color: #FF4141\"> <unk></span><span style=\"background-color: #FF9191\"> <eos></span><span style=\"background-color: #FF8D8D\"> <pad></span><span style=\"background-color: #FF2F2F\"> <pad></span><span style=\"background-color: #FF5858\"> <pad></span><span style=\"background-color: #FF2020\"> <pad></span><span style=\"background-color: #FF8D8D\"> <pad></span><span style=\"background-color: #FF1A1A\"> <pad></span><span style=\"background-color: #FF5050\"> <pad></span><span style=\"background-color: #FF6B6B\"> <pad></span><span style=\"background-color: #FF8181\"> <pad></span><span style=\"background-color: #FF9696\"> <pad></span><span style=\"background-color: #FF5959\"> <pad></span><span style=\"background-color: #FF4E4E\"> <pad></span><span style=\"background-color: #FF3131\"> <pad></span><span style=\"background-color: #FF6262\"> <pad></span><span style=\"background-color: #FF8585\"> <pad></span><span style=\"background-color: #FFA1A1\"> <pad></span><span style=\"background-color: #FF4646\"> <pad></span><span style=\"background-color: #FF0000\"> <pad></span><span style=\"background-color: #FF6262\"> <pad></span><span style=\"background-color: #FF5555\"> <pad></span><span style=\"background-color: #FF8787\"> <pad></span><span style=\"background-color: #FF5454\"> <pad></span><span style=\"background-color: #FF8888\"> <pad></span><span style=\"background-color: #FF4141\"> <pad></span><span style=\"background-color: #FF5050\"> <pad></span><span style=\"background-color: #FF5858\"> <pad></span><span style=\"background-color: #FF7C7C\"> <pad></span><span style=\"background-color: #FF4B4B\"> <pad></span><span style=\"background-color: #FF8F8F\"> <pad></span><span style=\"background-color: #FF2929\"> <pad></span><span style=\"background-color: #FF6464\"> <pad></span><span style=\"background-color: #FF5E5E\"> <pad></span><span style=\"background-color: #FF3232\"> <pad></span><span style=\"background-color: #FF5959\"> <pad></span><span style=\"background-color: #FF8888\"> <pad></span><span style=\"background-color: #FF9E9E\"> <pad></span><span style=\"background-color: #FF6565\"> <pad></span><span style=\"background-color: #FF6868\"> <pad></span><span style=\"background-color: #FF6262\"> <pad></span><span style=\"background-color: #FF4646\"> <pad></span><span style=\"background-color: #FF5F5F\"> <pad></span><span style=\"background-color: #FF4C4C\"> <pad></span><span style=\"background-color: #FF4242\"> <pad></span><span style=\"background-color: #FFA2A2\"> <pad></span><span style=\"background-color: #FF9898\"> <pad></span><span style=\"background-color: #FF6464\"> <pad></span><span style=\"background-color: #FF9A9A\"> <pad></span><span style=\"background-color: #FF5959\"> <pad></span><span style=\"background-color: #FF8E8E\"> <pad></span><span style=\"background-color: #FF4D4D\"> <pad></span><span style=\"background-color: #FF4B4B\"> <pad></span><span style=\"background-color: #FF4646\"> <pad></span><span style=\"background-color: #FF4646\"> <pad></span><span style=\"background-color: #FF6363\"> <pad></span><span style=\"background-color: #FF4D4D\"> <pad></span><span style=\"background-color: #FF5050\"> <pad></span><span style=\"background-color: #FF4C4C\"> <pad></span><span style=\"background-color: #FF6666\"> <pad></span><span style=\"background-color: #FF5353\"> <pad></span><span style=\"background-color: #FF5E5E\"> <pad></span><span style=\"background-color: #FF6A6A\"> <pad></span><span style=\"background-color: #FF5454\"> <pad></span><span style=\"background-color: #FF5B5B\"> <pad></span><span style=\"background-color: #FF8E8E\"> <pad></span><span style=\"background-color: #FF1E1E\"> <pad></span><span style=\"background-color: #FF9494\"> <pad></span><span style=\"background-color: #FF7575\"> <pad></span><span style=\"background-color: #FF6666\"> <pad></span><span style=\"background-color: #FF7777\"> <pad></span><span style=\"background-color: #FF6060\"> <pad></span><span style=\"background-color: #FF8F8F\"> <pad></span><span style=\"background-color: #FF5D5D\"> <pad></span><span style=\"background-color: #FF5F5F\"> <pad></span><span style=\"background-color: #FF9595\"> <pad></span><span style=\"background-color: #FF3737\"> <pad></span><span style=\"background-color: #FF7979\"> <pad></span><span style=\"background-color: #FF4343\"> <pad></span><span style=\"background-color: #FFA4A4\"> <pad></span><span style=\"background-color: #FF6363\"> <pad></span><span style=\"background-color: #FF5151\"> <pad></span><span style=\"background-color: #FF6363\"> <pad></span><span style=\"background-color: #FF9292\"> <pad></span><span style=\"background-color: #FF7373\"> <pad></span><span style=\"background-color: #FF9999\"> <pad></span><span style=\"background-color: #FF5F5F\"> <pad></span><span style=\"background-color: #FF6F6F\"> <pad></span><span style=\"background-color: #FF9C9C\"> <pad></span><span style=\"background-color: #FF5757\"> <pad></span><span style=\"background-color: #FF5D5D\"> <pad></span><span style=\"background-color: #FF6F6F\"> <pad></span><span style=\"background-color: #FF5A5A\"> <pad></span><span style=\"background-color: #FF5252\"> <pad></span><span style=\"background-color: #FF6969\"> <pad></span><span style=\"background-color: #FF5757\"> <pad></span><span style=\"background-color: #FF6C6C\"> <pad></span><span style=\"background-color: #FF7171\"> <pad></span><span style=\"background-color: #FF7676\"> <pad></span><span style=\"background-color: #FF8585\"> <pad></span><span style=\"background-color: #FF7D7D\"> <pad></span><span style=\"background-color: #FF9A9A\"> <pad></span><span style=\"background-color: #FF6464\"> <pad></span><span style=\"background-color: #FF5555\"> <pad></span><span style=\"background-color: #FF6666\"> <pad></span><span style=\"background-color: #FF7777\"> <pad></span><span style=\"background-color: #FF4F4F\"> <pad></span><span style=\"background-color: #FF7474\"> <pad></span><span style=\"background-color: #FF5A5A\"> <pad></span><span style=\"background-color: #FF9999\"> <pad></span><span style=\"background-color: #FF6262\"> <pad></span><span style=\"background-color: #FF4343\"> <pad></span><span style=\"background-color: #FF7B7B\"> <pad></span><span style=\"background-color: #FF6B6B\"> <pad></span><span style=\"background-color: #FF3F3F\"> <pad></span><span style=\"background-color: #FF6F6F\"> <pad></span><span style=\"background-color: #FFB6B6\"> <pad></span><span style=\"background-color: #FF9090\"> <pad></span><span style=\"background-color: #FF6A6A\"> <pad></span><span style=\"background-color: #FF4343\"> <pad></span><span style=\"background-color: #FF9C9C\"> <pad></span><span style=\"background-color: #FF6C6C\"> <pad></span><span style=\"background-color: #FF5252\"> <pad></span><span style=\"background-color: #FF5757\"> <pad></span><span style=\"background-color: #FF9191\"> <pad></span><span style=\"background-color: #FF2E2E\"> <pad></span><span style=\"background-color: #FF4C4C\"> <pad></span><span style=\"background-color: #FF6464\"> <pad></span><span style=\"background-color: #FFA7A7\"> <pad></span><span style=\"background-color: #FF9E9E\"> <pad></span><span style=\"background-color: #FF7373\"> <pad></span><span style=\"background-color: #FFA9A9\"> <pad></span><span style=\"background-color: #FF4141\"> <pad></span><span style=\"background-color: #FF6464\"> <pad></span><span style=\"background-color: #FF7575\"> <pad></span><span style=\"background-color: #FF4D4D\"> <pad></span><span style=\"background-color: #FFA1A1\"> <pad></span><span style=\"background-color: #FFB6B6\"> <pad></span><span style=\"background-color: #FF4F4F\"> <pad></span><span style=\"background-color: #FF6262\"> <pad></span><span style=\"background-color: #FF3131\"> <pad></span><span style=\"background-color: #FF6868\"> <pad></span><span style=\"background-color: #FF5C5C\"> <pad></span><span style=\"background-color: #FF6060\"> <pad></span><span style=\"background-color: #FF7D7D\"> <pad></span><span style=\"background-color: #FF5555\"> <pad></span><span style=\"background-color: #FF8787\"> <pad></span><span style=\"background-color: #FF9494\"> <pad></span><span style=\"background-color: #FF8080\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><br><br>[TransformerBlock의 두번째 단의 Attention을 시각화]<br><span style=\"background-color: #FF9494\"> <cls></span><span style=\"background-color: #FF7676\"> great</span><span style=\"background-color: #FF7D7D\"> underrated</span><span style=\"background-color: #FF8F8F\"> movie</span><span style=\"background-color: #FF7272\"> great</span><span style=\"background-color: #FF8F8F\"> action</span><span style=\"background-color: #FF9D9D\"> good</span><span style=\"background-color: #FF7272\"> actors</span><span style=\"background-color: #FF6666\"> and</span><span style=\"background-color: #FF6A6A\"> a</span><span style=\"background-color: #FF7171\"> wonderful</span><span style=\"background-color: #FF9292\"> story</span><span style=\"background-color: #FFB4B4\"> line</span><span style=\"background-color: #FF4444\"> .</span><span style=\"background-color: #FF7E7E\"> wesley</span><span style=\"background-color: #FFBCBC\"> is</span><span style=\"background-color: #FF7373\"> <unk></span><span style=\"background-color: #FF7A7A\"> good</span><span style=\"background-color: #FF6767\"> and</span><span style=\"background-color: #FF6969\"> the</span><span style=\"background-color: #FF5E5E\"> villain</span><span style=\"background-color: #FF4141\"> the</span><span style=\"background-color: #FF8F8F\"> bad</span><span style=\"background-color: #FF6262\"> guy</span><span style=\"background-color: #FF7373\"> is</span><span style=\"background-color: #FF6060\"> wonderful</span><span style=\"background-color: #FF7A7A\"> the</span><span style=\"background-color: #FF6F6F\"> girl</span><span style=\"background-color: #FF7676\"> plays</span><span style=\"background-color: #FF5656\"> a</span><span style=\"background-color: #FF6F6F\"> nice</span><span style=\"background-color: #FF6060\"> role</span><span style=\"background-color: #FF7070\"> and</span><span style=\"background-color: #FFADAD\"> the</span><span style=\"background-color: #FF6C6C\"> comedy</span><span style=\"background-color: #FF8484\"> mixed</span><span style=\"background-color: #FF6262\"> with</span><span style=\"background-color: #FF9C9C\"> <unk></span><span style=\"background-color: #FF6565\"> <eos></span><span style=\"background-color: #FF7676\"> <pad></span><span style=\"background-color: #FF7979\"> <pad></span><span style=\"background-color: #FF4C4C\"> <pad></span><span style=\"background-color: #FF7878\"> <pad></span><span style=\"background-color: #FF9191\"> <pad></span><span style=\"background-color: #FF7A7A\"> <pad></span><span style=\"background-color: #FF5454\"> <pad></span><span style=\"background-color: #FF5E5E\"> <pad></span><span style=\"background-color: #FF9898\"> <pad></span><span style=\"background-color: #FFA4A4\"> <pad></span><span style=\"background-color: #FF6161\"> <pad></span><span style=\"background-color: #FF6060\"> <pad></span><span style=\"background-color: #FF6767\"> <pad></span><span style=\"background-color: #FF4949\"> <pad></span><span style=\"background-color: #FF8989\"> <pad></span><span style=\"background-color: #FF9D9D\"> <pad></span><span style=\"background-color: #FF6161\"> <pad></span><span style=\"background-color: #FFB9B9\"> <pad></span><span style=\"background-color: #FF6464\"> <pad></span><span style=\"background-color: #FFA8A8\"> <pad></span><span style=\"background-color: #FF5D5D\"> <pad></span><span style=\"background-color: #FF5F5F\"> <pad></span><span style=\"background-color: #FFA2A2\"> <pad></span><span style=\"background-color: #FFBBBB\"> <pad></span><span style=\"background-color: #FF5A5A\"> <pad></span><span style=\"background-color: #FF8787\"> <pad></span><span style=\"background-color: #FFC1C1\"> <pad></span><span style=\"background-color: #FF6868\"> <pad></span><span style=\"background-color: #FF7878\"> <pad></span><span style=\"background-color: #FF2B2B\"> <pad></span><span style=\"background-color: #FF8181\"> <pad></span><span style=\"background-color: #FF7E7E\"> <pad></span><span style=\"background-color: #FFA9A9\"> <pad></span><span style=\"background-color: #FF7A7A\"> <pad></span><span style=\"background-color: #FF6C6C\"> <pad></span><span style=\"background-color: #FF6262\"> <pad></span><span style=\"background-color: #FF7A7A\"> <pad></span><span style=\"background-color: #FF7A7A\"> <pad></span><span style=\"background-color: #FF7878\"> <pad></span><span style=\"background-color: #FF3838\"> <pad></span><span style=\"background-color: #FF9A9A\"> <pad></span><span style=\"background-color: #FF4C4C\"> <pad></span><span style=\"background-color: #FF5959\"> <pad></span><span style=\"background-color: #FF6B6B\"> <pad></span><span style=\"background-color: #FF7878\"> <pad></span><span style=\"background-color: #FF6868\"> <pad></span><span style=\"background-color: #FFB0B0\"> <pad></span><span style=\"background-color: #FF5D5D\"> <pad></span><span style=\"background-color: #FF5E5E\"> <pad></span><span style=\"background-color: #FF4343\"> <pad></span><span style=\"background-color: #FF5252\"> <pad></span><span style=\"background-color: #FF8181\"> <pad></span><span style=\"background-color: #FF6C6C\"> <pad></span><span style=\"background-color: #FF6C6C\"> <pad></span><span style=\"background-color: #FF2B2B\"> <pad></span><span style=\"background-color: #FF5C5C\"> <pad></span><span style=\"background-color: #FF8383\"> <pad></span><span style=\"background-color: #FF6666\"> <pad></span><span style=\"background-color: #FF7676\"> <pad></span><span style=\"background-color: #FF6969\"> <pad></span><span style=\"background-color: #FF0000\"> <pad></span><span style=\"background-color: #FF6E6E\"> <pad></span><span style=\"background-color: #FF6D6D\"> <pad></span><span style=\"background-color: #FF9F9F\"> <pad></span><span style=\"background-color: #FFBCBC\"> <pad></span><span style=\"background-color: #FF7C7C\"> <pad></span><span style=\"background-color: #FF8A8A\"> <pad></span><span style=\"background-color: #FF6E6E\"> <pad></span><span style=\"background-color: #FF9C9C\"> <pad></span><span style=\"background-color: #FF7272\"> <pad></span><span style=\"background-color: #FF7C7C\"> <pad></span><span style=\"background-color: #FF5353\"> <pad></span><span style=\"background-color: #FF6969\"> <pad></span><span style=\"background-color: #FF9E9E\"> <pad></span><span style=\"background-color: #FF8484\"> <pad></span><span style=\"background-color: #FF7676\"> <pad></span><span style=\"background-color: #FF7373\"> <pad></span><span style=\"background-color: #FF2A2A\"> <pad></span><span style=\"background-color: #FF7575\"> <pad></span><span style=\"background-color: #FF7676\"> <pad></span><span style=\"background-color: #FF9F9F\"> <pad></span><span style=\"background-color: #FF8A8A\"> <pad></span><span style=\"background-color: #FF9A9A\"> <pad></span><span style=\"background-color: #FF5858\"> <pad></span><span style=\"background-color: #FF9393\"> <pad></span><span style=\"background-color: #FF8383\"> <pad></span><span style=\"background-color: #FF7E7E\"> <pad></span><span style=\"background-color: #FF8080\"> <pad></span><span style=\"background-color: #FFA5A5\"> <pad></span><span style=\"background-color: #FFAFAF\"> <pad></span><span style=\"background-color: #FF7B7B\"> <pad></span><span style=\"background-color: #FF6C6C\"> <pad></span><span style=\"background-color: #FFA3A3\"> <pad></span><span style=\"background-color: #FF6C6C\"> <pad></span><span style=\"background-color: #FFB3B3\"> <pad></span><span style=\"background-color: #FFB6B6\"> <pad></span><span style=\"background-color: #FF9393\"> <pad></span><span style=\"background-color: #FF6C6C\"> <pad></span><span style=\"background-color: #FF8383\"> <pad></span><span style=\"background-color: #FFB5B5\"> <pad></span><span style=\"background-color: #FF8383\"> <pad></span><span style=\"background-color: #FF6767\"> <pad></span><span style=\"background-color: #FF9292\"> <pad></span><span style=\"background-color: #FF8D8D\"> <pad></span><span style=\"background-color: #FF8282\"> <pad></span><span style=\"background-color: #FF9393\"> <pad></span><span style=\"background-color: #FF8181\"> <pad></span><span style=\"background-color: #FF9797\"> <pad></span><span style=\"background-color: #FF7373\"> <pad></span><span style=\"background-color: #FF4141\"> <pad></span><span style=\"background-color: #FFA3A3\"> <pad></span><span style=\"background-color: #FF8484\"> <pad></span><span style=\"background-color: #FF8D8D\"> <pad></span><span style=\"background-color: #FF9D9D\"> <pad></span><span style=\"background-color: #FF9B9B\"> <pad></span><span style=\"background-color: #FF8A8A\"> <pad></span><span style=\"background-color: #FF9191\"> <pad></span><span style=\"background-color: #FF9C9C\"> <pad></span><span style=\"background-color: #FF6D6D\"> <pad></span><span style=\"background-color: #FF9A9A\"> <pad></span><span style=\"background-color: #FF7F7F\"> <pad></span><span style=\"background-color: #FF8888\"> <pad></span><span style=\"background-color: #FFAAAA\"> <pad></span><span style=\"background-color: #FF8D8D\"> <pad></span><span style=\"background-color: #FF6464\"> <pad></span><span style=\"background-color: #FF8686\"> <pad></span><span style=\"background-color: #FF7575\"> <pad></span><span style=\"background-color: #FF7070\"> <pad></span><span style=\"background-color: #FF8282\"> <pad></span><span style=\"background-color: #FF7B7B\"> <pad></span><span style=\"background-color: #FF8A8A\"> <pad></span><span style=\"background-color: #FF7B7B\"> <pad></span><span style=\"background-color: #FF8080\"> <pad></span><span style=\"background-color: #FF6868\"> <pad></span><span style=\"background-color: #FF6A6A\"> <pad></span><span style=\"background-color: #FFA3A3\"> <pad></span><span style=\"background-color: #FF7A7A\"> <pad></span><span style=\"background-color: #FF5454\"> <pad></span><span style=\"background-color: #FF8181\"> <pad></span><span style=\"background-color: #FF8787\"> <pad></span><span style=\"background-color: #FF7070\"> <pad></span><span style=\"background-color: #FF7E7E\"> <pad></span><span style=\"background-color: #FF9D9D\"> <pad></span><span style=\"background-color: #FF7E7E\"> <pad></span><span style=\"background-color: #FFC3C3\"> <pad></span><span style=\"background-color: #FF7373\"> <pad></span><span style=\"background-color: #FFBABA\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><span style=\"background-color: #FFFFFF\"> <pad></span><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\\index = 23  # 출력할 데이터\n",
        "html_output = mk_html(index, batch, preds, normlized_weights_1,\n",
        "                      normlized_weights_2, TEXT)  # HTML 작성\n",
        "HTML(html_output)  # HTML 형식으로 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "WN3BnnsAW-sC",
        "outputId": "f495959a-d1da-4d78-afad-ac8f9a68bb6f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "정답 라벨: Positive<br>추론 라벨: Negative<br><br>[TransformerBlock의 첫번째 단의 Attention을 시각화]<br><span style=\"background-color: #FF4B4B\"> <cls></span><span style=\"background-color: #FF7878\"> the</span><span style=\"background-color: #FF7575\"> further</span><span style=\"background-color: #FF6161\"> adventures</span><span style=\"background-color: #FF4444\"> of</span><span style=\"background-color: #FF8A8A\"> ma</span><span style=\"background-color: #FF8C8C\"> and</span><span style=\"background-color: #FF4F4F\"> pa</span><span style=\"background-color: #FF9595\"> <unk></span><span style=\"background-color: #FF6161\"> almost</span><span style=\"background-color: #FF6E6E\"> seamlessly</span><span style=\"background-color: #FF9999\"> picks</span><span style=\"background-color: #FF6B6B\"> up</span><span style=\"background-color: #FF8A8A\"> where</span><span style=\"background-color: #FF8686\"> the</span><span style=\"background-color: #FF9C9C\"> egg</span><span style=\"background-color: #FF9393\"> and</span><span style=\"background-color: #FF9696\"> i</span><span style=\"background-color: #FF4141\"> left</span><span style=\"background-color: #FF5B5B\"> off</span><span style=\"background-color: #FF9090\"> .</span><span style=\"background-color: #FF7C7C\"> for</span><span style=\"background-color: #FFADAD\"> the</span><span style=\"background-color: #FF9B9B\"> first</span><span style=\"background-color: #FF6969\"> solo</span><span style=\"background-color: #FF7070\"> adventure</span><span style=\"background-color: #FF8787\"> of</span><span style=\"background-color: #FF4F4F\"> the</span><span style=\"background-color: #FF5050\"> <unk></span><span style=\"background-color: #FF3A3A\"> a</span><span style=\"background-color: #FF8A8A\"> new</span><span style=\"background-color: #FF5353\"> writing</span><span style=\"background-color: #FF7272\"> team</span><span style=\"background-color: #FF8F8F\"> and</span><span style=\"background-color: #FF5454\"> director</span><span style=\"background-color: #FF7B7B\"> is</span><span style=\"background-color: #FF9999\"> introduced</span><span style=\"background-color: #FF1717\"> .</span><span style=\"background-color: #FF9696\"> leonard</span><span style=\"background-color: #FF9999\"> <unk></span><span style=\"background-color: #FF6060\"> ,</span><span style=\"background-color: #FF6A6A\"> associate</span><span style=\"background-color: #FF9A9A\"> producer</span><span style=\"background-color: #FF0D0D\"> of</span><span style=\"background-color: #FF5E5E\"> the</span><span style=\"background-color: #FF5C5C\"> egg</span><span style=\"background-color: #FF2323\"> and</span><span style=\"background-color: #FF6D6D\"> i</span><span style=\"background-color: #FF3F3F\"> ,</span><span style=\"background-color: #FF7373\"> was</span><span style=\"background-color: #FF9C9C\"> producer</span><span style=\"background-color: #FF7F7F\"> of</span><span style=\"background-color: #FF6A6A\"> the</span><span style=\"background-color: #FF4040\"> further</span><span style=\"background-color: #FF5E5E\"> adventures</span><span style=\"background-color: #FF1515\"> of</span><span style=\"background-color: #FF8383\"> ma</span><span style=\"background-color: #FF6868\"> and</span><span style=\"background-color: #FF0505\"> pa</span><span style=\"background-color: #FF5E5E\"> <unk></span><span style=\"background-color: #FF5A5A\"> .</span><span style=\"background-color: #FF0000\"> with</span><span style=\"background-color: #FF9090\"> many</span><span style=\"background-color: #FF9090\"> of</span><span style=\"background-color: #FF8F8F\"> the</span><span style=\"background-color: #FF9191\"> characters</span><span style=\"background-color: #FF5050\"> played</span><span style=\"background-color: #FFFFFF\"> by</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> same</span><span style=\"background-color: #FFFFFF\"> actors</span><span style=\"background-color: #FFFFFF\"> and</span><span style=\"background-color: #FFFFFF\"> actresses</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> focus</span><span style=\"background-color: #FFFFFF\"> from</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> works</span><span style=\"background-color: #FFFFFF\"> very</span><span style=\"background-color: #FFFFFF\"> well</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> there</span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> reference</span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> ma</span><span style=\"background-color: #FFFFFF\"> beating</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> hicks</span><span style=\"background-color: #FFFFFF\"> for</span><span style=\"background-color: #FFFFFF\"> first</span><span style=\"background-color: #FFFFFF\"> prize</span><span style=\"background-color: #FFFFFF\"> at</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> fair</span><span style=\"background-color: #FFFFFF\"> for</span><span style=\"background-color: #FFFFFF\"> her</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> ,</span><span style=\"background-color: #FFFFFF\"> an</span><span style=\"background-color: #FFFFFF\"> import</span><span style=\"background-color: #FFFFFF\"> scene</span><span style=\"background-color: #FFFFFF\"> in</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> egg</span><span style=\"background-color: #FFFFFF\"> and</span><span style=\"background-color: #FFFFFF\"> i</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> prize</span><span style=\"background-color: #FFFFFF\"> money</span><span style=\"background-color: #FFFFFF\"> from</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> contest</span><span style=\"background-color: #FFFFFF\"> was</span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> be</span><span style=\"background-color: #FFFFFF\"> used</span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> send</span><span style=\"background-color: #FFFFFF\"> tom</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> college</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> in</span><span style=\"background-color: #FFFFFF\"> this</span><span style=\"background-color: #FFFFFF\"> movie</span><span style=\"background-color: #FFFFFF\"> tom</span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> returning</span><span style=\"background-color: #FFFFFF\"> home</span><span style=\"background-color: #FFFFFF\"> as</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> college</span><span style=\"background-color: #FFFFFF\"> graduate</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> there</span><span style=\"background-color: #FFFFFF\"> are</span><span style=\"background-color: #FFFFFF\"> two</span><span style=\"background-color: #FFFFFF\"> plots</span><span style=\"background-color: #FFFFFF\"> intertwined</span><span style=\"background-color: #FFFFFF\"> in</span><span style=\"background-color: #FFFFFF\"> this</span><span style=\"background-color: #FFFFFF\"> movie</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> one</span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> comedy</span><span style=\"background-color: #FFFFFF\"> of</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> simple</span><span style=\"background-color: #FFFFFF\"> mountain</span><span style=\"background-color: #FFFFFF\"> family</span><span style=\"background-color: #FFFFFF\"> moving</span><span style=\"background-color: #FFFFFF\"> into</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> state</span><span style=\"background-color: #FFFFFF\"> of</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> art</span><span style=\"background-color: #FFFFFF\"> modern</span><span style=\"background-color: #FFFFFF\"> house</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> other</span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> light</span><span style=\"background-color: #FFFFFF\"> morality</span><span style=\"background-color: #FFFFFF\"> play</span><span style=\"background-color: #FFFFFF\"> on</span><span style=\"background-color: #FFFFFF\"> how</span><span style=\"background-color: #FFFFFF\"> environment</span><span style=\"background-color: #FFFFFF\"> affects</span><span style=\"background-color: #FFFFFF\"> children</span><span style=\"background-color: #FFFFFF\"> as</span><span style=\"background-color: #FFFFFF\"> they</span><span style=\"background-color: #FFFFFF\"> grow</span><span style=\"background-color: #FFFFFF\"> up</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> pa</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> wanted</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> free</span><span style=\"background-color: #FFFFFF\"> tobacco</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> for</span><span style=\"background-color: #FFFFFF\"> entering</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> contest</span><span style=\"background-color: #FFFFFF\"> ,</span><span style=\"background-color: #FFFFFF\"> and</span><span style=\"background-color: #FFFFFF\"> ended</span><span style=\"background-color: #FFFFFF\"> up</span><span style=\"background-color: #FFFFFF\"> winning</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> house</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> his</span><span style=\"background-color: #FFFFFF\"> disappointment</span><span style=\"background-color: #FFFFFF\"> at</span><span style=\"background-color: #FFFFFF\"> not</span><span style=\"background-color: #FFFFFF\"> getting</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> free</span><span style=\"background-color: #FFFFFF\"> tobacco</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> played</span><span style=\"background-color: #FFFFFF\"> for</span><span style=\"background-color: #FFFFFF\"> laughs</span><span style=\"background-color: #FFFFFF\"> quite</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> bit</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> when</span><span style=\"background-color: #FFFFFF\"> pa</span><span style=\"background-color: #FFFFFF\"> plays</span><span style=\"background-color: #FFFFFF\"> with</span><span style=\"background-color: #FFFFFF\"> dynamite</span><span style=\"background-color: #FFFFFF\"> he</span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> totally</span><span style=\"background-color: #FFFFFF\"> oblivious</span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> explosion</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> never</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> in</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> scene</span><span style=\"background-color: #FFFFFF\"> as</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> debris</span><span style=\"background-color: #FFFFFF\"> from</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> explosion</span><span style=\"background-color: #FFFFFF\"> fell</span><span style=\"background-color: #FFFFFF\"> around</span><span style=\"background-color: #FFFFFF\"> him</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> <eos></span><br><br>[TransformerBlock의 두번째 단의 Attention을 시각화]<br><span style=\"background-color: #FF8C8C\"> <cls></span><span style=\"background-color: #FF6C6C\"> the</span><span style=\"background-color: #FF1B1B\"> further</span><span style=\"background-color: #FF5E5E\"> adventures</span><span style=\"background-color: #FF3F3F\"> of</span><span style=\"background-color: #FF4747\"> ma</span><span style=\"background-color: #FF8B8B\"> and</span><span style=\"background-color: #FF6666\"> pa</span><span style=\"background-color: #FF7171\"> <unk></span><span style=\"background-color: #FF4D4D\"> almost</span><span style=\"background-color: #FF9797\"> seamlessly</span><span style=\"background-color: #FFA3A3\"> picks</span><span style=\"background-color: #FF8B8B\"> up</span><span style=\"background-color: #FF7474\"> where</span><span style=\"background-color: #FF4A4A\"> the</span><span style=\"background-color: #FF8686\"> egg</span><span style=\"background-color: #FF4646\"> and</span><span style=\"background-color: #FF7D7D\"> i</span><span style=\"background-color: #FF7474\"> left</span><span style=\"background-color: #FF5353\"> off</span><span style=\"background-color: #FF4545\"> .</span><span style=\"background-color: #FF4040\"> for</span><span style=\"background-color: #FF9898\"> the</span><span style=\"background-color: #FF3D3D\"> first</span><span style=\"background-color: #FF7B7B\"> solo</span><span style=\"background-color: #FFC7C7\"> adventure</span><span style=\"background-color: #FFAAAA\"> of</span><span style=\"background-color: #FF6B6B\"> the</span><span style=\"background-color: #FF6666\"> <unk></span><span style=\"background-color: #FF9191\"> a</span><span style=\"background-color: #FF3535\"> new</span><span style=\"background-color: #FF6868\"> writing</span><span style=\"background-color: #FF8282\"> team</span><span style=\"background-color: #FFA6A6\"> and</span><span style=\"background-color: #FF8D8D\"> director</span><span style=\"background-color: #FF7676\"> is</span><span style=\"background-color: #FF8E8E\"> introduced</span><span style=\"background-color: #FFABAB\"> .</span><span style=\"background-color: #FF6E6E\"> leonard</span><span style=\"background-color: #FF7979\"> <unk></span><span style=\"background-color: #FF3939\"> ,</span><span style=\"background-color: #FF6868\"> associate</span><span style=\"background-color: #FF7E7E\"> producer</span><span style=\"background-color: #FFA1A1\"> of</span><span style=\"background-color: #FF5959\"> the</span><span style=\"background-color: #FF6161\"> egg</span><span style=\"background-color: #FF8E8E\"> and</span><span style=\"background-color: #FFA8A8\"> i</span><span style=\"background-color: #FF4D4D\"> ,</span><span style=\"background-color: #FF7878\"> was</span><span style=\"background-color: #FF2828\"> producer</span><span style=\"background-color: #FF6262\"> of</span><span style=\"background-color: #FF3131\"> the</span><span style=\"background-color: #FF6565\"> further</span><span style=\"background-color: #FF6666\"> adventures</span><span style=\"background-color: #FF8A8A\"> of</span><span style=\"background-color: #FF8D8D\"> ma</span><span style=\"background-color: #FF7676\"> and</span><span style=\"background-color: #FF5C5C\"> pa</span><span style=\"background-color: #FF7676\"> <unk></span><span style=\"background-color: #FF0000\"> .</span><span style=\"background-color: #FF6767\"> with</span><span style=\"background-color: #FF7676\"> many</span><span style=\"background-color: #FF3434\"> of</span><span style=\"background-color: #FF3535\"> the</span><span style=\"background-color: #FF2F2F\"> characters</span><span style=\"background-color: #FF9696\"> played</span><span style=\"background-color: #FFFFFF\"> by</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> same</span><span style=\"background-color: #FFFFFF\"> actors</span><span style=\"background-color: #FFFFFF\"> and</span><span style=\"background-color: #FFFFFF\"> actresses</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> focus</span><span style=\"background-color: #FFFFFF\"> from</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> works</span><span style=\"background-color: #FFFFFF\"> very</span><span style=\"background-color: #FFFFFF\"> well</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> there</span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> reference</span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> ma</span><span style=\"background-color: #FFFFFF\"> beating</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> hicks</span><span style=\"background-color: #FFFFFF\"> for</span><span style=\"background-color: #FFFFFF\"> first</span><span style=\"background-color: #FFFFFF\"> prize</span><span style=\"background-color: #FFFFFF\"> at</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> fair</span><span style=\"background-color: #FFFFFF\"> for</span><span style=\"background-color: #FFFFFF\"> her</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> ,</span><span style=\"background-color: #FFFFFF\"> an</span><span style=\"background-color: #FFFFFF\"> import</span><span style=\"background-color: #FFFFFF\"> scene</span><span style=\"background-color: #FFFFFF\"> in</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> egg</span><span style=\"background-color: #FFFFFF\"> and</span><span style=\"background-color: #FFFFFF\"> i</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> prize</span><span style=\"background-color: #FFFFFF\"> money</span><span style=\"background-color: #FFFFFF\"> from</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> contest</span><span style=\"background-color: #FFFFFF\"> was</span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> be</span><span style=\"background-color: #FFFFFF\"> used</span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> send</span><span style=\"background-color: #FFFFFF\"> tom</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> college</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> in</span><span style=\"background-color: #FFFFFF\"> this</span><span style=\"background-color: #FFFFFF\"> movie</span><span style=\"background-color: #FFFFFF\"> tom</span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> returning</span><span style=\"background-color: #FFFFFF\"> home</span><span style=\"background-color: #FFFFFF\"> as</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> college</span><span style=\"background-color: #FFFFFF\"> graduate</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> there</span><span style=\"background-color: #FFFFFF\"> are</span><span style=\"background-color: #FFFFFF\"> two</span><span style=\"background-color: #FFFFFF\"> plots</span><span style=\"background-color: #FFFFFF\"> intertwined</span><span style=\"background-color: #FFFFFF\"> in</span><span style=\"background-color: #FFFFFF\"> this</span><span style=\"background-color: #FFFFFF\"> movie</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> one</span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> comedy</span><span style=\"background-color: #FFFFFF\"> of</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> simple</span><span style=\"background-color: #FFFFFF\"> mountain</span><span style=\"background-color: #FFFFFF\"> family</span><span style=\"background-color: #FFFFFF\"> moving</span><span style=\"background-color: #FFFFFF\"> into</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> state</span><span style=\"background-color: #FFFFFF\"> of</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> art</span><span style=\"background-color: #FFFFFF\"> modern</span><span style=\"background-color: #FFFFFF\"> house</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> other</span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> light</span><span style=\"background-color: #FFFFFF\"> morality</span><span style=\"background-color: #FFFFFF\"> play</span><span style=\"background-color: #FFFFFF\"> on</span><span style=\"background-color: #FFFFFF\"> how</span><span style=\"background-color: #FFFFFF\"> environment</span><span style=\"background-color: #FFFFFF\"> affects</span><span style=\"background-color: #FFFFFF\"> children</span><span style=\"background-color: #FFFFFF\"> as</span><span style=\"background-color: #FFFFFF\"> they</span><span style=\"background-color: #FFFFFF\"> grow</span><span style=\"background-color: #FFFFFF\"> up</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> pa</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> wanted</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> free</span><span style=\"background-color: #FFFFFF\"> tobacco</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> for</span><span style=\"background-color: #FFFFFF\"> entering</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> contest</span><span style=\"background-color: #FFFFFF\"> ,</span><span style=\"background-color: #FFFFFF\"> and</span><span style=\"background-color: #FFFFFF\"> ended</span><span style=\"background-color: #FFFFFF\"> up</span><span style=\"background-color: #FFFFFF\"> winning</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> house</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> his</span><span style=\"background-color: #FFFFFF\"> disappointment</span><span style=\"background-color: #FFFFFF\"> at</span><span style=\"background-color: #FFFFFF\"> not</span><span style=\"background-color: #FFFFFF\"> getting</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> free</span><span style=\"background-color: #FFFFFF\"> tobacco</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> played</span><span style=\"background-color: #FFFFFF\"> for</span><span style=\"background-color: #FFFFFF\"> laughs</span><span style=\"background-color: #FFFFFF\"> quite</span><span style=\"background-color: #FFFFFF\"> a</span><span style=\"background-color: #FFFFFF\"> bit</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> when</span><span style=\"background-color: #FFFFFF\"> pa</span><span style=\"background-color: #FFFFFF\"> plays</span><span style=\"background-color: #FFFFFF\"> with</span><span style=\"background-color: #FFFFFF\"> dynamite</span><span style=\"background-color: #FFFFFF\"> he</span><span style=\"background-color: #FFFFFF\"> is</span><span style=\"background-color: #FFFFFF\"> totally</span><span style=\"background-color: #FFFFFF\"> oblivious</span><span style=\"background-color: #FFFFFF\"> to</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> explosion</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> never</span><span style=\"background-color: #FFFFFF\"> <unk></span><span style=\"background-color: #FFFFFF\"> in</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> scene</span><span style=\"background-color: #FFFFFF\"> as</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> debris</span><span style=\"background-color: #FFFFFF\"> from</span><span style=\"background-color: #FFFFFF\"> the</span><span style=\"background-color: #FFFFFF\"> explosion</span><span style=\"background-color: #FFFFFF\"> fell</span><span style=\"background-color: #FFFFFF\"> around</span><span style=\"background-color: #FFFFFF\"> him</span><span style=\"background-color: #FFFFFF\"> .</span><span style=\"background-color: #FFFFFF\"> <eos></span><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GPUOwKaHXMKE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}