{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53777e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "training code\n",
    "also contains the F-score evaluation code.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "#from apex import amp\n",
    "\n",
    "from config import cfg, assert_and_infer_cfg\n",
    "from utils.misc import AverageMeter, prep_experiment, evaluate_eval, fast_hist, set_bn_eval\n",
    "from utils.f_boundary import eval_mask_boundary\n",
    "import datasets\n",
    "import loss\n",
    "import network\n",
    "import optimizer\n",
    "\n",
    "\n",
    "args = argparse.Namespace()\n",
    "args.lr = 0.002\n",
    "args.arch = 'network.EBLNet.EBLNet_resnext101_os8'\n",
    "args.dataset = 'MSD'\n",
    "\n",
    "args.cv = 0\n",
    "args.class_uniform_pct = 0.0\n",
    "args.class_uniform_tile = 1024\n",
    "args.coarse_boost_classes = None\n",
    "\n",
    "args.img_wt_loss = False\n",
    "args.batch_weighting = False\n",
    "args.dice_loss = True\n",
    "args.ohem = False\n",
    "args.aux = False\n",
    "args.jointwtborder = True\n",
    "args.joint_edge_loss_light_cascade = True\n",
    "args.edge_weight = 3.0\n",
    "args.body_weight = 1.0\n",
    "args.seg_weight = 1.0\n",
    "args.rlx_off_epoch = -1\n",
    "args.rescale = 1.0\n",
    "args.repoly = 1.5\n",
    "args.apex = False\n",
    "args.fp16 = False\n",
    "\n",
    "args.local_rank = 0\n",
    "\n",
    "args.sgd = True\n",
    "args.adam = False\n",
    "args.amsgrad = False\n",
    "\n",
    "args.freeze_trunk = False\n",
    "args.hardnm = 0\n",
    "\n",
    "args.trunk = 'resnet101'\n",
    "args.max_epoch = 160\n",
    "args.eval_epoch = 150\n",
    "args.max_cu_epoch = 160\n",
    "args.start_epoch = 0\n",
    "args.color_aug = 0.0\n",
    "args.gblur = True\n",
    "args.bblur = False\n",
    "args.lr_schedule = 'poly'\n",
    "args.poly_exp = 0.9\n",
    "args.bs_mult = 2\n",
    "args.bs_mult_val = 1\n",
    "args.crop_size = 384\n",
    "args.pre_size = None\n",
    "args.scale_min = 1.0\n",
    "args.scale_max = 1.0\n",
    "args.weight_decay = 1e-4\n",
    "args.momentum = 0.9\n",
    "args.snapshot = 'C:/Users/iml/Desktop/EBLNet-main/best.pth'\n",
    "args.restore_optimizer = False\n",
    "args.exp = 'default'\n",
    "args.tb_tag = ''\n",
    "args.ckpt = 'logs/ckpt'\n",
    "args.tb_path = 'logs/tb'\n",
    "args.syncbn = False\n",
    "args.fix_bn = False\n",
    "args.evaluateF = False\n",
    "args.eval_thresholds = '0.0005,0.001875,0.00375,0.005'\n",
    "args.dump_augmentation_images = False\n",
    "args.test_mode = False\n",
    "args.wb = 1.0\n",
    "args.maxSkip = 0\n",
    "args.scf = False\n",
    "\n",
    "args.print_freq = 5\n",
    "args.eval_freq = 1\n",
    "args.num_cascade = 3\n",
    "args.weight_mean = 0\n",
    "args.num_points = 97\n",
    "args.thres_gcn = 0.9\n",
    "args.thicky = 8\n",
    "\n",
    "args.ngpu = 1\n",
    "torch.backends.cudnn.benchmark = True\n",
    "args.world_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a037fb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iml\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:222: UserWarning: NLLLoss2d has been deprecated. Please use NLLLoss instead as a drop-in replacement and see https://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\n",
      "  warnings.warn(\"NLLLoss2d has been deprecated. \"\n",
      "C:\\Users\\iml\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, train_obj = datasets.setup_loaders(args)\n",
    "criterion, criterion_val = loss.get_loss(args)\n",
    "net = network.get_net(args, criterion)\n",
    "\n",
    "optim, scheduler = optimizer.get_optimizer(args, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3b1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from network import resnet_d as Resnet_Deep\n",
    "from network.resnext import resnext101_32x8\n",
    "from network.nn.mynn import Norm2d\n",
    "from network.nn.contour_point_gcn import ContourPointGCN\n",
    "from network.nn.operators import _AtrousSpatialPyramidPoolingModule\n",
    "\n",
    "\n",
    "num_classes = 2  # args.dataset_cls.num_classes\n",
    "criterion = criterion\n",
    "num_cascade = args.num_cascade\n",
    "num_points = args.num_points\n",
    "threshold = args.thres_gcn\n",
    "\n",
    "trunk = 'resnext-101-32x8'\n",
    "variant = 'D'\n",
    "skip = 'm1'\n",
    "skip_num = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec5ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Edge_extractorWofirstext(nn.Module):\n",
    "    def __init__(self, inplane, skip_num, norm_layer):\n",
    "        '''default: inplane=256, skip_num=48'''\n",
    "        super(Edge_extractorWofirstext, self).__init__()\n",
    "        self.skip_mum = skip_num\n",
    "        \n",
    "        self.pre_extractor = nn.Sequential(\n",
    "            nn.Conv2d(inplane, inplane, kernel_size=3,\n",
    "                      padding=1, groups=1, bias=False),\n",
    "            nn.BatchNorm2d(inplane),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        \n",
    "        self.extractor = nn.Sequential(\n",
    "            nn.Conv2d(inplane + skip_num, inplane, kernel_size=3,\n",
    "                      padding=1, groups=8, bias=False),\n",
    "            nn.BatchNorm2d(inplane),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, aspp, layer1):  \n",
    "        '''supoose input image: (N, 3, 512, 512)\n",
    "           aspp: high-level feature (N, 256, 64, 64)\n",
    "           layer1: (projected)low-level feature (N, 48, 128, 128)\n",
    "           \n",
    "           seg_edge, seg_body: (N, 256, 128, 128)'''\n",
    "        seg_edge = torch.cat([F.interpolate(aspp, size=layer1.size()[2:], mode='bilinear',\n",
    "                                            align_corners=True), layer1], dim=1)  # 200\n",
    "        seg_edge = self.extractor(seg_edge) \n",
    "        \n",
    "        # F_residual = F_in - F_edge\n",
    "        seg_body = F.interpolate(aspp, layer1.size()[2:], mode='bilinear', align_corners=True) - seg_edge\n",
    "\n",
    "        return seg_edge, seg_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba6806b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EBLNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement deeplabv3 plus module without depthwise conv\n",
    "    A: stride=8\n",
    "    B: stride=16\n",
    "    with skip connection\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, trunk='seresnext-50', criterion=None, variant='D',\n",
    "                 skip='m1', skip_num=48, num_cascade=4, num_points=96, threshold=0.8):\n",
    "        ''''''\n",
    "        super(EBLNet, self).__init__()\n",
    "        self.criterion = criterion\n",
    "        self.variant = variant\n",
    "        self.skip = skip\n",
    "        self.skip_mum = skip_num\n",
    "        self.num_cascade = num_cascade\n",
    "        self.num_points = num_points\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # --------------------------- 0.feature extractor ---------------------------\n",
    "        # resnet\n",
    "        resnet = resnext101_32x8()\n",
    "        resnet.layer0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)\n",
    "        self.layer0 = resnet.layer0\n",
    "        self.layer1, self.layer2, self.layer3, self.layer4 = \\\n",
    "            resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4\n",
    "\n",
    "        for n, m in self.layer3.named_modules():\n",
    "            if 'conv2' in n:\n",
    "                m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
    "            elif 'downsample.0' in n:\n",
    "                m.stride = (1, 1)\n",
    "        for n, m in self.layer4.named_modules():\n",
    "            if 'conv2' in n:\n",
    "                m.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n",
    "            elif 'downsample.0' in n:\n",
    "                m.stride = (1, 1)\n",
    "        \n",
    "        # aspp (high-level)\n",
    "        self.aspp = _AtrousSpatialPyramidPoolingModule(in_dim=2048, reduction_dim=256,\n",
    "                                                       output_stride=8 if self.variant == 'D' else 16)\n",
    "        self.bot_aspp = nn.Conv2d(1280, 256, kernel_size=1, bias=False)\n",
    "        \n",
    "        # low-level feature projection\n",
    "        self.bot_fine = nn.Conv2d(256, self.skip_mum, kernel_size=1, bias=False)  # skip_num=48\n",
    "            \n",
    "        # --------------------------- 1.for initial F_residual(body) & F_edge ---------------------------\n",
    "        # outputs F_residual & F_edge\n",
    "        self.edge_extractors = [Edge_extractorWofirstext(256, norm_layer=Norm2d, skip_num=48)\n",
    "                                for _ in range(self.num_cascade)]\n",
    "        self.edge_extractors = nn.ModuleList(self.edge_extractors)\n",
    "         \n",
    "        # --------------------------- 2.to refine F_residual with F_high ---------------------------\n",
    "        # high-level feature projection (F_high)\n",
    "        # (N, C, 64, 64) -> (N, 48, 128, 128)\n",
    "        self.body_fines = nn.ModuleList()\n",
    "        for i in range(self.num_cascade):  # num_cascade=3\n",
    "            inchannels = 2 ** (11 - i)\n",
    "            self.body_fines.append(nn.Conv2d(inchannels, 48, kernel_size=1, bias=False))\n",
    "        \n",
    "        # concat(F_high, F_residual)conv to outputs F_residual'\n",
    "        self.body_fuse = [nn.Conv2d(256 + 48, 256, kernel_size=1, bias=False) for _ in range(self.num_cascade)]\n",
    "        self.body_fuse = nn.ModuleList(self.body_fuse)\n",
    "        \n",
    "        # --------------------------- 2.1.final residual head ---------------------------\n",
    "        # F_residual' -> F_r (supervised by GT-residual(body) mask)\n",
    "        self.body_out_pre = [nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)) for _ in range(self.num_cascade)]\n",
    "        self.body_out_pre = nn.ModuleList(self.body_out_pre)\n",
    "        \n",
    "        self.body_out = nn.ModuleList([nn.Conv2d(256, num_classes, kernel_size=1, bias=False)\n",
    "                                       for _ in range(self.num_cascade)])\n",
    "        \n",
    "        #  --------------------------- 3. to outputs F_b(boundary) from F_edge ---------------------------\n",
    "        self.edge_out_pre = [nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)) for _ in range(self.num_cascade)]\n",
    "        self.edge_out_pre = nn.ModuleList(self.edge_out_pre)\n",
    "        \n",
    "        self.edge_out = nn.ModuleList([nn.Conv2d(256, 1, kernel_size=1, bias=False)\n",
    "                                       for _ in range(self.num_cascade)])\n",
    "        \n",
    "        # --------------------------- 4. point-based GCN to refine F_merge with F_b  ---------------------------\n",
    "        # refine F_merge -> F_m where F_merge = F_residual + F_edge (from stage 1)\n",
    "        self.refines = [ContourPointGCN(256, self.num_points, self.threshold) for _ in range(self.num_cascade)]\n",
    "        self.refines = nn.ModuleList(self.refines)\n",
    "        \n",
    "        # --------------------------- 5. final seg head with F_m ---------------------------\n",
    "        self.final_seg_out_pre = [nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)) for _ in range(self.num_cascade - 1)]\n",
    "        \n",
    "        self.final_seg_out_pre.append(nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)))  \n",
    "        self.final_seg_out_pre = nn.ModuleList(self.final_seg_out_pre)\n",
    "         \n",
    "        self.final_seg_out = nn.ModuleList([nn.Conv2d(256, num_classes, kernel_size=1, bias=False)\n",
    "                                            for _ in range(self.num_cascade)])\n",
    "        \n",
    "    def forward(self, x, gts=None):\n",
    "        '''x: (N, 3, 512, 512)'''\n",
    "        \n",
    "        # ------------------ 0. extract features ------------------\n",
    "        x_size = x.size()  \n",
    "        # intermediate features\n",
    "        feats = []\n",
    "        feats.append(self.layer0(x))  # (N, 64, 128, 128) \n",
    "        feats.append(self.layer1(feats[0]))  # (N, 256, 128, 128) \n",
    "        feats.append(self.layer2(feats[1]))  # (N, 512, 64, 64)\n",
    "        feats.append(self.layer3(feats[2]))  # (N, 1024, 64, 64)\n",
    "        feats.append(self.layer4(feats[3]))  # (N, 2048, 64, 64)\n",
    "        \n",
    "        # high-level feature\n",
    "        aspp = self.aspp(feats[-1])  # (N, 1280, 64, 64) \n",
    "        fine_size = feats[1].size()   \n",
    "        \n",
    "        aspp_ = self.bot_aspp(aspp)  # (N, 256, 64, 64) \n",
    "        final_fuse_feat = F.interpolate(aspp_, size=fine_size[2:], mode='bilinear', align_corners=True)  # (N, 256, 128, 128)\n",
    "        \n",
    "        # low-level feature projection\n",
    "        # it is used at all cascade stage\n",
    "        low_feat = self.bot_fine(feats[1])  # (N, 256, 128, 128) -> (N, 48, 128, 128)\n",
    "\n",
    "        seg_edges = []\n",
    "        seg_edge_outs = []\n",
    "        seg_bodys = []\n",
    "        seg_body_outs = []\n",
    "        seg_finals = []\n",
    "        seg_final_outs = []\n",
    "\n",
    "        for i in range(self.num_cascade):\n",
    "            if i == 0:\n",
    "                last_seg_feat = aspp_  # (N, 256, 64, 64)\n",
    "            else:\n",
    "                # seg_finals: F_m(refined F_merge where F_merge = F_edge + F_residual)\n",
    "                last_seg_feat = seg_finals[-1]  # from previous cascade stage (N, 256, 128, 128)\n",
    "                last_seg_feat = F.interpolate(last_seg_feat, size=aspp_.size()[2:],\n",
    "                                              mode='bilinear', align_corners=True)  # (N, 256, 64, 64)\n",
    "            \n",
    "            # ------------------ 1. initial F_edge & F_residual ------------------\n",
    "            # last_seg_feat: (N, 256, 64, 64) / low_feat: (N, 48, 128, 128)\n",
    "            # seg_edge: F_edge / seg_body: F_residual\n",
    "            seg_edge, seg_body = self.edge_extractors[i](last_seg_feat, low_feat)  # (N, 256, 128, 128), (N, 256, 128, 128)\n",
    "            \n",
    "            # ------------------ 2. refine F_residual -> F_residual' ------------------\n",
    "            # high-level feature projection (F_high)\n",
    "            # feats[-1]: (N, 2048, 64, 64)\n",
    "            # feats[-2]: (N, 1024, 64, 64)\n",
    "            # feats[-3]: (N,512, 64, 64)\n",
    "            high_fine = F.interpolate(self.body_fines[i](feats[-(i + 1)]), size=fine_size[2:], mode='bilinear',\n",
    "                                      align_corners=True)  # (N, 48, 128, 128)\n",
    "            \n",
    "            # F_residual -> F_residual' with F_high\n",
    "            seg_body = self.body_fuse[i](torch.cat([seg_body, high_fine], dim=1))  # (N, 256, 128, 128)\n",
    "            \n",
    "            # ------------------ 2.1 final residual head: F_residual' -> F_r(body) ------------------\n",
    "            # F_residual' -> F_r\n",
    "            seg_body_pre = self.body_out_pre[i](seg_body)  # (N, 256, 128, 128)\n",
    "            seg_body_out = F.interpolate(self.body_out[i](seg_body_pre), size=x_size[2:],\n",
    "                                         mode='bilinear', align_corners=True)  # (N, # classes, 512, 512)\n",
    "            seg_bodys.append(seg_body_pre)\n",
    "            seg_body_outs.append(seg_body_out)\n",
    "            \n",
    "            # ------------------ 3. F_edge -> F_b(boundary) ------------------\n",
    "            # F_edge -> F_b (boundary)\n",
    "            seg_edge_pre = self.edge_out_pre[i](seg_edge)  # (N, 256, 128, 128)\n",
    "            seg_edge_out_pre = self.edge_out[i](seg_edge_pre)  # (N, 1, 128, 128)\n",
    "\n",
    "            seg_edge_out = F.interpolate(seg_edge_out_pre, size=x_size[2:],\n",
    "                                         mode='bilinear', align_corners=True)  # (N, 1, 512, 512)\n",
    "            seg_edges.append(seg_edge_pre)\n",
    "            seg_edge_outs.append(seg_edge_out)\n",
    "            \n",
    "            # ------------------ F_merge = F_body + F_edge (from 1.) ------------------\n",
    "            seg_out = seg_body + seg_edge  # (N, 256, 128, 128)\n",
    "            \n",
    "            # ------------------ 4. F_merge -> F_merge' with PGM ------------------\n",
    "            # seg_edge_out_pre: F_b(HXWX1)\n",
    "            seg_out2 = self.refines[i](seg_out, torch.sigmoid(seg_edge_out_pre.clone().detach()))  # (N, 256, 128, 128)\n",
    "            \n",
    "            # ------------------ 5. final semantic segmentation ------------------\n",
    "            if i >= self.num_cascade - 1:\n",
    "                # final_fuse_feat: projected aspp (N, 256, 128, 128)\n",
    "                seg_final_pre = self.final_seg_out_pre[i](torch.cat([final_fuse_feat, seg_out2], dim=1))  # (N, 256, 128, 128)\n",
    "            else:\n",
    "                seg_final_pre = self.final_seg_out_pre[i](seg_out2)  # (N, 256, 128, 128)\n",
    "                \n",
    "            seg_final_out = F.interpolate(self.final_seg_out[i](seg_final_pre), size=x_size[2:],\n",
    "                                          mode='bilinear', align_corners=True)  # (N, # classes, 512, 512)\n",
    "            seg_finals.append(seg_final_pre)\n",
    "            seg_final_outs.append(seg_final_out)\n",
    "\n",
    "        # if self.training:\n",
    "        #    return self.criterion((seg_final_outs, seg_body_outs, seg_edge_outs), gts)\n",
    "\n",
    "        return seg_final_outs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f221af7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "model = EBLNet(num_classes=2, trunk='resnext-101-32x8', variant='D', skip='m1', skip_num=48,  # num_classes=2 for bg/fg\n",
    "               num_cascade=3, num_points=97, threshold=0.9)\n",
    "x = torch.randn([2, 3, 512, 512])\n",
    "out = model(x, gts=None)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141f618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ad62f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
