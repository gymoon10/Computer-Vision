{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MoCoV1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8mU3nk8A1qo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utils\n",
        "@torch.no_grad()\n",
        "def concat_all_gather(tensor):\n",
        "    \"\"\"\n",
        "    Performs all_gather operation on the provided tensors.\n",
        "    *** Warning ***: torch.distributed.all_gather has no gradient.\n",
        "    \"\"\"\n",
        "    tensors_gather = [torch.ones_like(tensor)\n",
        "        for _ in range(torch.distributed.get_world_size())]\n",
        "    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
        "\n",
        "    output = torch.cat(tensors_gather, dim=0)\n",
        "    \n",
        "    return output"
      ],
      "metadata": {
        "id": "WCTigSXyGezj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://user-images.githubusercontent.com/44194558/154207714-c25c7c84-12b4-4702-89a2-c3eaad687369.png)\n"
      ],
      "metadata": {
        "id": "Mh6rkpD0Mdw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MoCo(nn.Module):\n",
        "    \"\"\"\n",
        "    Build a MoCo model with: a query encoder, a key encoder, and a queue\n",
        "    https://arxiv.org/abs/1911.05722\n",
        "    \"\"\"\n",
        "    def __init__(self, base_encoder, dim=128, K=65536, m=0.999, T=0.07, mlp=False):\n",
        "        \"\"\"\n",
        "        dim: feature dimension (default: 128)\n",
        "        K: queue size; # of negative keys (default: 65536)\n",
        "        m: MoCo momentum of updating key encoder (default: 0.999)\n",
        "        T: softmax temperature (default: 0.07)\n",
        "        \"\"\"\n",
        "        super(MoCo, self).__init__()\n",
        "\n",
        "        self.K = K\n",
        "        self.m = m\n",
        "        self.T = T\n",
        "        \n",
        "        # Encoder networks for Query & Key\n",
        "        #self.encoder_q = base_encoder(num_classes=dim)\n",
        "        #self.encoder_k = base_encoder(num_classes=dim)\n",
        "\n",
        "        self.encoder_q = resnet18(pretrained=False, num_classes=128)  # 128 차원의 representation으로 encoding\n",
        "        self.encoder_k = resnet18(pretrained=False, num_classes=128)\n",
        "\n",
        "        if mlp:  # for MoCoV2\n",
        "            # self.encoder_q.fc = Linear(in_features, out_features=dim=128)\n",
        "            dim_mlp = self.encoder_q.fc.weight.shape[1]  # in_features의 차원\n",
        "            self.encoder_q.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_q.fc)  # F.C layer에 앞쪽에 새로운 Linear layer, ReLU 추가\n",
        "            self.encoder_k.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_k.fc)\n",
        "        \n",
        "        # theta_q, theta_k\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data.copy_(param_q.data)  # initialize\n",
        "            param_k.requires_grad = False  # not update by gradient (역전파를 통해 갱신되는 것은 encoder_q의 파라미터 뿐)\n",
        "\n",
        "        # Queue 생성\n",
        "        self.register_buffer(\"queue\", torch.randn(dim, K))  # [128, 65536] - 128차원의 feature로 표현되는 65536개의 negative sample들\n",
        "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
        "\n",
        "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))  # pointer (enqueue, dequeue용)\n",
        "    \n",
        "    # Momentum update for Key encoder\n",
        "    @torch.no_grad()  # 역전파에 의한 갱신 x\n",
        "    def _momentum_update_key_encoder(self):\n",
        "        \"\"\"\n",
        "        Momentum update of the key encoder\n",
        "        \"\"\"\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
        "        \n",
        "    @torch.no_grad()\n",
        "    def _dequeue_and_enqueue(self, keys):\n",
        "        # gather keys before updating queue\n",
        "        keys = concat_all_gather(keys)\n",
        "\n",
        "        batch_size = keys.shape[0]\n",
        "\n",
        "        ptr = int(self.queue_ptr)  # pointer\n",
        "        assert self.K % batch_size == 0  # for simplicity\n",
        "\n",
        "        # replace the keys at ptr (dequeue and enqueue)\n",
        "        self.queue[:, ptr:ptr + batch_size] = keys.T  # 가장 과거의 mini-batch를 교체\n",
        "        ptr = (ptr + batch_size) % self.K  # move pointer\n",
        "\n",
        "        self.queue_ptr[0] = ptr       \n",
        "    \n",
        "    # Shuffling BN (Shuffling없이 BN을 적용시키면 성능 감소)\n",
        "    @torch.no_grad()\n",
        "    def _batch_shuffle_ddp(self, x):\n",
        "        \"\"\"\n",
        "        Batch shuffle, for making use of BatchNorm.\n",
        "        *** Only support DistributedDataParallel (DDP) model. ***\n",
        "        \"\"\"\n",
        "        # gather from all gpus\n",
        "        batch_size_this = x.shape[0]\n",
        "        x_gather = concat_all_gather(x)\n",
        "        batch_size_all = x_gather.shape[0]\n",
        "\n",
        "        num_gpus = batch_size_all // batch_size_this\n",
        "\n",
        "        # random shuffle index\n",
        "        idx_shuffle = torch.randperm(batch_size_all).cuda()\n",
        "\n",
        "        # broadcast to all gpus\n",
        "        torch.distributed.broadcast(idx_shuffle, src=0)\n",
        "\n",
        "        # index for restoring\n",
        "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
        "\n",
        "        # shuffled index for this gpu\n",
        "        gpu_idx = torch.distributed.get_rank()\n",
        "        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n",
        "\n",
        "        return x_gather[idx_this], idx_unshuffle\n",
        "    \n",
        "    @torch.no_grad()\n",
        "    def _batch_unshuffle_ddp(self, x, idx_unshuffle):\n",
        "        \"\"\"\n",
        "        Undo batch shuffle.\n",
        "        *** Only support DistributedDataParallel (DDP) model. ***\n",
        "        \"\"\"\n",
        "        # gather from all gpus\n",
        "        batch_size_this = x.shape[0]\n",
        "        x_gather = concat_all_gather(x)\n",
        "        batch_size_all = x_gather.shape[0]\n",
        "\n",
        "        num_gpus = batch_size_all // batch_size_this\n",
        "\n",
        "        # restored index for this gpu\n",
        "        gpu_idx = torch.distributed.get_rank()\n",
        "        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n",
        "\n",
        "        return x_gather[idx_this]\n",
        "\n",
        "    def forward(self, im_q, im_k):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            im_q: a batch of query images (randomly augmented version of X)\n",
        "            im_k: a batch of key images  (another randomly augmented version of X)\n",
        "        Output:\n",
        "            logits, targets\n",
        "        \"\"\"\n",
        "\n",
        "        # 1. Compute Query features\n",
        "        q = self.encoder_q(im_q)  # queries: NxC (C=dim=128)\n",
        "        q = nn.functional.normalize(q, dim=1)\n",
        "\n",
        "        # 2. Compute Key features\n",
        "        with torch.no_grad():  # no gradient to keys\n",
        "            self._momentum_update_key_encoder()  # (momentum)update the key encoder\n",
        "\n",
        "            # shuffle for making use of BN\n",
        "            im_k, idx_unshuffle = self._batch_shuffle_ddp(im_k)\n",
        "\n",
        "            k = self.encoder_k(im_k)  # keys: NxC\n",
        "            k = nn.functional.normalize(k, dim=1)\n",
        "\n",
        "            # undo shuffle\n",
        "            k = self._batch_unshuffle_ddp(k, idx_unshuffle)\n",
        "\n",
        "        # 3. Compute logits\n",
        "        l_pos = torch.einsum('nc, nc -> n', [q, k]).unsqueeze(-1)  # positive logits: Nx1 ([N, 1, C] x [N, C, 1])\n",
        "        l_neg = torch.einsum('nc, ck -> nk', [q, self.queue.clone().detach()])  # negative logits: NxK ([N, C] x [C, K], no gradient)\n",
        "\n",
        "        logits = torch.cat([l_pos, l_neg], dim=1)  # concat\n",
        "        logits /= self.T\n",
        "\n",
        "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
        "\n",
        "        # dequeue and enqueue\n",
        "        self._dequeue_and_enqueue(k)\n",
        "\n",
        "        return logits, labels"
      ],
      "metadata": {
        "id": "U_W1I9G3A-es"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}