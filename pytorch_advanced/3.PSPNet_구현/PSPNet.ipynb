{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSPNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "다음 4개의 모듈 구현\n",
        "\n",
        "1. Feature\n",
        "\n",
        "2. Pyramid Pooling\n",
        "\n",
        "3. Decoder\n",
        "\n",
        "4. AuxLoss"
      ],
      "metadata": {
        "id": "ar1TV2JNQ-H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "QSZemncVRD6A"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PSPNet 네트워크 구조"
      ],
      "metadata": {
        "id": "isw3ta4mRbKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 모듈, 네트워크를 1~3 과정으로 구현\n",
        "class PSPNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(PSPNet, self).__init__()\n",
        "\n",
        "        # parameters\n",
        "        block_config = [3, 4, 6, 3]  # resnet50\n",
        "        img_size = 475\n",
        "        img_size_8 = 60\n",
        "\n",
        "        # 1. Feature 모듈의 sub-networks\n",
        "        self.feature_conv = FeatureMap_convolution()\n",
        "\n",
        "        self.feature_res_1 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n",
        "        self.feature_res_2 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n",
        "        \n",
        "        self.feature_dilated_res_1 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n",
        "        self.feature_dilated_res_2 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n",
        "        \n",
        "        # 2. Pyramid Pooling\n",
        "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[6, 3, 2, 1],  # 입력을 5개로 분기시켜 pooling (1개는 pooling없이 입력을 그대로 사용)\n",
        "                                              height=img_size_8, width=img_size_8)\n",
        "\n",
        "        # 3. Decoder (Up-sampling)\n",
        "        self.decode_feature = DecodePSPFeature(\n",
        "            height=img_size, width=img_size, n_classes=n_classes)\n",
        "\n",
        "        # 4. AuxLoss\n",
        "        self.aux = AuxiliaryPSPlayers(\n",
        "            in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.feature_conv(x)\n",
        "        x = self.feature_res_1(x)\n",
        "        x = self.feature_res_2(x)\n",
        "        x = self.feature_dilated_res_1(x)\n",
        "\n",
        "        output_aux = self.aux(x)  # Feature 모듈의 중간 출력을 AuxLoss 모듈의 입력으로 제공 -> (21, 475, 475)\n",
        "\n",
        "        x = self.feature_dilated_res_2(x)  # Feature 모듈의 최종 output\n",
        "        \n",
        "        # Pyramid pooling 이후 Decoder를 통해 각 픽셀의 클래스 라벨 예측\n",
        "        x = self.pyramid_pooling(x)\n",
        "        output = self.decode_feature(x)  # (21, 475, 475)\n",
        "\n",
        "        return (output, output_aux)"
      ],
      "metadata": {
        "id": "WyLq-WhIRaFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Feature 모듈\n",
        "\n",
        "Encoder 모듈 - 입력 이미지의 특징 파악\n",
        "\n",
        "(3, 475, 475) -> (2048, 60, 60) feature map\n",
        "\n",
        "총 5개의 sub-network로 구성\n",
        "\n",
        " - 1개의 FeatureMap_convolution\n",
        " - 2개의 ResidualBlockPSP - 1개의 BottleNeckPSP, 다수의 BottleNeckIdentifyPSP (block_config 참고)\n",
        " - 2개의 DilatedResidualBlockPSP "
      ],
      "metadata": {
        "id": "Kr-w1J5AVbNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 FeatureMap_convolution\n",
        "\n",
        "합성곱, 배치 정규화, ReLU를 세트로 하는 conv2dBatchNormRelu 3개 + pooling\n",
        "\n",
        "(3, 475, 475) -> (128, 119, 119)"
      ],
      "metadata": {
        "id": "owA_OGHpW2d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class conv2DBatchNormRelu(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
        "        super(conv2DBatchNormRelu, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
        "                              kernel_size, stride, padding, dilation, bias=bias)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)  # ReLU에 대한 입력을 메모리에 저장하지 않고 그대로 출력 계산 (메모리 절약 옵션)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.batchnorm(x)\n",
        "        outputs= self.relu(x)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "wulqkHfMUEZx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3개의 FeatureMap_convolution을 통과 후 pooling layer 거침\n",
        "class FeatureMap_convolution(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureMap_convolution, self).__init__()\n",
        "    \n",
        "        # Conv1\n",
        "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 3, 64, 3, 2, 1, 1, False  # 입력 : (3, 475, 475)\n",
        "        self.cbnr_1 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)  # (64, 238, 238)\n",
        "\n",
        "        # Conv2\n",
        "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 64, 3, 1, 1, 1, False  # stride=1\n",
        "        self.cbnr_2 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)  # (64, 238, 238)\n",
        "\n",
        "        # Conv3\n",
        "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 128, 3, 1, 1, 1, False  # stride=1\n",
        "        self.cbnr_3 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)  # (128, 238, 238)\n",
        "\n",
        "        # MaxPooling\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # (128, 119, 119)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cbnr_1(x)\n",
        "        x = self.cbnr_2(x)\n",
        "        x = self.cbnr_3(x)\n",
        "\n",
        "        outputs = self.maxpool(x)\n",
        "\n",
        "        return outputs  # (128, 119, 119)"
      ],
      "metadata": {
        "id": "rHoZevZdUEeU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 ResidualBlockPSP\n",
        "\n",
        "bottleNeckPSP를 통과한 후 bottleNeckIdentifyPSP를 여러 번 반복 출력 (ResNet50에서 사용하는 횟수인 block_config [3, 4, 6, 3] 에서 지정된 횟수 만큼 반복)"
      ],
      "metadata": {
        "id": "BN4a4OksZ6_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# conv + BatchNorm (Relu x)\n",
        "class conv2DBatchNorm(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
        "        super(conv2DBatchNorm, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
        "                              kernel_size, stride, padding, dilation, bias=bias)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        outputs = self.batchnorm(x)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "cBif9uswbjPV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1 bottleNeckPSP\n",
        "\n",
        "down-sampling 이후 skip-conn (차원을 맞춰주기 위해)"
      ],
      "metadata": {
        "id": "vCXlePWyoh7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class bottleNeckPSP(nn.Module):\n",
        "    def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n",
        "        super(bottleNeckPSP, self).__init__()\n",
        "        \n",
        "        # F(x)\n",
        "        self.cbr_1 = conv2DBatchNormRelu(\n",
        "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "        self.cbr_2 = conv2DBatchNormRelu(\n",
        "            mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
        "        self.cb_3 = conv2DBatchNorm(\n",
        "            mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "        \n",
        "        # x (채널을 맞춰주기 위해 1x1 conv로 down-sampling)\n",
        "        self.cb_residual = conv2DBatchNorm(\n",
        "            in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv = self.cbr_3(self.cbr_2(self.cbr_1(x)))\n",
        "        residual = self.cb_residual(x)\n",
        "\n",
        "        return self.relu(conv + residual)  # F(x) + x (skip-conn)"
      ],
      "metadata": {
        "id": "q2k6RTLobjSh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.2 bottleNeckIdentifyPSP\n",
        "\n",
        "down-sampling 없이 skip-conn"
      ],
      "metadata": {
        "id": "uqrsCg3IvYFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class bottleNeckIdentifyPSP(nn.Module):\n",
        "    def __init__(self, in_channels, mid_channels, stride, dilation):\n",
        "        super(bottleNeckIdentifyPSP, self).__init__()\n",
        "        \n",
        "        # F(x)\n",
        "        self.cbr_1 = conv2DBatchNormRelu(\n",
        "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "        self.cbr_2 = conv2DBatchNormRelu(\n",
        "            mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
        "        self.cb_3 = conv2DBatchNorm(\n",
        "            mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
        "        residual = x  # down-sampling x\n",
        "\n",
        "        return self.relu(conv + residual)  # F(x) + x"
      ],
      "metadata": {
        "id": "qJrM2TAxvPUv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlockPSP(nn.Sequential):\n",
        "    def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n",
        "        super(ResidualBlockPSP, self).__init__()\n",
        "        \n",
        "        # bottleNeckPSP\n",
        "        self.add_module(\n",
        "            'block1',\n",
        "            bottleNeckPSP(in_channels, mid_channels, out_channels, stride, dilation)\n",
        "        )\n",
        "       \n",
        "       # bottleNeckIdentifyyPSP (blcok_config에서 지정된 횟수 만큼 반복)\n",
        "        for i in range(n_blocks - 1):\n",
        "            self.add_module(\n",
        "               'block' + str(i+2),\n",
        "                bottleNeckIdentifyPSP(out_channels, mid_channels, stride, dilation)\n",
        "           )"
      ],
      "metadata": {
        "id": "Hi6TOn5DUEhZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Pyramid Pooling\n",
        "\n",
        "Feature 모듈의 최종 출력 (2048, 60, 60) tensor를 입력으로 받음\n",
        "\n",
        "해당 입력은 5개로 분기되고, 그 중 4개는 각각 AdaptiveAvgPool2d를 통과(multi-scale 처리). 마지막 분기는 (2048, 60, 60) 별다른 처리없이 그대로 4개 분기의 출력과 최종적으로 결합\n",
        "\n",
        " - P6 -> (2048, 6, 6)\n",
        " - P3 -> (2048, 3, 3)\n",
        " - P2 -> (2048, 2, 2)\n",
        " - P1 -> (2048, 1, 1)\n",
        "\n",
        "4개의 분기는 pooling 이후 각각 conv2DBatchNormRelu를 통과하여 크기는 유지한 채 동일한 512 채널을 갖도록 함\n",
        "\n",
        " - P6 -> conv2DBatchNormRelu -> (512, 6, 6)\n",
        " - P3 -> conv2DBatchNormRelu -> (512, 3, 3)\n",
        " - P2 -> conv2DBatchNormRelu -> (512, 2, 2)\n",
        " - P1 -> conv2DBatchNormRelu -> (512, 1, 1)\n",
        "\n",
        "Up-sampling을 통해 크기를 60으로 맞춰줌\n",
        "\n",
        " - P6 -> conv2DBatchNormRelu -> Up-sample -> (512, 60, 60)\n",
        " - P3 -> conv2DBatchNormRelu -> Up-sample -> (512, 60, 60)\n",
        " - P2 -> conv2DBatchNormRelu -> Up-sample -> (512, 60, 60)\n",
        " - P1 -> conv2DBatchNormRelu -> Up-sample -> (512, 60, 60)\n",
        "\n",
        "5개 분기의 출력들을 결합 (512x4 + 2048 = 4096 채널)\n",
        "\n",
        "\n",
        "multi scale 정보를 가짐. 다양한 scale의 feature map을 사용하기 때문에 높은 정밀도를 가진 semantic 분할이 가능.\n",
        "\n"
      ],
      "metadata": {
        "id": "Tk3v5sjCyNKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PyramidPooling(nn.Module):\n",
        "    def __init__(self, in_channels, pool_sizes, height, width):\n",
        "        super(PyramidPooling, self).__init__()\n",
        "\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        out_channels = int(in_channels / len(pool_sizes))\n",
        "\n",
        "        # 개별 합성곱 층 (pool_size : [6, 3, 2, 1])\n",
        "        self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])  \n",
        "        self.cbr_1 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)  # (512, 6, 6)\n",
        "        \n",
        "        self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n",
        "        self.cbr_2 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)  # (512, 3, 3)\n",
        "        \n",
        "        self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n",
        "        self.cbr_3 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)  # (512, 2, 2)\n",
        "        \n",
        "        self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n",
        "        self.cbr_4 = conv2DBatchNormRelu(\n",
        "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)  # (512, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.cbr_1(self.avpool_1(x))\n",
        "        out1 = F.interpolate(out1, size=(self.height, self.width),  # Up-sampling\n",
        "                             mode='bilinear', align_corners=True)  # (512, 60, 60)\n",
        "        \n",
        "        out2 = self.cbr_2(self.avpool_2(x))\n",
        "        out2 = F.interpolate(out2, size=(self.height, self.width),  # Up-sampling\n",
        "                             mode='bilinear', align_corners=True)  # (512, 60, 60)\n",
        "        \n",
        "        out3 = self.cbr_3(self.avpool_3(x))\n",
        "        out3 = F.interpolate(out3, size=(self.height, self.width),  # Up-sampling\n",
        "                             mode='bilinear', align_corners=True)  # (512, 60, 60)\n",
        "        \n",
        "        out4 = self.cbr_4(self.avpool_4(x))\n",
        "        out4 = F.interpolate(out4, size=(self.height, self.width),  # Up-sampling\n",
        "                             mode='bilinear', align_corners=True)  # (512, 60, 60)\n",
        "        \n",
        "        output = torch.cat([x, out1, out2, out3, out4], dim=1)  # 5개 분기의 출력들을 결합\n",
        "\n",
        "        return output  # (4096, 60, 60)"
      ],
      "metadata": {
        "id": "R8dbBRyhUEkC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Decoder & AuxLoss\n",
        "\n",
        "Pyramid pooling, Feature 모듈의 출력 tensor를 decode한 후 원래 크기 (475, 475)로 up-sampling\n",
        "\n",
        "둘 다 최종 출력은 (21, 475, 475)"
      ],
      "metadata": {
        "id": "dUHULF683-80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecodePSPFeature(nn.Module):\n",
        "    def __init__(self, height, width, n_classes):\n",
        "        super(DecodePSPFeature, self).__init__()\n",
        "\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        \n",
        "        self.cbr = conv2DBatchNormRelu(\n",
        "            in_channels=4096, out_channels=512, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
        "        self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.classification = nn.Conv2d(\n",
        "            in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cbr(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.classification(x)\n",
        "        output = F.interpolate(\n",
        "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "CtpFHhW4UEm8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AuxiliaryPSPlayers(nn.Module):\n",
        "    def __init__(self, in_channels, height, width, n_classes):\n",
        "        super(AuxiliaryPSPlayers, self).__init__()\n",
        "\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "        self.cbr = conv2DBatchNormRelu(\n",
        "            in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
        "        self.dropout = nn.Dropout2d(p=0.1)\n",
        "        self.classification = nn.Conv2d(\n",
        "            in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cbr(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.classification(x)\n",
        "        output = F.interpolate(\n",
        "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "GRejE1R16iW0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rEZY0Lug6rhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 확인"
      ],
      "metadata": {
        "id": "Jpt6GM-A6-Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 모듈, 네트워크를 1~3 과정으로 구현\n",
        "class PSPNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(PSPNet, self).__init__()\n",
        "\n",
        "        # parameters\n",
        "        block_config = [3, 4, 6, 3]  # resnet50\n",
        "        img_size = 475\n",
        "        img_size_8 = 60\n",
        "\n",
        "        # 1. Feature 모듈의 sub-networks\n",
        "        self.feature_conv = FeatureMap_convolution()\n",
        "\n",
        "        self.feature_res_1 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n",
        "        self.feature_res_2 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n",
        "        \n",
        "        self.feature_dilated_res_1 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n",
        "        self.feature_dilated_res_2 = ResidualBlockPSP(\n",
        "            n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n",
        "        \n",
        "        # 2. Pyramid Pooling\n",
        "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[6, 3, 2, 1],  # 입력을 5개로 분기시켜 pooling (1개는 pooling없이 입력을 그대로 사용)\n",
        "                                              height=img_size_8, width=img_size_8)\n",
        "\n",
        "        # 3. Decoder (Up-sampling)\n",
        "        self.decode_feature = DecodePSPFeature(\n",
        "            height=img_size, width=img_size, n_classes=n_classes)\n",
        "\n",
        "        # 4. AuxLoss\n",
        "        self.aux = AuxiliaryPSPlayers(\n",
        "            in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.feature_conv(x)\n",
        "        x = self.feature_res_1(x)\n",
        "        x = self.feature_res_2(x)\n",
        "        x = self.feature_dilated_res_1(x)\n",
        "\n",
        "        output_aux = self.aux(x)  # Feature 모듈의 중간 출력을 AuxLoss 모듈의 입력으로 제공 -> (21, 475, 475)\n",
        "\n",
        "        x = self.feature_dilated_res_2(x)  # Feature 모듈의 최종 output\n",
        "        \n",
        "        # Pyramid pooling 이후 Decoder를 통해 각 픽셀의 클래스 라벨 예측\n",
        "        x = self.pyramid_pooling(x)\n",
        "        output = self.decode_feature(x)  # (21, 475, 475)\n",
        "\n",
        "        return (output, output_aux)"
      ],
      "metadata": {
        "id": "XOsuH26x6uqV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = PSPNet(n_classes=21)\n",
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aAuIQa57Ai_",
        "outputId": "1cd9cc35-c3aa-42de-d710-6afae67b12b1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PSPNet(\n",
              "  (feature_conv): FeatureMap_convolution(\n",
              "    (cbnr_1): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (cbnr_2): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (cbnr_3): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (feature_res_1): ResidualBlockPSP(\n",
              "    (block1): bottleNeckPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (cb_residual): conv2DBatchNorm(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block2): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block3): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (feature_res_2): ResidualBlockPSP(\n",
              "    (block1): bottleNeckPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (cb_residual): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block2): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block3): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block4): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (feature_dilated_res_1): ResidualBlockPSP(\n",
              "    (block1): bottleNeckPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (cb_residual): conv2DBatchNorm(\n",
              "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block2): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block3): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block4): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block5): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block6): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (feature_dilated_res_2): ResidualBlockPSP(\n",
              "    (block1): bottleNeckPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (cb_residual): conv2DBatchNorm(\n",
              "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block2): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (block3): bottleNeckIdentifyPSP(\n",
              "      (cbr_1): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cbr_2): conv2DBatchNormRelu(\n",
              "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (cb_3): conv2DBatchNorm(\n",
              "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (pyramid_pooling): PyramidPooling(\n",
              "    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n",
              "    (cbr_1): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n",
              "    (cbr_2): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n",
              "    (cbr_3): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n",
              "    (cbr_4): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (decode_feature): DecodePSPFeature(\n",
              "    (cbr): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (aux): AuxiliaryPSPlayers(\n",
              "    (cbr): conv2DBatchNormRelu(\n",
              "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
              "    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "dummy_img = torch.rand(batch_size, 3, 475, 475)\n",
        "\n",
        "outputs = net(dummy_img)\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "5TnLrOEL7BxZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}