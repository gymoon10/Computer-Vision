{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECO.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHRo06Jh-Eil"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ECO - Efficient Convolutional network for Online video understanding\n",
        "\n",
        "\n",
        "C3D(Convolutional 3D)는 옵티컬 플로우처럼 시간 방향의 feature representation을 데이터로부터 학습하나, 대량의 비디오 데이터를 필요로 한다는 단점 존재.\n",
        "\n",
        "ECO는 C3D의 단점을 해결하기 위해 고안. 프레임 이미지를 2차원의 합성곱 신경망에서 작은 크기의 feature로 변환하고, 이를 C3D에 입력하여 동영상을 처리\n",
        "\n",
        " - 전체 프레임을 사용하지 않고, 10초 정도 길이의 동영상에서 일정한 간격으로 총 16 프레임 정도의 이미지를 추출 -  `[# of frames, channel, H, W]`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CXDqU7lD-vFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 16 프레임의 개별 이미지가 각각 2D Net에 입력 (Inception-v2 사용)\n",
        " - 하나의 2D Net이 모든 프레임을 개별적으로 처리 & 결합\n",
        "\n",
        " - `[16, 3, 224, 224] -> [16, 96, 28, 28]`  \n",
        "\n",
        "\n",
        "2. 2D Net의 출력을 3D Net 모듈에 입력\n",
        "\n",
        "  - 공간, 시간 방향의 특징 고려\n",
        "  - `[16, 96, 28, 28] -> [512]`\n",
        "\n",
        "3. 512 채널의 1차원 feature를 F.C layer에 입력으로 제공 & 소프트맥스 계산\n",
        "\n",
        "  - `[512] -> 400 (학습 데이터의 클래스 수)` "
      ],
      "metadata": {
        "id": "HR0_G09sA_Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vQDDIjBX_aLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 2D Net (Inception-v2)\n",
        "\n",
        "**구성**\n",
        "\n",
        "`입력 : [3, 224, 224] - 개별 프레임 (총 16개)`\n",
        "\n",
        "1. BasicConv `-> [192, 28, 28]` \n",
        "\n",
        "2. InceptionA `-> [256, 28, 28]` \n",
        "\n",
        "3. InceptionB `-> [320, 28, 28]` \n",
        "\n",
        "4. InceptionC `-> [96, 28, 28] - 최종 출력` \n"
      ],
      "metadata": {
        "id": "XYYWIRHTDg58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "8WbGaY1LDl15"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1 BasicConv\n",
        "\n",
        "2D Conv, 배치 정규화, ReLU, MaxPooling을 이용하는 기본적인 합성곱 신경망 모듈"
      ],
      "metadata": {
        "id": "9SROpTwpE1jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicConv(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BasicConv, self).__init__()\n",
        "        \n",
        "        # C7 + B + R\n",
        "        self.conv1_7x7_s2 = nn.Conv2d(\n",
        "            3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
        "        self.conv1_7x7_s2_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv1_relu_7x7 = nn.ReLU(inplace=True)\n",
        "        \n",
        "        # MP 3\n",
        "        self.pool1_3x3_s2 = nn.MaxPool2d(\n",
        "            kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
        "        \n",
        "        # C1 + B + R\n",
        "        self.conv2_3x3_reduce = nn.Conv2d(\n",
        "            64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.conv2_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_relu_3x3_reduce = nn.ReLU(inplace=True)\n",
        "\n",
        "        # C3 + B + R\n",
        "        self.conv2_3x3 = nn.Conv2d(\n",
        "            64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv2_3x3_bn = nn.BatchNorm2d(\n",
        "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_relu_3x3 = nn.ReLU(inplace=True)\n",
        "        \n",
        "        # # MP 3\n",
        "        self.pool2_3x3_s2 = nn.MaxPool2d(\n",
        "            kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
        "        \n",
        "    def forward(self, x):   # x : [3, 224, 224]\n",
        "        # C7 + B + R\n",
        "        out = self.conv1_7x7_s2(x)\n",
        "        out = self.conv1_7x7_s2_bn(out)\n",
        "        out = self.conv1_relu_7x7(out)  # [64, 112, 112]\n",
        "        \n",
        "        # MP 3\n",
        "        out = self.pool1_3x3_s2(out)  # [64, 56, 56]\n",
        "\n",
        "        # C1 + B + R\n",
        "        out = self.conv2_3x3_reduce(out)\n",
        "        out = self.conv2_3x3_reduce_bn(out)\n",
        "        out = self.conv2_relu_3x3_reduce(out)  # [64, 56, 56]\n",
        "\n",
        "        # C3 + B + R\n",
        "        out = self.conv2_3x3(out)\n",
        "        out = self.conv2_3x3_bn(out)\n",
        "        out = self.conv2_relu_3x3(out)  # [192, 56, 56]\n",
        "        \n",
        "        # MP 3\n",
        "        out = self.pool2_3x3_s2(out)  # [192, 28, 28]\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "zWOgHdZSDnn1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 InceptionA\n",
        "\n",
        "입력이 분기된 후 합성곱층, 배치 정규화, ReLU에 의해 병렬적으로 처리되고 결합\n",
        "\n",
        " - GoogLeNet에서 처음 제안된 기법\n",
        "\n",
        " - 필터 크기가 작은 합성곱 층을 병렬시킴으로써 필터 크기가 큰 합성곱 층을 대체\n",
        " - 학습할 파라미터를 줄이면서도 보다 깊은 네트워크를 구성할 수 있다는 장점\n",
        " (5x5 vs 3x3 + 2x2)\n",
        "\n",
        "<br/>\n",
        "\n",
        "InceptionB와 기본적인 방식은 동일 (네트워크 구조만 약간 다름)"
      ],
      "metadata": {
        "id": "Wy5WaCMJIfG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionA(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(InceptionA, self).__init__()\n",
        "        \n",
        "        # 분기 1 : C1+B+R\n",
        "        self.inception_3a_1x1 = nn.Conv2d(\n",
        "            192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_1x1_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_1x1 = nn.ReLU(inplace=True)\n",
        "        \n",
        "        # 분기 2 : C1+B+R & C3+B+R\n",
        "        self.inception_3a_3x3_reduce = nn.Conv2d(\n",
        "            192, 64, kernel_size=(1, 1), stride=(1, 1))  \n",
        "        self.inception_3a_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_3x3_reduce = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3a_3x3 = nn.Conv2d(\n",
        "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_3x3_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_3x3 = nn.ReLU(inplace=True)\n",
        "        \n",
        "        # 분기 3 : C1+B+R & C3+B+R & C3+B+R\n",
        "        self.inception_3a_double_3x3_reduce = nn.Conv2d(\n",
        "            192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_double_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_double_3x3_reduce = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3a_double_3x3_1 = nn.Conv2d(\n",
        "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_double_3x3_1_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_double_3x3_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3a_double_3x3_2 = nn.Conv2d(\n",
        "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3a_double_3x3_2_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_double_3x3_2 = nn.ReLU(inplace=True)\n",
        "        \n",
        "        # 분기 4 : AP3 & C1+B+R \n",
        "        self.inception_3a_pool = nn.AvgPool2d(\n",
        "            kernel_size=3, stride=1, padding=1)\n",
        "        \n",
        "        self.inception_3a_pool_proj = nn.Conv2d(\n",
        "            192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3a_pool_proj_bn = nn.BatchNorm2d(\n",
        "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3a_relu_pool_proj = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):  # x : [192, 28, 28] - 각 분기의 입력으로 제공\n",
        "        # 분기 1 : C1+B+R\n",
        "        out1 = self.inception_3a_1x1(x)\n",
        "        out1 = self.inception_3a_1x1_bn(out1)\n",
        "        out1 = self.inception_3a_relu_1x1(out1)  # [64, 28, 28]\n",
        "        \n",
        "        # 분기 2 : C1+B+R & C3+B+R\n",
        "        out2 = self.inception_3a_3x3_reduce(x)\n",
        "        out2 = self.inception_3a_3x3_reduce_bn(out2)\n",
        "        out2 = self.inception_3a_relu_3x3_reduce(out2)\n",
        "\n",
        "        out2 = self.inception_3a_3x3(out2)\n",
        "        out2 = self.inception_3a_3x3_bn(out2)\n",
        "        out2 = self.inception_3a_relu_3x3(out2)  # [64, 28, 28]\n",
        "        \n",
        "        # 분기 3 : C1+B+R & C3+B+R & C3+B+R\n",
        "        out3 = self.inception_3a_double_3x3_reduce(x)\n",
        "        out3 = self.inception_3a_double_3x3_reduce_bn(out3)\n",
        "        out3 = self.inception_3a_relu_double_3x3_reduce(out3)  # [64, 28, 28]\n",
        "\n",
        "        out3 = self.inception_3a_double_3x3_1(out3)\n",
        "        out3 = self.inception_3a_double_3x3_1_bn(out3)\n",
        "        out3 = self.inception_3a_relu_double_3x3_1(out3)  # [96, 28, 28]\n",
        "\n",
        "        out3 = self.inception_3a_double_3x3_2(out3)\n",
        "        out3 = self.inception_3a_double_3x3_2_bn(out3)\n",
        "        out3 = self.inception_3a_relu_double_3x3_2(out3)  # [96, 28, 28]\n",
        "        \n",
        "        # 분기 4 : AP3 & C1+B+R \n",
        "        out4 = self.inception_3a_pool(x)\n",
        "        out4 = self.inception_3a_pool_proj(out4)\n",
        "        out4 = self.inception_3a_pool_proj_bn(out4)\n",
        "        out4 = self.inception_3a_relu_pool_proj(out4)  # [32, 28, 28]\n",
        "\n",
        "        # Concat\n",
        "        outputs = [out1, out2, out3, out4]\n",
        "        outputs = torch.cat(outputs, 1)  # [256, 28, 28] - 256=64+64+96+32\n",
        "\n",
        "        return outputs "
      ],
      "metadata": {
        "id": "yfN0gBKeDsCb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3 InceptionB"
      ],
      "metadata": {
        "id": "aII6lM1eNuS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionB(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(InceptionB, self).__init__()\n",
        "\n",
        "        # 분기 1        \n",
        "        self.inception_3b_1x1 = nn.Conv2d(\n",
        "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_1x1_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_1x1 = nn.ReLU(inplace=True)\n",
        "        \n",
        "        # 분기 2\n",
        "        self.inception_3b_3x3_reduce = nn.Conv2d(\n",
        "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_3x3_reduce = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3b_3x3 = nn.Conv2d(\n",
        "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_3x3_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_3x3 = nn.ReLU(inplace=True)\n",
        "        \n",
        "        # 분기 3\n",
        "        self.inception_3b_double_3x3_reduce = nn.Conv2d(\n",
        "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_double_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_double_3x3_reduce = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3b_double_3x3_1 = nn.Conv2d(\n",
        "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_double_3x3_1_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_double_3x3_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.inception_3b_double_3x3_2 = nn.Conv2d(\n",
        "            96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3b_double_3x3_2_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_double_3x3_2 = nn.ReLU(inplace=True)\n",
        "        \n",
        "        # 분기 4\n",
        "        self.inception_3b_pool = nn.AvgPool2d(\n",
        "            kernel_size=3, stride=1, padding=1)\n",
        "        \n",
        "        self.inception_3b_pool_proj = nn.Conv2d(\n",
        "            256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3b_pool_proj_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3b_relu_pool_proj = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):  # [256, 28, 28]\n",
        "        \n",
        "        # 분기 1 \n",
        "        out1 = self.inception_3b_1x1(x)\n",
        "        out1 = self.inception_3b_1x1_bn(out1)\n",
        "        out1 = self.inception_3b_relu_1x1(out1)  # [64, 28, 28]\n",
        "        \n",
        "        # 분기 2\n",
        "        out2 = self.inception_3b_3x3_reduce(x)\n",
        "        out2 = self.inception_3b_3x3_reduce_bn(out2)\n",
        "        out2 = self.inception_3b_relu_3x3_reduce(out2)\n",
        "\n",
        "        out2 = self.inception_3b_3x3(out2)\n",
        "        out2 = self.inception_3b_3x3_bn(out2)\n",
        "        out2 = self.inception_3b_relu_3x3(out2)  # [96, 28, 28]\n",
        "        \n",
        "        # 분기 3\n",
        "        out3 = self.inception_3b_double_3x3_reduce(x)\n",
        "        out3 = self.inception_3b_double_3x3_reduce_bn(out3)\n",
        "        out3 = self.inception_3b_relu_double_3x3_reduce(out3)\n",
        "\n",
        "        out3 = self.inception_3b_double_3x3_1(out3)\n",
        "        out3 = self.inception_3b_double_3x3_1_bn(out3)\n",
        "        out3 = self.inception_3b_relu_double_3x3_1(out3)\n",
        "\n",
        "        out3 = self.inception_3b_double_3x3_2(out3)\n",
        "        out3 = self.inception_3b_double_3x3_2_bn(out3)\n",
        "        out3 = self.inception_3b_relu_double_3x3_2(out3)  # [96, 28, 28]\n",
        "        \n",
        "        # 분기 4\n",
        "        out4 = self.inception_3b_pool(x)\n",
        "\n",
        "        out4 = self.inception_3b_pool_proj(out4)\n",
        "        out4 = self.inception_3b_pool_proj_bn(out4)\n",
        "        out4 = self.inception_3b_relu_pool_proj(out4)  # [64, 28, 28]\n",
        "\n",
        "        outputs = [out1, out2, out3, out4]\n",
        "\n",
        "        return torch.cat(outputs, 1)"
      ],
      "metadata": {
        "id": "I-_07oUwDsEr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4 InceptionC\n",
        "\n",
        "분기 x (합성곱 층, 배치 정규화, ReLU로 구성)"
      ],
      "metadata": {
        "id": "U0HwwvlWQPF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionC(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(InceptionC, self).__init__()\n",
        "        \n",
        "        # C1+B+R\n",
        "        self.inception_3c_double_3x3_reduce = nn.Conv2d(\n",
        "            320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
        "        self.inception_3c_double_3x3_reduce_bn = nn.BatchNorm2d(\n",
        "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3c_relu_double_3x3_reduce = nn.ReLU(inplace=True)\n",
        "\n",
        "        # C3+B+R\n",
        "        self.inception_3c_double_3x3_1 = nn.Conv2d(\n",
        "            64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.inception_3c_double_3x3_1_bn = nn.BatchNorm2d(\n",
        "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.inception_3c_relu_double_3x3_1 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):  # [320, 28, 28]\n",
        "        # C1+B+R\n",
        "        out = self.inception_3c_double_3x3_reduce(x)\n",
        "        out = self.inception_3c_double_3x3_reduce_bn(out)\n",
        "        out = self.inception_3c_relu_double_3x3_reduce(out)  # [64, 28, 28]\n",
        "        \n",
        "        # C3+B+R\n",
        "        out = self.inception_3c_double_3x3_1(out)\n",
        "        out = self.inception_3c_double_3x3_1_bn(out)\n",
        "        out = self.inception_3c_relu_double_3x3_1(out)  # [96, 28, 28]\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "IJ9poBzPDsJ8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.5 ECO의 2D Net 모듈 구현\n",
        "\n",
        "1.1 ~ 1.4를 묶음"
      ],
      "metadata": {
        "id": "-yfMTb4lQyWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ECO_2D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ECO_2D, self).__init__()\n",
        "\n",
        "        # BasicConv\n",
        "        self.basic_conv = BasicConv()\n",
        "\n",
        "        # Inception\n",
        "        self.inception_a = InceptionA()\n",
        "        self.inception_b = InceptionB()\n",
        "        self.inception_c = InceptionC()\n",
        "\n",
        "    def forward(self, x):  # [3, 224, 224] - 개별 프레임\n",
        "        out = self.basic_conv(x)  # [192, 28, 28]\n",
        "        out = self.inception_a(out)  # [256, 28, 28]\n",
        "        out = self.inception_b(out)  # [320, 28, 28]\n",
        "        out = self.inception_c(out)  # [96, 28, 28]\n",
        "\n",
        "        return out  "
      ],
      "metadata": {
        "id": "cXqdTNwRDsMs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 동작 확인\n",
        "net = ECO_2D()\n",
        "net.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj-cEp-yRluR",
        "outputId": "d9aefcf6-18fe-4a41-c042-9442660d9a5b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ECO_2D(\n",
              "  (basic_conv): BasicConv(\n",
              "    (conv1_7x7_s2): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv1_relu_7x7): ReLU(inplace=True)\n",
              "    (pool1_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2_relu_3x3_reduce): ReLU(inplace=True)\n",
              "    (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2_relu_3x3): ReLU(inplace=True)\n",
              "    (pool2_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  )\n",
              "  (inception_a): InceptionA(\n",
              "    (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_1x1): ReLU(inplace=True)\n",
              "    (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_3x3_reduce): ReLU(inplace=True)\n",
              "    (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_3x3): ReLU(inplace=True)\n",
              "    (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "    (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_double_3x3_1): ReLU(inplace=True)\n",
              "    (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_double_3x3_2): ReLU(inplace=True)\n",
              "    (inception_3a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
              "    (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3a_relu_pool_proj): ReLU(inplace=True)\n",
              "  )\n",
              "  (inception_b): InceptionB(\n",
              "    (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_1x1): ReLU(inplace=True)\n",
              "    (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_3x3_reduce): ReLU(inplace=True)\n",
              "    (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_3x3): ReLU(inplace=True)\n",
              "    (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "    (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_double_3x3_1): ReLU(inplace=True)\n",
              "    (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_double_3x3_2): ReLU(inplace=True)\n",
              "    (inception_3b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
              "    (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3b_relu_pool_proj): ReLU(inplace=True)\n",
              "  )\n",
              "  (inception_c): InceptionC(\n",
              "    (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3c_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "    (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (inception_3c_relu_double_3x3_1): ReLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.6 네트워크 시각화"
      ],
      "metadata": {
        "id": "nJS2KjyQSOWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsn7YhNkSZcC",
        "outputId": "fcc526ce-162e-4d78-cb59-1aa152d72ec0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. tensorboardX의 저장 클래스를 호출합니다\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "# 2. \"tbX\" 폴더에 저장할 writer를 준비합니다\n",
        "# \"tbX\" 폴더가 존재하지 않는 경우 작성합니다\n",
        "writer = SummaryWriter(\"./tbX/\")\n",
        "\n",
        "\n",
        "# 3. 네트워크에 넣을 더미 데이터를 작성합니다\n",
        "batch_size = 1\n",
        "dummy_img = torch.rand(batch_size, 3, 224, 224)\n",
        "\n",
        "# 4. net에 대한 더미 데이터\n",
        "# dummy_img를 넣었을 때의 graph를 writer에 저장시킵니다\n",
        "writer.add_graph(net, (dummy_img, ))\n",
        "writer.close()\n",
        "\n",
        "\n",
        "# 5. 명령 프롬프트를 열어서, \"tbX\" 폴더가 위치한 폴더에 이동하여, \n",
        "# 다음 명령을 실행합니다\n",
        "\n",
        "# tensorboard --logdir=\"./tbX/\"\n",
        "\n",
        "# 그 후, http://localhost:6006 에 액세스합니다"
      ],
      "metadata": {
        "id": "rg2AKD9WSDgq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 3D Net (3DCNN)\n",
        "\n",
        "`입력 : [16, 96, 28, 28] - [frames, c, h, w] (배치 고려 x)`\n",
        "\n",
        "`출력 : 채널=512의 텐서`\n",
        "\n",
        "<br/>\n",
        "\n",
        "**구성**\n",
        "\n",
        "1. 입력 텐서 차원 변경\n",
        "  - (시간=frames, 높이, 폭)의 순서에 맞게 \n",
        "\n",
        "  - `[16, 96, 28, 28] -> [96, 16, 28, 28]`\n",
        "\n",
        "2. Resnet_3D_3\n",
        "\n",
        "  - `[96, 16, 28, 28] -> [128, 16, 28, 28]`\n",
        "\n",
        "3. Resnet_3D_4\n",
        "\n",
        "  - `[128, 16, 28, 28] -> [256, 8, 14, 14]`\n",
        "\n",
        "4. Resnet_3D_5\n",
        "\n",
        "  - `[256, 8, 14, 14] -> [512, 4, 7, 7]`\n",
        "\n",
        "5. 3x3 Average Pooling\n",
        "\n",
        "  - `[512, 4, 7, 7] -> [512, 1, 1, 1]`"
      ],
      "metadata": {
        "id": "RgwAaiBWSnuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Resnet_3D_3\n",
        "\n",
        "Conv3D : https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html?highlight=conv3d#torch.nn.Conv3d\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/152112177-44eba40d-416f-499e-a30a-68b42de6c7f1.png)\n",
        "\n",
        " - 여기에선 N은 고려 x"
      ],
      "metadata": {
        "id": "Cdl5D4KCWOVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With square kernels and equal stride\n",
        "m = nn.Conv3d(16, 33, 3, stride=2)\n",
        "\n",
        "# non-square kernels and unequal stride and with padding\n",
        "m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0))\n",
        "\n",
        "input = torch.randn(20, 16, 10, 50, 100)\n",
        "output = m(input)\n",
        "\n",
        "print('input :', input.shape)\n",
        "print('output :', output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "429D1MxXXUM8",
        "outputId": "dd6f87d2-0ac9-441a-b21a-076181de1d4c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input : torch.Size([20, 16, 10, 50, 100])\n",
            "output : torch.Size([20, 33, 8, 50, 99])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet_3D_3(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet_3D_3, self).__init__()\n",
        "        \n",
        "        # 3DC3 - Residual X\n",
        "        self.res3a_2 = nn.Conv3d(\n",
        "            96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        # B+R & 3DC3+B+R & 3DC3 - F(X) \n",
        "        self.res3a_bn = nn.BatchNorm3d(\n",
        "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res3a_relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.res3b_1 = nn.Conv3d(\n",
        "            128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        self.res3b_1_bn = nn.BatchNorm3d(\n",
        "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res3b_1_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.res3b_2 = nn.Conv3d(\n",
        "            128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        # B+R - F(X)+X 처리\n",
        "        self.res3b_bn = nn.BatchNorm3d(\n",
        "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res3b_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):  # [96, 16, 28, 28]\n",
        "       \n",
        "        # Residual (3DC3) : X\n",
        "        residual = self.res3a_2(x)\n",
        "\n",
        "        # B+R & 3DC3+B+R & 3DC3 : F(X)\n",
        "        out = self.res3a_bn(residual)\n",
        "        out = self.res3a_relu(out)\n",
        "\n",
        "        out = self.res3b_1(out)\n",
        "        out = self.res3b_1_bn(out)\n",
        "        out = self.res3b_relu(out)\n",
        "\n",
        "        out = self.res3b_2(out)\n",
        "        \n",
        "        # Skip-conn : F(X) + X\n",
        "        out += residual\n",
        "        \n",
        "        # B+R\n",
        "        out = self.res3b_bn(out)\n",
        "        out = self.res3b_relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "5hh-1xcfSh2a"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2 Resnet_3D_4\n",
        "\n",
        "skip-conn 2회 반복"
      ],
      "metadata": {
        "id": "abJvfA_YZVUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet_3D_4(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet_3D_4, self).__init__()\n",
        "        \n",
        "        # 분기 1.1 - 3DC3+B+R & 3DC3\n",
        "        self.res4a_1 = nn.Conv3d(\n",
        "            128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        self.res4a_1_bn = nn.BatchNorm3d(\n",
        "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res4a_1_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.res4a_2 = nn.Conv3d(\n",
        "            256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        # 분기 1.2 - 3DC3\n",
        "        self.res4a_down = nn.Conv3d(\n",
        "            128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        \n",
        "        ## 분기 1.1, 1.2의 출력 결합 (skip-conn) - residual_2 ##\n",
        "        \n",
        "        # 분기 2 - B+R & 3DC3+B+R & 3DC3\n",
        "        self.res4a_bn = nn.BatchNorm3d(\n",
        "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res4a_relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.res4b_1 = nn.Conv3d(256, 256, kernel_size=(\n",
        "            3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        self.res4b_1_bn = nn.BatchNorm3d(\n",
        "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res4b_1_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.res4b_2 = nn.Conv3d(256, 256, kernel_size=(\n",
        "            3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        ## 분기 2의 출력, residual_2 결합 ##\n",
        "\n",
        "        # B+R - 위의 결합 처리\n",
        "        self.res4b_bn = nn.BatchNorm3d(\n",
        "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res4b_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):  # [128, 16, 28, 28]\n",
        "\n",
        "        # 분기 1.2 - 3DC3\n",
        "        residual = self.res4a_down(x)  # [256, 8, 14, 14]\n",
        "        \n",
        "        # 분기 1.1 - 3DC3+B+R & 3DC3\n",
        "        out = self.res4a_1(x)\n",
        "        out = self.res4a_1_bn(out)\n",
        "        out = self.res4a_1_relu(out)\n",
        "\n",
        "        out = self.res4a_2(out)  # [256, 8, 14, 14]\n",
        "        \n",
        "        # Skip-conn (분기 1.1 + 1.2)\n",
        "        out += residual  # [256, 8, 14, 14]\n",
        "\n",
        "        residual2 = out\n",
        "        \n",
        "        # 분기 2 - B+R & 3DC3+B+R & 3DC3\n",
        "        out = self.res4a_bn(out)\n",
        "        out = self.res4a_relu(out)\n",
        "\n",
        "        out = self.res4b_1(out)\n",
        "        out = self.res4b_1_bn(out)\n",
        "        out = self.res4b_1_relu(out)\n",
        "\n",
        "        out = self.res4b_2(out)  # [256, 8, 14, 14]\n",
        "        \n",
        "        # Skip-conn (분기 2 + residual2)\n",
        "        out += residual2  # [256, 8, 14, 14]\n",
        "        \n",
        "        # B+R\n",
        "        out = self.res4b_bn(out)\n",
        "        out = self.res4b_relu(out)\n",
        "\n",
        "        return out  "
      ],
      "metadata": {
        "id": "-ec-qHdnSUCR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3 Resnet_3D_5\n",
        "\n",
        "구성은 Resnet_3D_4와 동일 (채널 수 다름)"
      ],
      "metadata": {
        "id": "Ew6tBiu2cMgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet_3D_5(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet_3D_5, self).__init__()\n",
        "        \n",
        "        # 분기 1.1 - 3DC3+B+R & 3DC3\n",
        "        self.res5a_1 = nn.Conv3d(\n",
        "            256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        self.res5a_1_bn = nn.BatchNorm3d(\n",
        "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res5a_1_relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.res5a_2 = nn.Conv3d(\n",
        "            512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        # 분기 1.2 - 3DC3\n",
        "        self.res5a_down = nn.Conv3d(\n",
        "            256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        \n",
        "        ## Skip-conn : 분기 1.1 + 분기 1.2 -> residual 2 ##\n",
        "        \n",
        "        # 분기 2 - B+R & 3DC3+B+R & 3DC3\n",
        "        self.res5a_bn = nn.BatchNorm3d(\n",
        "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res5a_relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.res5b_1 = nn.Conv3d(\n",
        "            512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        self.res5b_1_bn = nn.BatchNorm3d(\n",
        "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res5b_1_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.res5b_2 = nn.Conv3d(\n",
        "            512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
        "        \n",
        "        ## Skip-conn : 분기 2 + residual 2 ##\n",
        "\n",
        "        # B+R\n",
        "        self.res5b_bn = nn.BatchNorm3d(\n",
        "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.res5b_relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):  # [256, 8, 14, 14]\n",
        "        \n",
        "        # 분기 1.2 - 3DC3\n",
        "        residual = self.res5a_down(x)  # [512, 4, 7, 7]\n",
        "        \n",
        "        # 분기 1.1 - 3DC3+B+R & 3DC3\n",
        "        out = self.res5a_1(x)\n",
        "        out = self.res5a_1_bn(out)\n",
        "        out = self.res5a_1_relu(out)\n",
        "\n",
        "        out = self.res5a_2(out)  # [512, 4, 7, 7]\n",
        "        \n",
        "        # Skip-conn\n",
        "        out += residual  # [512, 4, 7, 7] - res5b\n",
        "\n",
        "        residual2 = out\n",
        "        \n",
        "        # 분기 2 - B+R & 3DC3+B+R & 3DC3\n",
        "        out = self.res5a_bn(out)\n",
        "        out = self.res5a_relu(out)\n",
        "\n",
        "        out = self.res5b_1(out)\n",
        "        out = self.res5b_1_bn(out)\n",
        "        out = self.res5b_1_relu(out)\n",
        "\n",
        "        out = self.res5b_2(out)  # [512, 4, 7, 7]\n",
        "        \n",
        "        # Skip-conn\n",
        "        out += residual2  # [512, 4, 7, 7] - res5b\n",
        "        \n",
        "        # B+R\n",
        "        out = self.res5b_bn(out)\n",
        "        out = self.res5b_relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "o8QBU1feb7Uk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4 ECO의 3D Net 클래스 구현\n",
        "\n",
        "2.1 ~ 2.3 묶기"
      ],
      "metadata": {
        "id": "ku0g7-maeU7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ECO_3D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ECO_3D, self).__init__()\n",
        "\n",
        "        # 3D_Resnet 모듈\n",
        "        self.res_3d_3 = Resnet_3D_3()\n",
        "        self.res_3d_4 = Resnet_3D_4()\n",
        "        self.res_3d_5 = Resnet_3D_5()\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.global_pool = nn.AvgPool3d(\n",
        "            kernel_size=(4, 7, 7), stride=1, padding=0)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        입력 x의 크기 torch.Size([batch_num, frames=16, 96, 28, 28])\n",
        "        '''\n",
        "        # 차원 교체\n",
        "        out = torch.transpose(x, 1, 2)  # [batch_num, 96, 16, 28, 28]\n",
        "        \n",
        "        # 3D_Resnet\n",
        "        out = self.res_3d_3(out)  # [batch_num, 128, 16, 28, 28]\n",
        "        out = self.res_3d_4(out)  # [batch_num, 256, 8, 14, 14]\n",
        "        out = self.res_3d_5(out)  # [batch_num, 512, 4, 7, 7]\n",
        "\n",
        "        # GAP\n",
        "        out = self.global_pool(out)  # [batch_num, 512, 1, 1, 1]\n",
        "        \n",
        "        # 텐서 크기 변경 : [batch_num, 512, 1, 1, 1] -> [batch_num, 512]\n",
        "        out = out.view(out.size()[0], out.size()[1])\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "e-4DFGJfePqS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 동작 확인\n",
        "net = ECO_3D()\n",
        "net.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izwis0CtgMmW",
        "outputId": "665383c1-9ffc-4fd3-b8e4-c6bd84e7552e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ECO_3D(\n",
              "  (res_3d_3): Resnet_3D_3(\n",
              "    (res3a_2): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res3a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res3a_relu): ReLU(inplace=True)\n",
              "    (res3b_1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res3b_1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res3b_1_relu): ReLU(inplace=True)\n",
              "    (res3b_2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res3b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res3b_relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (res_3d_4): Resnet_3D_4(\n",
              "    (res4a_1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "    (res4a_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res4a_1_relu): ReLU(inplace=True)\n",
              "    (res4a_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res4a_down): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "    (res4a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res4a_relu): ReLU(inplace=True)\n",
              "    (res4b_1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res4b_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res4b_1_relu): ReLU(inplace=True)\n",
              "    (res4b_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res4b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res4b_relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (res_3d_5): Resnet_3D_5(\n",
              "    (res5a_1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "    (res5a_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res5a_1_relu): ReLU(inplace=True)\n",
              "    (res5a_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res5a_down): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "    (res5a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res5a_relu): ReLU(inplace=True)\n",
              "    (res5b_1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res5b_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res5b_1_relu): ReLU(inplace=True)\n",
              "    (res5b_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "    (res5b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (res5b_relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (global_pool): AvgPool3d(kernel_size=(4, 7, 7), stride=1, padding=0)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. tensorboardX의 저장 클래스를 호출합니다\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "# 2. \"tbX\" 폴더에 저장할 writer를 준비합니다\n",
        "# \"tbX\" 폴더가 존재하지 않는 경우 작성합니다\n",
        "writer = SummaryWriter(\"./tbX/\")\n",
        "\n",
        "\n",
        "# 3. 네트워크에 넣을 더미 데이터를 작성합니다\n",
        "batch_size = 1\n",
        "dummy_img = torch.rand(batch_size, 16, 96, 28, 28)\n",
        "\n",
        "# 4. net에 대한 더미 데이터\n",
        "# dummy_img를 넣었을 때의 graph를 writer에 저장시킵니다\n",
        "writer.add_graph(net, (dummy_img, ))\n",
        "writer.close()\n",
        "\n",
        "\n",
        "# 5. 명령 프롬프트를 열어서, \"tbX\" 폴더가 위치한 폴더에 이동하여, \n",
        "# 다음 명령을 실행합니다\n",
        "\n",
        "# tensorboard --logdir=\"./tbX/\"\n",
        "\n",
        "# 그 후, http://localhost:6006 에 액세스합니다"
      ],
      "metadata": {
        "id": "grU2_oEAgdrb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ncmvOs1lgf7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 최종 구현\n",
        "\n",
        "\n",
        "**유의 사항**\n",
        "\n",
        "2D Net은 nn.Conv2d는 4차원의 텐서만 입력할 수 있으므로 frame 차원을 가진 5차원 텐서는 처리하지 못함.\n",
        "\n",
        "2D Net은 2차원의 프레임 이미지를 독립적으로 처리하므로 frame 차원을 batch 차원에 포함시켜도 문제가 되지 않기 때문에 적절한 차원 변환 필요"
      ],
      "metadata": {
        "id": "blL6f3fkl_iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gymoon10/utils.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQh2NTnzmEmy",
        "outputId": "70fa06c8-eb9d-4d33-944e-8afb53462e7d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'utils'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 50 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (50/50), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.eco import ECO_2D, ECO_3D\n",
        "\n",
        "class ECO_Lite(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ECO_Lite, self).__init__()\n",
        "\n",
        "        # 2D Net \n",
        "        self.eco_2d = ECO_2D()\n",
        "\n",
        "        # 3D Net \n",
        "        self.eco_3d = ECO_3D()\n",
        "\n",
        "        # 클래스 분류 F.C layer\n",
        "        self.fc_final = nn.Linear(in_features=512, out_features=400, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        입력 x : torch.Size([batch_num=8, frames=16, 3, 224, 224]))\n",
        "        '''\n",
        "        # 입력 텐서 크기 변환\n",
        "        bs, ns, c, h, w = x.shape\n",
        "        out = x.view(-1, c, h, w)  # [bs*ns, c, h, w]=[128, 96, 28, 28]\n",
        "        \n",
        "        # 2D Net \n",
        "        out = self.eco_2d(out)\n",
        "\n",
        "        # 차원 복원\n",
        "        out = out.view(-1, ns, 96, 28, 28)\n",
        "\n",
        "        # 3D Net\n",
        "        out = self.eco_3d(out)  # [8, 512]\n",
        "\n",
        "        # Classification\n",
        "        out = self.fc_final(out)  # [8, 400]\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "kOEJVDlamJ0v"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = ECO_Lite()\n",
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTpPy2camU6B",
        "outputId": "b8327ae3-3c05-4a17-bcdf-0072d7efbf50"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ECO_Lite(\n",
              "  (eco_2d): ECO_2D(\n",
              "    (basic_conv): BasicConv(\n",
              "      (conv1_7x7_s2): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "      (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1_relu_7x7): ReLU(inplace=True)\n",
              "      (pool1_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "      (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2_relu_3x3_reduce): ReLU(inplace=True)\n",
              "      (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2_relu_3x3): ReLU(inplace=True)\n",
              "      (pool2_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    )\n",
              "    (inception_a): InceptionA(\n",
              "      (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_1x1): ReLU(inplace=True)\n",
              "      (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_3x3_reduce): ReLU(inplace=True)\n",
              "      (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_3x3): ReLU(inplace=True)\n",
              "      (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "      (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_double_3x3_1): ReLU(inplace=True)\n",
              "      (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_double_3x3_2): ReLU(inplace=True)\n",
              "      (inception_3a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
              "      (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3a_relu_pool_proj): ReLU(inplace=True)\n",
              "    )\n",
              "    (inception_b): InceptionB(\n",
              "      (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_1x1): ReLU(inplace=True)\n",
              "      (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_3x3_reduce): ReLU(inplace=True)\n",
              "      (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_3x3): ReLU(inplace=True)\n",
              "      (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "      (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_double_3x3_1): ReLU(inplace=True)\n",
              "      (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_double_3x3_2): ReLU(inplace=True)\n",
              "      (inception_3b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
              "      (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3b_relu_pool_proj): ReLU(inplace=True)\n",
              "    )\n",
              "    (inception_c): InceptionC(\n",
              "      (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3c_relu_double_3x3_reduce): ReLU(inplace=True)\n",
              "      (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (inception_3c_relu_double_3x3_1): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (eco_3d): ECO_3D(\n",
              "    (res_3d_3): Resnet_3D_3(\n",
              "      (res3a_2): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res3a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res3a_relu): ReLU(inplace=True)\n",
              "      (res3b_1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res3b_1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res3b_1_relu): ReLU(inplace=True)\n",
              "      (res3b_2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res3b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res3b_relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (res_3d_4): Resnet_3D_4(\n",
              "      (res4a_1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      (res4a_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res4a_1_relu): ReLU(inplace=True)\n",
              "      (res4a_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res4a_down): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      (res4a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res4a_relu): ReLU(inplace=True)\n",
              "      (res4b_1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res4b_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res4b_1_relu): ReLU(inplace=True)\n",
              "      (res4b_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res4b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res4b_relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (res_3d_5): Resnet_3D_5(\n",
              "      (res5a_1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      (res5a_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res5a_1_relu): ReLU(inplace=True)\n",
              "      (res5a_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res5a_down): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
              "      (res5a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res5a_relu): ReLU(inplace=True)\n",
              "      (res5b_1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res5b_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res5b_1_relu): ReLU(inplace=True)\n",
              "      (res5b_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
              "      (res5b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (res5b_relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): AvgPool3d(kernel_size=(4, 7, 7), stride=1, padding=0)\n",
              "  )\n",
              "  (fc_final): Linear(in_features=512, out_features=400, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oNo60IHbn8Zv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}