{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataLoader.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QQYMDi5jjYlj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tarfile\n",
        "\n",
        "# https://github.com/tensorboy/pytorch_Realtime_Multi-Person_Pose_Estimation\n",
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "weights_dir = \"./weights/\"\n",
        "if not os.path.exists(weights_dir):\n",
        "    os.mkdir(weights_dir)\n",
        "\n",
        "url =  \"http://images.cocodataset.org/zips/val2014.zip\"\n",
        "target_path = os.path.join(data_dir, \"val2014.zip\") \n",
        "\n",
        "if not os.path.exists(target_path):\n",
        "    urllib.request.urlretrieve(url, target_path)\n",
        "    \n",
        "    zip = zipfile.ZipFile(target_path)\n",
        "    zip.extractall(data_dir)  # ZIP 파일 압축 해제\n",
        "    zip.close()  # ZIP 파일 닫기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음 파일들을 다운 받아 'data' 폴더에 배치\n",
        "# https://www.dropbox.com/s/0sj2q24hipiiq5t/COCO.json?dl=0  (annotation)\n",
        "# https://www.dropbox.com/s/bd9ty7b4fqd5ebf/mask.tar.gz?dl=0  (mask)"
      ],
      "metadata": {
        "id": "ilrhwG0bqboT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = os.path.join(data_dir, \"mask.tar.gz\") \n",
        "with tarfile.open(save_path, 'r:*') as tar:\n",
        "    tar.extractall(data_dir)"
      ],
      "metadata": {
        "id": "YX6NDizPnNSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-trained된 모델\n",
        "# https://www.dropbox.com/s/5v654d2u65fuvyr/pose_model_scratch.pth?dl=0"
      ],
      "metadata": {
        "id": "vMlbahq5qvKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iZKYYpDewsyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch.utils.data as data"
      ],
      "metadata": {
        "id": "CpjnhJMUqvNE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_datapath_list(rootpath):\n",
        "    # annotation의 json 파일 읽기\n",
        "    json_path = osp.join(rootpath, 'COCO.json')\n",
        "    with open(json_path) as data_file:\n",
        "        data_this = json.load(data_file)\n",
        "        data_json = data_this['root']\n",
        "    \n",
        "    # index 저장 (train/val 구별)\n",
        "    num_samples = len(data_json)\n",
        "    train_indexes = []\n",
        "    val_indexes = []\n",
        "    for count in range(num_samples):\n",
        "        if data_json[count]['isValidation'] != 0:\n",
        "            val_indexes.append(count)\n",
        "        else:\n",
        "            train_indexes.append(count)\n",
        "    \n",
        "    # 이미지 데이터 경로 저장\n",
        "    train_img_list = []\n",
        "    val_img_list = []\n",
        "\n",
        "    for idx in train_indexes:\n",
        "        img_path = os.path.join(rootpath, data_json[idx]['img_paths'])\n",
        "        train_img_list.append(img_path)\n",
        "\n",
        "    for idx in val_indexes:\n",
        "        img_path = os.path.join(rootpath, data_json[idx]['img_paths'])\n",
        "        val_img_list.append(img_path)\n",
        "\n",
        "    # mask 데이터 경로 저장\n",
        "    train_mask_list = []\n",
        "    val_mask_list = []\n",
        "\n",
        "    for idx in train_indexes:\n",
        "        img_idx = data_json[idx]['img_paths'][-16:-4]\n",
        "        anno_path = \"./data/mask/train2014/mask_COCO_tarin2014_\" + img_idx+'.jpg'\n",
        "        train_mask_list.append(anno_path)\n",
        "\n",
        "    for idx in val_indexes:\n",
        "        img_idx = data_json[idx]['img_paths'][-16:-4]\n",
        "        anno_path = \"./data/mask/val2014/mask_COCO_val2014_\" + img_idx+'.jpg'\n",
        "        val_mask_list.append(anno_path)\n",
        "    \n",
        "    # annotation 경로 저장\n",
        "    train_meta_list = list()\n",
        "    val_meta_list = list()\n",
        "\n",
        "    for idx in train_indexes:\n",
        "        train_meta_list.append(data_json[idx])\n",
        "\n",
        "    for idx in val_indexes:\n",
        "        val_meta_list.append(data_json[idx])\n",
        "\n",
        "    return train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list"
      ],
      "metadata": {
        "id": "E9rNPl7pq-ei"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(\n",
        "    rootpath=\"./data/\")\n",
        "\n",
        "val_meta_list[24]"
      ],
      "metadata": {
        "id": "_ezcVrGTu0_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 마스크 데이터 확인\n",
        "index = 24\n",
        "\n",
        "# 이미지\n",
        "img = cv2.imread(val_img_list[index])\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# 마스크\n",
        "mask_miss = cv2.imread(val_mask_list[index])\n",
        "mask_miss = cv2.cvtColor(mask_miss, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(mask_miss)\n",
        "plt.show()\n",
        "\n",
        "# 합성 (이미지 + 마스크)\n",
        "blend_img = cv2.addWeighted(img, 0.4, mask_miss, 0.6, 0)\n",
        "plt.imshow(blend_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "McCpsyoht6It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gymoon10/utils.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH1yWLset6Lw",
        "outputId": "867a768b-8f23-48c8-dec3-efbf1eb9fff9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'utils'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 14 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (14/14), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.data_augumentation import Compose, get_anno, add_neck, aug_scale, aug_rotate, aug_croppad, aug_flip, remove_illegal_joint, Normalize_Tensor, no_Normalize_Tensor\n",
        "\n",
        "class DataTransform():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.data_transform = {\n",
        "           'train': Compose([\n",
        "                get_anno(),  # JSON에서 어노테이션을 사전에 저장\n",
        "                add_neck(),  # 어노테이션 데이터의 순서를 변경하고, 목의 어노테이션 데이터를 추가\n",
        "                aug_scale(),  # 확대 축소\n",
        "                aug_rotate(),  # 회전\n",
        "                aug_croppad(),  # 자르기\n",
        "                aug_flip(),  # 좌우 반전\n",
        "                remove_illegal_joint(),  # 화상에서 밀려나온 어노테이션을 제거\n",
        "                # Normalize_Tensor()  # 색상 정보의 표준화 및 텐서화\n",
        "                no_Normalize_Tensor()  # 여기서는 색상 정보의 표준화를 생략\n",
        "            ]),\n",
        "            'val': Compose([\n",
        "                # 검증을 생략\n",
        "            ])\n",
        "        }\n",
        "\n",
        "    def __call__(self, phase, meta_data, img, mask_miss):\n",
        "\n",
        "        meta_data, img, mask_miss = self.data_transform[phase](\n",
        "            meta_data, img, mask_miss)\n",
        "\n",
        "        return meta_data, img, mask_miss"
      ],
      "metadata": {
        "id": "tzKwdsBWt6N7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 24\n",
        "img = cv2.imread(val_img_list[index])\n",
        "mask_miss = cv2.imread(val_mask_list[index])\n",
        "meat_data = val_meta_list[index]\n",
        "\n",
        "transform = DataTransform()\n",
        "meta_data, img, mask_miss = transform(\"train\", meat_data, img, mask_miss)\n",
        "\n",
        "img = img.numpy().transpose((1, 2, 0))\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "mask_miss = mask_miss.numpy().transpose((1, 2, 0))\n",
        "plt.imshow(mask_miss)\n",
        "plt.show()\n",
        "\n",
        "img = Image.fromarray(np.uint8(img*255))\n",
        "img = np.asarray(img.convert('RGB'))\n",
        "mask_miss = Image.fromarray(np.uint8((mask_miss)))\n",
        "mask_miss = np.asarray(mask_miss.convert('RGB'))\n",
        "blend_img = cv2.addWeighted(img, 0.4, mask_miss, 0.6, 0)\n",
        "plt.imshow(blend_img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6GpINELWu6qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pdSETi5IwQhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OIoobJP6wQj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "-4z-DMcxwUWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.dataloader import get_ground_truth\n",
        "\n",
        "class COCOkeypointsDataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, img_list, mask_list, meta_list, phase, transform):\n",
        "        self.img_list = img_list\n",
        "        self.mask_list = mask_list\n",
        "        self.meta_list = meta_list\n",
        "        self.phase = phase\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, heatmaps, heat_mask, pafs, paf_mask = self.pull_item(index)\n",
        "        return img, heatmaps, heat_mask, pafs, paf_mask\n",
        "\n",
        "    def pull_item(self, index):\n",
        "        image_file_path = self.img_list[index]\n",
        "        img = cv2.imread(image_file_path)  # [높이][폭][색BGR]\n",
        "\n",
        "        mask_miss = cv2.imread(self.mask_list[index])\n",
        "        meat_data = self.meta_list[index]\n",
        "\n",
        "        meta_data, img, mask_miss = self.transform(\n",
        "            self.phase, meat_data, img, mask_miss)\n",
        "\n",
        "        mask_miss_numpy = mask_miss.numpy().transpose((1, 2, 0))\n",
        "        heat_mask, heatmaps, paf_mask, pafs = get_ground_truth(\n",
        "            meta_data, mask_miss_numpy)\n",
        "\n",
        "        heat_mask = heat_mask[:, :, :, 0]\n",
        "        paf_mask = paf_mask[:, :, :, 0]\n",
        "\n",
        "        paf_mask = paf_mask.permute(2, 0, 1)\n",
        "        heat_mask = heat_mask.permute(2, 0, 1)\n",
        "        pafs = pafs.permute(2, 0, 1)\n",
        "        heatmaps = heatmaps.permute(2, 0, 1)\n",
        "\n",
        "        return img, heatmaps, heat_mask, pafs, paf_mask"
      ],
      "metadata": {
        "id": "Y-aupcZJwQmp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = COCOkeypointsDataset(\n",
        "    val_img_list, val_mask_list, val_meta_list, phase=\"train\", transform=DataTransform())\n",
        "val_dataset = COCOkeypointsDataset(\n",
        "    val_img_list, val_mask_list, val_meta_list, phase=\"val\", transform=DataTransform())\n",
        "\n",
        "item = train_dataset.__getitem__(0)\n",
        "print(item[0].shape)  # img\n",
        "print(item[1].shape)  # heatmaps,\n",
        "print(item[2].shape)  # heat_mask\n",
        "print(item[3].shape)  # pafs \n",
        "print(item[4].shape)  # paf_mask"
      ],
      "metadata": {
        "id": "QrVwEgcAwTF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "8WchnMBMwlHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_dataloader = data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataloader = data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "\n",
        "# 동작 확인\n",
        "batch_iterator = iter(dataloaders_dict[\"train\"])  # 반복으로 변환\n",
        "item = next(batch_iterator)  # 1번째 요소를 꺼낸다\n",
        "print(item[0].shape)  # img\n",
        "print(item[1].shape)  # heatmaps,\n",
        "print(item[2].shape)  # heat_mask\n",
        "print(item[3].shape)  # pafs \n",
        "print(item[4].shape)  # paf_mask"
      ],
      "metadata": {
        "id": "a1MZXf-7wgzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D3GBQpd2wg13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bx38gYSlwg4w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}